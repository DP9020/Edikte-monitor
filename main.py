"""
Edikte-Monitor ‚Äì √ñsterreich
============================
Scraper f√ºr https://edikte.justiz.gv.at (Gerichtliche Versteigerungen)
Alle Bundesl√§nder | HTTP-Request (kein Browser n√∂tig) | Notion | Telegram
"""

import os
import re
import json
import time
import asyncio
import urllib.request
import urllib.parse
from datetime import datetime
from notion_client import Client

try:
    import fitz          # PyMuPDF ‚Äì optionale Abh√§ngigkeit
    FITZ_AVAILABLE = True
except ImportError:
    fitz = None
    FITZ_AVAILABLE = False

try:
    from openai import OpenAI as _OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    _OpenAI = None
    OPENAI_AVAILABLE = False

# =============================================================================
# KONFIGURATION
# =============================================================================

BASE_URL = "https://edikte.justiz.gv.at"

# Bundesland-Werte aus dem Formular (name=BL)
BUNDESLAENDER = {
    "Wien":           "0",
    "Nieder√∂sterreich": "1",
    "Burgenland":     "2",
    "Ober√∂sterreich": "3",
    "Salzburg":       "4",
    "Steiermark":     "5",
    "K√§rnten":        "6",
    "Tirol":          "7",
    "Vorarlberg":     "8",
}

# Nur diese Link-Texte werden verarbeitet
RELEVANT_TYPES = ("Versteigerung", "Entfall des Termins", "Verschiebung")

# Schl√ºsselw√∂rter im Link-Text ‚Üí Objekt wird NICHT importiert
# (greift auf Ergebnisseite, wo der Text oft nur "Versteigerung (Datum)" ist)
EXCLUDE_KEYWORDS = [
    "landwirtschaft",
    "land- und forst",
    "forstwirtschaft",
    "gewerb",
    "betriebsobjekt",
    "industrie",
    "lager",
    "b√ºro",
    "hotel",
    "pension",
]

# Kategorien aus der Detailseite ‚Üí Objekt wird NICHT importiert
# Entspricht den Werten im Feld "Kategorie(n)" auf edikte.justiz.gv.at
EXCLUDE_KATEGORIEN = {
    "land- und forstwirtschaftlich genutzte liegenschaft",  # LF
    "gewerbliche liegenschaft",                             # GL
    "betriebsobjekt",
    "super√§difikat",                                        # SE ‚Äì nur wenn gewerblich
}

# Notion-Feldname f√ºr PLZ (exakt so wie in der Datenbank angelegt)
NOTION_PLZ_FIELD = "Liegenschafts PLZ"

# Edikt-ID aus dem Link extrahieren
ID_RE = re.compile(r"alldoc/([0-9a-f]+)!OpenDocument", re.IGNORECASE)

# Verkehrswert / Sch√§tzwert
SCHAETZWERT_RE = re.compile(
    r'(?:Sch√§tzwert|Verkehrswert|Sch√§tzungswert|Wert)[:\s]+([\d\.\s,]+(?:EUR|‚Ç¨)?)',
    re.IGNORECASE
)


# =============================================================================
# HILFSFUNKTIONEN
# =============================================================================

def env(name: str) -> str:
    """Liest eine Umgebungsvariable ‚Äì wirft Fehler wenn nicht gesetzt."""
    value = os.getenv(name)
    if not value:
        raise RuntimeError(f"Fehlende Umgebungsvariable: {name}")
    return value


def clean_notion_db_id(raw: str) -> str:
    """Bereinigt die Notion Datenbank-ID (entfernt View-Parameter etc.)."""
    raw = raw.split("?")[0].strip()
    raw = raw.rstrip("/").split("/")[-1]
    clean = re.sub(r"[^0-9a-fA-F]", "", raw)
    if len(clean) == 32:
        return f"{clean[0:8]}-{clean[8:12]}-{clean[12:16]}-{clean[16:20]}-{clean[20:32]}"
    return raw


def is_excluded(text: str) -> bool:
    """Pr√ºft ob ein Objekt anhand des Link-Texts ausgeschlossen werden soll."""
    return any(kw in text.lower() for kw in EXCLUDE_KEYWORDS)


def is_excluded_by_kategorie(kategorie: str) -> bool:
    """Pr√ºft ob ein Objekt anhand der Detailseiten-Kategorie ausgeschlossen werden soll."""
    return kategorie.lower().strip() in EXCLUDE_KATEGORIEN


def parse_euro(raw: str) -> float | None:
    """
    Wandelt einen √∂sterreichischen Betragsstring in float um.
    z.B. '180.000,00 EUR' ‚Üí 180000.0
    """
    try:
        cleaned = re.sub(r"[‚Ç¨EUReur\s]", "", raw.strip())
        cleaned = cleaned.replace(".", "").replace(",", ".")
        return float(cleaned)
    except Exception:
        return None


def parse_flaeche(raw: str) -> float | None:
    """Wandelt '96,72 m¬≤' in 96.72 um."""
    try:
        m = re.search(r"([\d.,]+)", raw)
        if m:
            return float(m.group(1).replace(".", "").replace(",", "."))
    except Exception:
        pass
    return None


def fetch_detail(link: str) -> dict:
    """
    L√§dt die Edikt-Detailseite und extrahiert alle strukturierten Felder
    direkt aus dem Bootstrap-Grid (span.col-sm-3 + p.col-sm-9).

    Liefert ein Dict mit den Schl√ºsseln:
      liegenschaftsadresse, plz_ort, adresse_voll   ‚Üê echte Immobilienadresse
      gericht, aktenzeichen, wegen
      termin, termin_iso
      kategorie, grundbuch, ez
      flaeche_objekt, flaeche_grundstueck
      schaetzwert (float), schaetzwert_str
      geringstes_gebot (float)
    """
    try:
        req = urllib.request.Request(
            link,
            headers={"User-Agent": "Mozilla/5.0 (compatible; EdikteMonitor/1.0)"}
        )
        with urllib.request.urlopen(req, timeout=20) as r:
            html = r.read().decode("utf-8", errors="replace")
    except Exception as exc:
        print(f"    [Detail] ‚ö†Ô∏è  Fehler beim Laden: {exc}")
        return {}

    # ‚îÄ‚îÄ Alle label‚Üívalue Paare aus dem Bootstrap-Grid extrahieren ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    grid_re = re.compile(
        r'<span[^>]*col-sm-3[^>]*>\s*([^<]+?)\s*</span>\s*<p[^>]*col-sm-9[^>]*>\s*(.*?)\s*</p>',
        re.DOTALL | re.IGNORECASE
    )

    def clean(html_fragment: str) -> str:
        t = re.sub(r"<[^>]+>", " ", html_fragment)
        t = t.replace("\xa0", " ").replace("&nbsp;", " ")
        from html import unescape
        t = unescape(t)
        return " ".join(t.split()).strip()

    fields: dict[str, str] = {}
    for label, value in grid_re.findall(html):
        key = label.strip().rstrip(":").strip()
        fields[key] = clean(value)

    result: dict = {}

    # ‚îÄ‚îÄ Liegenschaftsadresse (echte Immobilienadresse!) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    adresse    = fields.get("Liegenschaftsadresse", "")
    plz_ort    = fields.get("PLZ/Ort", "")
    if adresse:
        result["liegenschaftsadresse"] = adresse
        result["plz_ort"]              = plz_ort
        result["adresse_voll"]         = f"{adresse}, {plz_ort}".strip(", ")
        print(f"    [Detail] üìç Adresse: {result['adresse_voll']}")

    # ‚îÄ‚îÄ Gericht / Dienststelle ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    if "Dienststelle" in fields:
        result["gericht"] = fields["Dienststelle"]
    elif "Dienststelle:" in fields:
        result["gericht"] = fields["Dienststelle:"]

    # ‚îÄ‚îÄ Aktenzeichen ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    for k in ("Aktenzeichen", "Aktenzeichen:"):
        if k in fields:
            result["aktenzeichen"] = fields[k]
            break

    # ‚îÄ‚îÄ wegen ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    if "wegen" in fields:
        result["wegen"] = fields["wegen"]

    # ‚îÄ‚îÄ Versteigerungstermin ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    termin_raw = fields.get("Versteigerungstermin", "")
    m = re.search(r"(\d{1,2}\.\d{1,2}\.\d{4})\s+um\s+([\d:]+\s*Uhr)", termin_raw)
    if m:
        result["termin"] = f"{m.group(1)} {m.group(2)}"
        try:
            dt = datetime.strptime(m.group(1), "%d.%m.%Y")
            result["termin_iso"] = dt.strftime("%Y-%m-%d")
        except Exception:
            pass

    # ‚îÄ‚îÄ Kategorie / Objektart ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    if "Kategorie(n)" in fields:
        result["kategorie"] = fields["Kategorie(n)"]

    # ‚îÄ‚îÄ Grundbuch / EZ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    if "Grundbuch" in fields:
        result["grundbuch"] = fields["Grundbuch"]
    if "EZ" in fields:
        result["ez"] = fields["EZ"]

    # ‚îÄ‚îÄ Fl√§chen ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    fobj = fields.get("Objektgr√∂√üe", "")
    if fobj:
        parsed = parse_flaeche(fobj)
        if parsed:
            result["flaeche_objekt"] = parsed

    fgrst = fields.get("Grundst√ºcksgr√∂√üe", "")
    if fgrst:
        parsed = parse_flaeche(fgrst)
        if parsed:
            result["flaeche_grundstueck"] = parsed

    # ‚îÄ‚îÄ Sch√§tzwert ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    sv_raw = fields.get("Sch√§tzwert", "")
    if sv_raw:
        result["schaetzwert_str"] = sv_raw
        parsed = parse_euro(sv_raw)
        if parsed is not None:
            result["schaetzwert"] = parsed
            print(f"    [Detail] üí∞ Sch√§tzwert: {parsed:,.0f} ‚Ç¨")

    # ‚îÄ‚îÄ Geringstes Gebot ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    gg_raw = fields.get("Geringstes Gebot", "")
    if gg_raw:
        parsed = parse_euro(gg_raw)
        if parsed is not None:
            result["geringstes_gebot"] = parsed

    return result


# =============================================================================
# TELEGRAM
# =============================================================================

def html_escape(text: str) -> str:
    """Escapt Sonderzeichen f√ºr Telegram HTML-Modus."""
    return (text
            .replace("&", "&amp;")
            .replace("<", "&lt;")
            .replace(">", "&gt;"))


def _telegram_send_raw(url: str, payload_dict: dict) -> None:
    """Interne Hilfsfunktion: sendet einen JSON-Payload an die Telegram API."""
    payload = json.dumps(payload_dict, ensure_ascii=False).encode("utf-8")
    req = urllib.request.Request(
        url,
        data=payload,
        headers={"Content-Type": "application/json; charset=utf-8"},
    )
    with urllib.request.urlopen(req, timeout=15) as r:
        r.read()


def _truncate_plain(text: str, limit: int = 4096) -> str:
    """K√ºrzt Plain-Text sicher auf das Zeichenlimit."""
    if len(text) <= limit:
        return text
    return text[:limit - 6] + "\n[...]"


def _strip_html_tags(text: str) -> str:
    """Entfernt alle HTML-Tags und dekodiert HTML-Entities."""
    plain = re.sub(r"<[^>]+>", "", text)
    plain = plain.replace("&amp;", "&").replace("&lt;", "<").replace("&gt;", ">")
    return plain


async def send_telegram(message: str) -> None:
    """
    Sendet eine Nachricht via Telegram Bot (HTML-Modus).
    - Wenn die Nachricht > 4096 Zeichen: wird in mehrere Teile aufgeteilt,
      wobei jeder Teil an einer Zeilengrenze getrennt wird (kein halber HTML-Tag).
    - Bei HTML-Fehler (400): Fallback auf reinen Text ohne parse_mode.
    """
    token   = env("TELEGRAM_BOT_TOKEN")
    chat_id = env("TELEGRAM_CHAT_ID")
    url     = f"https://api.telegram.org/bot{token}/sendMessage"

    def split_message(text: str, limit: int = 4000) -> list[str]:
        """Teilt eine Nachricht an Zeilengrenzen auf, sodass kein HTML-Tag zerrissen wird."""
        if len(text) <= limit:
            return [text]
        parts = []
        current = []
        current_len = 0
        for line in text.split("\n"):
            line_len = len(line) + 1  # +1 f√ºr \n
            if current_len + line_len > limit and current:
                parts.append("\n".join(current))
                current = [line]
                current_len = line_len
            else:
                current.append(line)
                current_len += line_len
        if current:
            parts.append("\n".join(current))
        return parts

    parts = split_message(message)
    total = len(parts)

    for i, part in enumerate(parts, 1):
        label = f" ({i}/{total})" if total > 1 else ""
        try:
            _telegram_send_raw(url, {
                "chat_id":                  chat_id,
                "text":                     part,
                "parse_mode":               "HTML",
                "disable_web_page_preview": True,
            })
            print(f"[Telegram] ‚úÖ Nachricht{label} gesendet ({len(part)} Zeichen)")
        except Exception as e:
            print(f"[Telegram] ‚ö†Ô∏è  HTML-Modus fehlgeschlagen{label} ({e}), versuche Plain Text ‚Ä¶")
            # Fallback: HTML-Tags entfernen, kein parse_mode senden
            plain = _truncate_plain(_strip_html_tags(part))
            try:
                _telegram_send_raw(url, {
                    "chat_id":                  chat_id,
                    "text":                     plain,
                    "disable_web_page_preview": True,
                })
                print(f"[Telegram] ‚úÖ Plain-Text{label} gesendet ({len(plain)} Zeichen)")
            except Exception as e2:
                raise RuntimeError(f"Telegram komplett fehlgeschlagen{label}: {e2}") from e2


# =============================================================================
# GUTACHTEN ‚Äì PDF-DOWNLOAD & PARSING
# =============================================================================

def gutachten_fetch_attachment_links(edikt_url: str) -> dict:
    """
    √ñffnet die Edikt-Detailseite und gibt alle Anhang-Links zur√ºck.
    R√ºckgabe: {"pdfs": [...], "images": [...]}
    """
    req = urllib.request.Request(
        edikt_url,
        headers={"User-Agent": "Mozilla/5.0 (compatible; EdikteMonitor/1.0)"}
    )
    with urllib.request.urlopen(req, timeout=30) as r:
        html = r.read().decode("utf-8", errors="replace")

    pattern = re.compile(
        r'href="(/edikte/ex/exedi3\.nsf/0/[^"]+\$file/([^"]+))"',
        re.IGNORECASE
    )
    pdfs   = []
    images = []
    for path, raw_fname in pattern.findall(html):
        fname = urllib.parse.unquote(raw_fname)
        full  = f"{BASE_URL}{path}"
        if fname.lower().endswith(".pdf"):
            pdfs.append({"url": full, "filename": fname})
        elif fname.lower().endswith((".jpg", ".jpeg", ".png")):
            images.append({"url": full, "filename": fname})
    return {"pdfs": pdfs, "images": images}


def gutachten_pick_best_pdf(pdfs: list) -> dict | None:
    """W√§hlt das wahrscheinlichste Gutachten-PDF aus der Liste."""
    preferred = ["gutachten", " g ", "sachverst", "sv-", "/g-", "g "]
    for pdf in pdfs:
        if any(kw in pdf["filename"].lower() for kw in preferred):
            return pdf
    for pdf in pdfs:
        if "anlagen" not in pdf["filename"].lower():
            return pdf
    return pdfs[0] if pdfs else None


def gutachten_download_pdf(url: str) -> bytes:
    """L√§dt ein PDF herunter und gibt die Bytes zur√ºck."""
    req = urllib.request.Request(
        url,
        headers={"User-Agent": "Mozilla/5.0 (compatible; EdikteMonitor/1.0)"}
    )
    with urllib.request.urlopen(req, timeout=60) as r:
        return r.read()


def _gb_extract_section(text: str, start_marker: str, end_marker: str) -> str:
    """Extrahiert Text zwischen zwei Markierungen."""
    start = text.lower().find(start_marker.lower())
    if start == -1:
        return ""
    end = text.lower().find(end_marker.lower(), start + len(start_marker))
    if end == -1:
        return text[start:]
    return text[start:end]


def _gb_parse_single_owner(lines: list, anteil_idx: int) -> dict:
    """
    Hilfsfunktion: Parst einen einzelnen Eigent√ºmer ab einer ANTEIL:-Zeile.
    Gibt dict mit name, adresse, plz_ort, geb zur√ºck.
    """
    adr_pattern = re.compile(
        r'GEB:\s*(\d{4}-\d{2}-\d{2})\s+ADR:\s*(.+?)\s{2,}(\d{4,5})\s*$',
        re.IGNORECASE
    )
    adr_no_geb  = re.compile(r'ADR:\s*(.+?)\s{2,}(\d{4,5})\s*$', re.IGNORECASE)
    adr_simple  = re.compile(r'ADR:\s*(.+)', re.IGNORECASE)

    owner = {"name": "", "adresse": "", "plz_ort": "", "geb": ""}

    for j in range(anteil_idx + 1, min(anteil_idx + 8, len(lines))):
        stripped = lines[j].strip()
        if not stripped:
            continue
        if re.match(r'^\d', stripped):         continue  # n√§chste ANTEIL-Zeile
        if re.match(r'^[a-z]\s+\d', stripped): continue  # "a 7321/2006 ..."
        if "GEB:" in stripped.upper():         continue
        if "ADR:" in stripped.upper():         continue
        if re.match(r'^\*+', stripped):        continue  # Trennlinie
        if re.match(r'^Seite\s+\d+\s+von\s+\d+', stripped, re.IGNORECASE): continue  # BUG 1: Seitenangabe

        owner["name"] = stripped

        # ADR-Zeile suchen (n√§chste Zeilen nach dem Namen)
        for k in range(j + 1, min(j + 4, len(lines))):
            adr_line = lines[k].strip()
            if not adr_line:
                continue
            m = adr_pattern.search(adr_line)
            if m:
                owner["geb"]     = m.group(1)
                owner["adresse"] = m.group(2).strip().rstrip(",")
                owner["plz_ort"] = m.group(3)
                break
            m2 = adr_no_geb.search(adr_line)
            if m2:
                owner["adresse"] = m2.group(1).strip().rstrip(",")
                owner["plz_ort"] = m2.group(2)
                break
            m3 = adr_simple.search(adr_line)
            if m3:
                adr_raw = m3.group(1).strip()
                plz_m   = re.search(r'\s+(\d{4,5})\s*$', adr_raw)
                if plz_m:
                    owner["plz_ort"] = plz_m.group(1)
                    owner["adresse"] = adr_raw[:plz_m.start()].strip().rstrip(",")
                else:
                    owner["adresse"] = adr_raw
                break
        break  # Name gefunden ‚Äì fertig mit diesem Eigent√ºmer

    return owner


def _gb_parse_owner(section_b: str) -> dict:
    """
    Parst ALLE Eigent√ºmer aus Section B des Grundbuchs (Miteigentum m√∂glich).

    Bei Miteigentum werden alle Namen mit ' | ' getrennt eingetragen.
    Adresse und PLZ/Ort kommen vom ersten Eigent√ºmer (Haupteigent√ºmer).

    R√ºckgabe:
      eigent√ºmer_name    ‚Äì alle Namen, z.B. "Hans Muster | Maria Muster"
      eigent√ºmer_adresse ‚Äì Adresse des ersten Eigent√ºmers
      eigent√ºmer_plz_ort ‚Äì PLZ/Ort des ersten Eigent√ºmers
      eigent√ºmer_geb     ‚Äì Geburtsdatum des ersten Eigent√ºmers
    """
    lines   = section_b.splitlines()
    owners  = []

    for i, line in enumerate(lines):
        if "ANTEIL:" not in line.upper():
            continue
        owner = _gb_parse_single_owner(lines, i)
        if owner["name"]:
            owners.append(owner)

    if not owners:
        return {
            "eigent√ºmer_name":    "",
            "eigent√ºmer_adresse": "",
            "eigent√ºmer_plz_ort": "",
            "eigent√ºmer_geb":     "",
        }

    # BUG 1: Duplikate entfernen (z.B. GmbH die 22x in Grundbuch erscheint), Reihenfolge behalten
    seen_names: set = set()
    unique_owners = []
    for o in owners:
        if o["name"] not in seen_names:
            seen_names.add(o["name"])
            unique_owners.append(o)
    owners = unique_owners

    # Alle Namen zusammenf√ºhren ("Seite X von Y" wird durch seen_names-Filter bereits verhindert)
    alle_namen = " | ".join(o["name"] for o in owners)
    erster     = owners[0]

    return {
        "eigent√ºmer_name":    alle_namen,
        "eigent√ºmer_adresse": erster["adresse"],
        "eigent√ºmer_plz_ort": erster["plz_ort"],
        "eigent√ºmer_geb":     erster["geb"],
    }


def _gb_parse_creditors(section_c: str) -> tuple:
    """Parst Pfandrechtsgl√§ubiger und Forderungsbetr√§ge aus Section C."""
    gl√§ubiger = []
    betrag    = ""
    lines = [l.strip() for l in section_c.splitlines() if l.strip()]
    fuer_pattern   = re.compile(r'^f√ºr\s+(.+)', re.IGNORECASE)
    betrag_pattern = re.compile(r'Hereinbringung von\s+(EUR\s+[\d\.,]+)', re.IGNORECASE)
    pfand_pattern  = re.compile(r'PFANDRECHT\s+H√∂chstbetrag\s+(EUR\s+[\d\.,]+)', re.IGNORECASE)
    seen = set()
    for line in lines:
        m = fuer_pattern.match(line)
        if m:
            name = m.group(1).strip().rstrip(".")
            if len(name) > 5 and name not in seen:
                gl√§ubiger.append(name)
                seen.add(name)
        if not betrag:
            mb = betrag_pattern.search(line)
            if mb:
                betrag = mb.group(1).strip()
    if not betrag:
        for line in lines:
            mp = pfand_pattern.search(line)
            if mp:
                betrag = mp.group(1).strip()
                break
    return gl√§ubiger, betrag


def gutachten_extract_info_llm(full_text: str) -> dict:
    """
    Extrahiert Eigent√ºmer, Adresse, Gl√§ubiger und Forderungsbetrag
    aus dem PDF-Text via OpenAI GPT-4o-mini.

    Gibt ein Result-Dict zur√ºck (gleiche Struktur wie gutachten_extract_info).
    Bei Fehler oder fehlendem API-Key: leeres Dict.
    """
    api_key = os.environ.get("OPENAI_API_KEY", "")
    if not api_key or not OPENAI_AVAILABLE:
        return {}

    # Nur die ersten 12.000 Zeichen senden ‚Äì reicht f√ºr alle relevanten Infos
    # und h√§lt die Token-Kosten niedrig (~0,002‚Ç¨ pro Dokument)
    text_snippet = full_text[:12000]

    prompt = """Du analysierst Texte aus √∂sterreichischen Gerichts-Gutachten f√ºr Zwangsversteigerungen.

Extrahiere genau diese Felder und antworte NUR mit validem JSON, ohne Erkl√§rungen:

{
  "eigent√ºmer_name": "Vollst√§ndiger Name der verpflichteten Partei (Immobilieneigent√ºmer). Nur der Name, keine Adresse, kein Geburtsdatum. Mehrere Eigent√ºmer mit ' | ' trennen.",
  "eigent√ºmer_adresse": "Stra√üe und Hausnummer der verpflichteten Partei (Wohnadresse f√ºr Briefversand, NICHT die Liegenschaftsadresse)",
  "eigent√ºmer_plz_ort": "PLZ und Ort der verpflichteten Partei, z.B. '1010 Wien' oder 'D-88250 Weingarten'",
  "gl√§ubiger": ["Liste der betreibenden Banken/Gl√§ubiger. Nur echte Kreditgeber (Banken, Sparkassen, etc.). KEINE Anw√§lte, Gerichte, Sachverst√§ndige, Hausverwaltungen (WEG/EG/EGT), Aktenzeichen."],
  "forderung_betrag": "Forderungsh√∂he falls angegeben, z.B. 'EUR 150.000'"
}

Wichtige Regeln:
- 'Verpflichtete Partei' = Eigent√ºmer/Schuldner ‚Üí das ist eigent√ºmer_name
- 'Betreibende Partei' = Gl√§ubiger/Bank ‚Üí das ist gl√§ubiger
- Anw√§lte (RA, Rechtsanwalt, vertreten durch) sind KEINE Gl√§ubiger
- Sachverst√§ndige, Hilfskr√§fte, Mitarbeiter des SV sind KEIN Eigent√ºmer
- WEG, EG, EGT, EigG, Eigent√ºmergemeinschaft sind KEINE Gl√§ubiger
- Wenn ein Feld nicht gefunden wird: null
- Geburtsdaten NICHT im Namen mitgeben"""

    try:
        client = _OpenAI(api_key=api_key)
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": prompt},
                {"role": "user",   "content": text_snippet},
            ],
            temperature=0,          # deterministisch
            max_tokens=400,         # reicht f√ºr JSON-Antwort
            response_format={"type": "json_object"},
        )
        raw = response.choices[0].message.content.strip()
        data = json.loads(raw)
    except Exception as exc:
        print(f"    [LLM] ‚ö†Ô∏è  OpenAI-Fehler: {exc}")
        return {}

    def _str(val) -> str:
        return str(val).strip() if val else ""

    def _lst(val) -> list:
        if isinstance(val, list):
            return [str(v).strip() for v in val if v and str(v).strip()]
        if isinstance(val, str) and val.strip():
            return [val.strip()]
        return []

    return {
        "eigent√ºmer_name":    _str(data.get("eigent√ºmer_name")),
        "eigent√ºmer_adresse": _str(data.get("eigent√ºmer_adresse")),
        "eigent√ºmer_plz_ort": _str(data.get("eigent√ºmer_plz_ort")),
        "eigent√ºmer_geb":     "",
        "gl√§ubiger":          _lst(data.get("gl√§ubiger")),
        "forderung_betrag":   _str(data.get("forderung_betrag")),
    }


def gutachten_extract_info(pdf_bytes: bytes) -> dict:
    """
    Extrahiert Eigent√ºmer, Adresse, Gl√§ubiger und Forderungsbetrag aus dem PDF.
    Unterst√ºtzt Grundbuchauszug-Format (K√§rnten-Stil) und professionelle
    Gutachten mit 'Verpflichtete Partei:'-Angabe (Wien-Stil).
    Gibt leeres Dict zur√ºck wenn fitz nicht verf√ºgbar ist.
    """
    if not FITZ_AVAILABLE:
        return {}

    doc      = fitz.open(stream=pdf_bytes, filetype="pdf")
    all_text = [p.get_text() for p in doc if p.get_text().strip()]
    full_text = "\n".join(all_text)

    result = {
        "eigent√ºmer_name":    "",
        "eigent√ºmer_adresse": "",
        "eigent√ºmer_plz_ort": "",
        "eigent√ºmer_geb":     "",
        "gl√§ubiger":          [],
        "forderung_betrag":   "",
    }

    # ‚îÄ‚îÄ Format 1: Grundbuchauszug Sektionen B / C ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    sec_b = _gb_extract_section(full_text, "** B ***", "** C ***")
    if not sec_b:
        sec_b = _gb_extract_section(full_text, "** B **", "** C **")
    if sec_b:
        result.update(_gb_parse_owner(sec_b))

    sec_c = _gb_extract_section(full_text, "** C ***", "** HINWEIS ***")
    if not sec_c:
        sec_c = _gb_extract_section(full_text, "** C **", "HINWEIS")
    if sec_c:
        gl, bt = _gb_parse_creditors(sec_c)
        result["gl√§ubiger"]        = gl
        result["forderung_betrag"] = bt

    # ‚îÄ‚îÄ Format 2: Professionelles Gutachten (Verpflichtete Partei) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # Suche im GESAMTEN Text ‚Äì "Verpflichtete Partei" kann auf Seite 1, 5 oder
    # sp√§ter stehen (nach Deckblatt/Inhaltsverzeichnis des Sachverst√§ndigen).
    #
    # Vorkommen:
    #   Format A (eine Zeile):  "Verpflichtete Partei: Name GmbH"
    #   Format B (n√§chste Zeile): "Verpflichtete Partei\n \nIng. Alfred ... GmbH"
    #
    # Adress-Extraktion: direkt aus dem Verpflichtete-Partei-Block, NICHT durch
    # sp√§tere Namensuche ‚Äì so wird die Wohnadresse des Eigent√ºmers gefunden
    # (inkl. Deutschland D-XXXXX oder andere 5-stellige PLZ).

    # Hilfsfunktion: pr√ºft ob eine Zeile eine Adresszeile ist
    # (Stra√üe + Nummer) oder eine PLZ/Ort-Zeile
    def _ist_adresszeile(line: str) -> bool:
        """True wenn die Zeile wie eine Stra√üe/Hausnummer aussieht."""
        return bool(re.search(
            r'(stra√üe|gasse|weg|platz|allee|ring|zeile|g√ºrtel|promenade|str\.|'
            r'strasse|gasse|graben|markt|anger|hof|aue|berg|dorf|'
            r'\d+[a-z]?\s*[/,]\s*\d|\s\d+[a-z]?$)',
            line, re.IGNORECASE))

    def _ist_plz_ort(line: str) -> tuple:
        """
        Gibt (plz, ort) zur√ºck wenn die Zeile eine PLZ/Ort-Kombination ist.
        Unterst√ºtzt:
          - AT:  '1234 Wien'  oder  '1234'
          - DE:  'D-12345 Berlin'  oder  '12345 M√ºnchen'
          - Kombination in einer Zeile: 'Musterstra√üe 5, 1234 Wien'
        """
        # Deutsches Pr√§fix: D-XXXXX
        m = re.search(r'\bD[-‚Äì]\s*(\d{5})\s+(.+)', line)
        if m:
            return m.group(1), f"D-{m.group(1)} {m.group(2).strip()}"
        # 5-stellige PLZ (Deutschland/Liechtenstein etc.)
        # Ortsname kann Bindestriche enthalten (z.B. Titisee-Neustadt, Baden-Baden)
        m = re.search(r'\b(\d{5})\s+([A-Z√Ñ√ñ√ú][\w\-\s]+)', line)
        if m:
            plz = m.group(1)
            if not re.match(r'^(19|20)\d{3}$', plz):  # keine Jahreszahl
                ort = m.group(2).strip().rstrip('.,')   # trailing Satzzeichen weg
                return plz, f"{plz} {ort}"
        # 4-stellige PLZ (√ñsterreich/Schweiz)
        m = re.search(r'\b(\d{4})\s+([A-Z√Ñ√ñ√ú][\w\-\s]+)', line)
        if m:
            plz = m.group(1)
            if not re.match(r'^(19|20)\d{2}$', plz):
                ort = m.group(2).strip().rstrip('.,')   # trailing Satzzeichen weg
                return plz, f"{plz} {ort}"
        # Nur PLZ (4 oder 5 Stellen) ohne Ortsname
        m = re.search(r'\b(\d{4,5})\b', line)
        if m:
            plz = m.group(1)
            if not re.match(r'^(19|20)\d{2,3}$', plz):
                return plz, plz
        return "", ""

    if not result["eigent√ºmer_name"]:
        # Alle Vorkommen von "Verpflichtete Partei" finden
        # Name + Adresse werden direkt aus diesem Block gelesen
        for vp_match in re.finditer(r'Verpflichtete\s+Partei', full_text, re.IGNORECASE):
            # Inline-Name direkt nach "Verpflichtete Partei: Name, Stra√üe, PLZ Ort"
            # z.B. "Verpflichtete Partei: Firma XY GmbH, Kirchgasse 3, 6900 Bregenz"
            rest_of_line = full_text[vp_match.end():].split("\n")[0].strip().lstrip(":").strip()
            block = full_text[vp_match.end():vp_match.end() + 500]
            lines_vp = [l.strip().lstrip(":").strip() for l in block.split("\n")]
            lines_vp = [l for l in lines_vp if l]  # Leerzeilen raus

            name_candidate = ""
            adr_candidate  = ""
            plz_candidate  = ""

            # Sonderfall: alles in einer Zeile "Name, Stra√üe, PLZ Ort"
            if rest_of_line and len(rest_of_line) > 3 and "," in rest_of_line:
                parts = [p.strip() for p in rest_of_line.split(",")]
                # Letzter Teil: PLZ Ort?
                plz, ort = _ist_plz_ort(parts[-1])
                if plz and len(parts) >= 2:
                    inline_name = parts[0].rstrip(".")
                    # BUG D: Hilfskraft/Mitarbeiter auch im Inline-Pfad filtern
                    # Pr√ºfe sowohl den Namensteil als auch die gesamte Zeile
                    if re.search(
                            r'(Hilfskraft|Mitarbeiter[in]*)\s+(des|der)\s+(S[Vv]|Sachverst)',
                            rest_of_line, re.IGNORECASE):
                        pass  # nicht setzen, weiter zum n√§chsten vp_match
                    # BUG: Nur Punkte / Sonderzeichen ohne Buchstaben/Ziffern ‚Üí √ºberspringen
                    elif not any(c.isalnum() for c in inline_name):
                        pass
                    else:
                        name_candidate = inline_name
                        adr_candidate  = parts[-2].rstrip(".") if len(parts) >= 3 else ""
                        plz_candidate  = ort
                        result["eigent√ºmer_name"]    = name_candidate
                        result["eigent√ºmer_adresse"] = adr_candidate
                        result["eigent√ºmer_plz_ort"] = plz_candidate
                        break

            for idx, line in enumerate(lines_vp):
                # Stopp: n√§chster Hauptabschnitt
                if re.match(r'^(wegen|gegen|Aktenzahl|Auftrag|Gericht|Betreibende|\d+\.)',
                            line, re.IGNORECASE):
                    break
                # Vertreter-Zeilen nie als Name nehmen
                if re.match(r'^(vertreten|durch:|RA\s|Rechtsanwalt)',
                            line, re.IGNORECASE):
                    break
                # Grundbuch-Anteil / Dateiname √ºberspringen
                if re.match(r'^GA\s+\d', line, re.IGNORECASE):
                    continue
                if re.match(r'^\d+/\d+\s+(Anteil|EZ|KG)', line, re.IGNORECASE):
                    continue

                if not name_candidate:
                    # Erste brauchbare Zeile = Name
                    if len(line) > 3:
                        # BUG: Nur Punkte/Sonderzeichen ohne Buchstaben ‚Üí kein Name
                        # Auch ".......... 2" (Punkte + Ziffer) ‚Üí kein Name
                        if not any(c.isalpha() for c in line):
                            break
                        # BUG: Fragmente wie ") und Ma-" (PDF-Zeilenumbruch-Artefakt)
                        # Erkennbar: beginnt mit ) oder endet mit -
                        if re.match(r'^[)\]}>]', line) or line.rstrip().endswith('-'):
                            break
                        # BUG D: Hilfskraft/Mitarbeiter des SV nie als Name
                        # "- Frau Mag. Zuzana ..., Hilfskraft des Sachverst√§ndigen"
                        # "Frau Dipl.-Ing. ..., Mitarbeiterin des SV"
                        if re.search(
                                r'(Hilfskraft|Mitarbeiter[in]*)\s+(des|der)\s+(S[Vv]|Sachverst)',
                                line, re.IGNORECASE):
                            break
                        # BUG E: Kontextzeilen wie "(Sohn der verpflichteten Partei)" √ºberspringen
                        if re.match(r'^\(', line) or re.search(
                                r'(Sohn|Tochter|Ehemann|Ehefrau|Partner)\s+(der|des)\s+verpflicht',
                                line, re.IGNORECASE):
                            break
                        # BUG C: Geburtsdatum aus Name entfernen (mit ODER ohne Komma)
                        # "Christine KLEMENT, geb.29.12.1975" ‚Üí "Christine KLEMENT"
                        # "Dino Ceranic geb. 26.12.1995"      ‚Üí "Dino Ceranic"
                        name_clean = re.sub(
                            r',?\s*geb\.?\s*\d{1,2}[.\-]\d{1,2}[.\-]\d{2,4}', '',
                            line, flags=re.IGNORECASE).strip().rstrip(",.")
                        # Auch "geb. DD.MM.YYYY" ohne Komma davor entfernen
                        name_clean = re.sub(
                            r'\s+geb\.?\s+\d{1,2}[.\-]\d{1,2}[.\-]\d{2,4}', '',
                            name_clean, flags=re.IGNORECASE).strip().rstrip(",.")
                        # BUG I: Name enth√§lt komplette Adresse (Komma + PLZ/Stra√üe)
                        # "AJ GmbH, Ragnitzstra√üe 91, 8047 Graz" ‚Üí nur erster Teil
                        if "," in name_clean:
                            parts_n = [p.strip() for p in name_clean.split(",")]
                            plz_t, _ = _ist_plz_ort(parts_n[-1])
                            if plz_t or _ist_adresszeile(parts_n[-1]):
                                name_clean = parts_n[0].strip()
                        name_candidate = name_clean
                    continue

                # Nach dem Namen: Adresse + PLZ/Ort suchen
                # Zeile k√∂nnte Stra√üe + PLZ/Ort in einer Zeile sein
                # z.B. "Kirchweg 3, 6900 Bregenz"
                if not adr_candidate:
                    inline_plz, inline_ort = _ist_plz_ort(line)
                    if inline_plz and _ist_adresszeile(line):
                        # Alles vor der PLZ = Stra√üe
                        sm = re.match(r'^(.+?),?\s+(?:D[-‚Äì]\s*)?\d{4,5}\s+', line)
                        if sm:
                            adr_candidate = sm.group(1).strip().rstrip(".,")
                            plz_candidate = inline_ort
                            break
                # Zeile k√∂nnte reine Stra√üe sein (ohne PLZ)
                # BUG F: Firmenbuchnummer nie als Adresse
                if re.match(r'^Firmenbuch', line, re.IGNORECASE):
                    break
                # BUG G: Geburtsdatum nie als Adresse ("Geb. 24. 9. 1967")
                if re.match(r'^[Gg]eb\.?\s*\d', line):
                    break
                if not adr_candidate and _ist_adresszeile(line):
                    adr_candidate = line.rstrip(".,")
                    continue

                # Zeile k√∂nnte PLZ/Ort sein
                plz, ort = _ist_plz_ort(line)
                if plz:
                    plz_candidate = ort
                    # Falls noch keine Stra√üe: schauen ob PLZ+Ort in einer Zeile mit Stra√üe
                    if not adr_candidate:
                        # Versuche Stra√üe aus derselben Zeile zu lesen
                        # z.B. "Musterstra√üe 5, 6900 Bregenz"
                        street_m = re.match(
                            r'^(.+?),?\s+(?:D[-‚Äì]\s*)?\d{4,5}\s+', line)
                        if street_m and _ist_adresszeile(street_m.group(1)):
                            adr_candidate = street_m.group(1).strip().rstrip(".,")
                    break

                # Stopp wenn n√§chster Abschnitt beginnt
                if re.match(r'^(wegen|gegen|Aktenzahl|Auftrag|\d+\.)', line,
                            re.IGNORECASE):
                    break

            if name_candidate and len(name_candidate) > 3:
                result["eigent√ºmer_name"]    = name_candidate
                result["eigent√ºmer_adresse"] = adr_candidate
                result["eigent√ºmer_plz_ort"] = plz_candidate
                break

    # Falls Name bekannt aber Adresse fehlt noch ‚Üí nochmal im gesamten Text suchen
    # (Fallback f√ºr F√§lle wo Adresse nicht direkt nach "Verpflichtete Partei" steht)
    if result["eigent√ºmer_name"] and not result["eigent√ºmer_adresse"]:
        name_start = re.escape(result["eigent√ºmer_name"][:40])
        all_matches = list(re.finditer(name_start, full_text, re.IGNORECASE))
        for match_pos in reversed(all_matches):  # letztes Vorkommen zuerst
            search_block = full_text[match_pos.start():match_pos.start() + 500]
            lines_adr = [l.strip() for l in search_block.split("\n") if l.strip()]
            prev_line = ""
            for line in lines_adr[1:]:
                if re.match(r'^GA\s+\d', line, re.IGNORECASE):
                    continue
                if re.match(r'^\d+/\d+\s+(Anteil|EZ|KG)', line, re.IGNORECASE):
                    continue
                if re.match(r'^(wegen|gegen|Aktenzahl|Auftrag|\d+\.)', line,
                            re.IGNORECASE):
                    break
                # BUG F+G auch im Fallback: Firmenbuch/Geburtsdatum nie als Adresse
                if re.match(r'^Firmenbuch', line, re.IGNORECASE):
                    break
                if re.match(r'^[Gg]eb\.?\s*\d', line):
                    break
                plz, ort = _ist_plz_ort(line)
                if plz:
                    if prev_line and _ist_adresszeile(prev_line):
                        result["eigent√ºmer_adresse"] = prev_line.rstrip(".,")
                    elif not prev_line or not _ist_adresszeile(prev_line):
                        # PLZ+Ort vielleicht in derselben Zeile wie Stra√üe
                        street_m = re.match(
                            r'^(.+?),?\s+(?:D[-‚Äì]\s*)?\d{4,5}\s+', line)
                        if street_m and _ist_adresszeile(street_m.group(1)):
                            result["eigent√ºmer_adresse"] = \
                                street_m.group(1).strip().rstrip(".,")
                    result["eigent√ºmer_plz_ort"] = ort
                    break
                if _ist_adresszeile(line):
                    prev_line = line
                else:
                    prev_line = line
            if result["eigent√ºmer_adresse"]:
                break

    # Gl√§ubiger / Betreibende Partei ‚Äì ebenfalls im gesamten Text suchen
    if not result["gl√§ubiger"]:
        # Alle Betreibende-Partei-Bl√∂cke sammeln (kann mehrere geben)
        gl_kandidaten: list[str] = []
        for bp_match in re.finditer(r'Betreibende\s+Partei', full_text, re.IGNORECASE):
            block = full_text[bp_match.end():bp_match.end() + 400]
            lines_block = [l.strip() for l in block.split("\n")]
            candidate = ""
            i = 0
            while i < len(lines_block):
                line_stripped = lines_block[i]
                if not line_stripped:
                    i += 1
                    continue
                # "vertreten durch:" ‚Üí echter Name kommt DANACH (√ºberspringen)
                if re.match(r'^vertreten\s+durch|^durch:', line_stripped, re.IGNORECASE):
                    # n√§chste nicht-leere Zeile ist der echte Gl√§ubiger
                    for j in range(i + 1, min(i + 4, len(lines_block))):
                        next_line = lines_block[j].strip()
                        if next_line and not re.match(
                                r'^(gegen|Verpflichtete|wegen|Aktenzahl|\d+\.)',
                                next_line, re.IGNORECASE):
                            candidate = next_line
                            break
                    break
                # N√§chster Abschnitt ‚Üí stoppen
                if re.match(r'^(gegen\s+die|Verpflichtete|wegen|Aktenzahl)',
                            line_stripped, re.IGNORECASE):
                    break
                if line_stripped in (":", ""):
                    i += 1
                    continue
                candidate = line_stripped
                break

            if candidate and len(candidate) > 3:
                gl_kandidaten.append(candidate.rstrip(",."))

        # BUG 5+6: Gl√§ubiger deduplicieren und EG/WEG-Hausverwaltungen filtern
        def _gl_normalize(name: str) -> str:
            """Entfernt FN-Nummern etc. f√ºr Duplikat-Vergleich."""
            return re.sub(r'\s*\(FN\s*\d+\w*\)', '', name, flags=re.IGNORECASE).strip()

        gl_seen_norm: set = set()
        gl_final: list[str] = []
        for gl in gl_kandidaten:
            # BUG A: f√ºhrende ': ' entfernen (": Sparkasse P√∂llau AG")
            gl = gl.lstrip(": ").strip()
            # BUG B: trailing ' |' und leere Segmente entfernen ("... AG |")
            gl = gl.rstrip(" |").strip()
            # Nach Bereinigung nochmal pr√ºfen ob noch was √ºbrig
            if not gl or len(gl) < 3:
                continue
            # Leere Pipe-Segmente entfernen ("| | & Gerichtsvollzieher" ‚Üí weg)
            parts_gl = [p.strip() for p in gl.split("|")]
            parts_gl = [p.lstrip(": ").strip() for p in parts_gl]
            # BUG J: Gerichtsvollzieher, Rechtsanwalt o.√§. als alleinstehende Segmente filtern
            # Auch Punkteketten (".......... 2") und Personen-mit-Datum-Segmente entfernen
            def _gl_segment_ok(p: str) -> bool:
                if not p or len(p) <= 3:
                    return False
                if re.match(r'^(&\s*)?(Gerichtsvollzieher|Rechtsanwalt|RA\s|im\s+Zuge)', p, re.IGNORECASE):
                    return False
                if not any(c.isalpha() for c in p):  # nur Punkte/Ziffern/Symbole
                    return False
                # Personen-Segment mit Geburtsdatum z.B. "Elisabeth Schmid geb 1954-01-18"
                if re.search(r'\bgeb\s+\d{4}[-./]\d{2}[-./]\d{2}\b', p, re.IGNORECASE):
                    return False
                if re.search(r'\b(19|18)\d{2}[-./]\d{1,2}[-./]\d{1,2}\b', p):
                    return False
                return True
            parts_gl = [p for p in parts_gl if _gl_segment_ok(p)]
            gl = " | ".join(parts_gl).strip(" |")
            if not gl or len(gl) < 3:
                continue

            # BUG 6: "EG der EZ XXXX KG XXXXX" mit vollst√§ndiger Katastralangabe weglassen
            if re.match(r'^EG\s+der\s+EZ\s+\d+\s+KG\s+\d+', gl, re.IGNORECASE):
                continue
            # Eigent√ºmergemeinschaft / Wohnungseigentumsgem. ‚Üí kein Gl√§ubiger
            if re.match(r'^(Eigent√ºmergemeinschaft|Wohnungseigentums?gem\.?)', gl, re.IGNORECASE):
                continue
            # WEG / EG / EGT / EigG als Gl√§ubiger filtern
            # "WEG EZ 2392 KG ...", "EGT Gemeinschaft ...", "EigG Kitzb√ºhel"
            if re.match(r'^(WEG|EG[T]?|EigG)\b', gl, re.IGNORECASE):
                continue
            # Aktenzeichen als Gl√§ubiger filtern ("Gem√§√ü Aktenzeichen: 3 E 3374/24f")
            if re.match(r'^Gem√§√ü\s+Aktenzeichen', gl, re.IGNORECASE):
                continue
            # Nur Punkte/Symbole ohne echte Buchstaben ‚Üí kein Gl√§ubiger
            if not any(c.isalpha() for c in gl):
                continue
            # Personen mit Geburtsdatum filtern ‚Äì verschiedene Formate:
            # "Hermann St√∂ckl, 1920-03-29"  (ISO mit Bindestrichen)
            # "Elisabeth Schmid geb 1954-01-18"  (mit 'geb' Marker)
            # "Elisabeth Schmid geb. 25.3.1954"  (mit Punkt-Datum)
            if re.search(r'\b(19|18)\d{2}[-./]\d{1,2}[-./]\d{1,2}\b', gl):
                continue
            if re.search(r'\bgeb\.?\s*\d{1,2}[.\-]\d{1,2}[.\-]\d{2,4}', gl, re.IGNORECASE):
                continue
            if re.search(r'\bgeb\s+\d{4}[-./]\d{2}[-./]\d{2}\b', gl, re.IGNORECASE):
                continue
            # BUG H: Hotels/Gastronomiebetriebe ohne Bank-Charakter filtern
            if re.search(r'(Mountain Resort|Hotel|Gasthof|Pension|Wirtshaus|Betreiber\s+ROJ)',
                         gl, re.IGNORECASE):
                continue

            norm = _gl_normalize(gl)
            if norm not in gl_seen_norm:
                gl_seen_norm.add(norm)
                gl_final.append(gl)

        if gl_final:
            result["gl√§ubiger"] = gl_final

    return result


def gutachten_enrich_notion_page(
    notion: Client,
    page_id: str,
    edikt_url: str,
) -> bool:
    """
    Hauptfunktion: L√§dt das Gutachten-PDF von der Edikt-Seite,
    extrahiert Eigent√ºmer/Gl√§ubiger und schreibt sie in die Notion-Seite.

    Gibt True zur√ºck wenn erfolgreich, False bei Fehler oder fehlendem PDF.
    Das Flag 'Gutachten analysiert?' wird immer gesetzt (True/False).
    """
    if not FITZ_AVAILABLE:
        print("    [Gutachten] ‚ö†Ô∏è  PyMuPDF nicht verf√ºgbar ‚Äì √ºberspringe PDF-Analyse")
        return False

    try:
        attachments = gutachten_fetch_attachment_links(edikt_url)
        pdfs = attachments["pdfs"]
    except Exception as exc:
        print(f"    [Gutachten] ‚ö†Ô∏è  Fehler beim Laden der Edikt-Seite: {exc}")
        notion.pages.update(
            page_id=page_id,
            properties={"Gutachten analysiert?": {"checkbox": False}}
        )
        return False

    if not pdfs:
        # BUG 9: analysiert?=True setzen damit dieser Eintrag nicht endlos wiederholt wird
        print("    [Gutachten] ‚ÑπÔ∏è  Kein PDF-Anhang gefunden ‚Äì markiere als abgeschlossen")
        notion.pages.update(
            page_id=page_id,
            properties={
                "Gutachten analysiert?": {"checkbox": True},
                "Notizen": {"rich_text": [{"text": {"content": "Kein PDF auf Edikt-Seite verf√ºgbar"}}]},
            }
        )
        return False

    gutachten = gutachten_pick_best_pdf(pdfs)
    print(f"    [Gutachten] üìÑ {gutachten['filename']}")

    try:
        pdf_bytes = gutachten_download_pdf(gutachten["url"])
    except Exception as exc:
        print(f"    [Gutachten] ‚ö†Ô∏è  Download-Fehler: {exc}")
        notion.pages.update(
            page_id=page_id,
            properties={"Gutachten analysiert?": {"checkbox": False}}
        )
        return False

    # ‚îÄ‚îÄ Text aus PDF extrahieren ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    try:
        doc       = fitz.open(stream=pdf_bytes, filetype="pdf")
        full_text = "\n".join(p.get_text() for p in doc if p.get_text().strip())
    except Exception as exc:
        print(f"    [Gutachten] ‚ö†Ô∏è  PDF-Text-Fehler: {exc}")
        notion.pages.update(
            page_id=page_id,
            properties={"Gutachten analysiert?": {"checkbox": False}}
        )
        return False

    # ‚îÄ‚îÄ Extraktion: LLM zuerst, Regex als Fallback ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    info = {}
    used_llm = False
    if OPENAI_AVAILABLE and os.environ.get("OPENAI_API_KEY"):
        try:
            info = gutachten_extract_info_llm(full_text)
            if info.get("eigent√ºmer_name") or info.get("gl√§ubiger"):
                used_llm = True
                print("    [Gutachten] ü§ñ LLM-Extraktion erfolgreich")
        except Exception as exc:
            print(f"    [Gutachten] ‚ö†Ô∏è  LLM-Fehler: {exc}")
            info = {}

    if not used_llm:
        # Fallback: Regex-Parser (Grundbuchauszug-Format + VP-Block)
        try:
            info = gutachten_extract_info(pdf_bytes)
            print("    [Gutachten] üîç Regex-Fallback verwendet")
        except Exception as exc:
            print(f"    [Gutachten] ‚ö†Ô∏è  Parse-Fehler: {exc}")
            notion.pages.update(
                page_id=page_id,
                properties={"Gutachten analysiert?": {"checkbox": False}}
            )
            return False

    # ‚îÄ‚îÄ Notion-Properties aufbauen ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # has_owner wird nach Bereinigung gesetzt (weiter unten)
    properties: dict = {
        "Gutachten analysiert?": {"checkbox": True},
    }

    def _rt(text: str) -> dict:
        return {"rich_text": [{"text": {"content": str(text)[:2000]}}]}

    # ‚îÄ‚îÄ Nachbereinigung: Name + Adresse validieren ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    def _clean_extracted_name(name: str) -> str:
        """Verwirft Parser-Artefakte die als Name durchgerutscht sind."""
        if not name:
            return ""
        # GPT-Platzhalter / Nicht-Namen herausfiltern
        INVALID_NAMES = {"nicht angegeben", "unbekannt", "n/a", "none", "null", "-", "‚Äì"}
        if name.strip().lower() in INVALID_NAMES:
            return ""
        # Fragmente wie ") und Ma-" (PDF-Seitenumbruch-Artefakte)
        if re.match(r'^[)\\]}>]', name) or name.rstrip().endswith('-'):
            return ""
        # Nur Punkte/Symbole ohne echte Buchstaben
        if not any(c.isalpha() for c in name):
            return ""
        return name

    def _clean_extracted_adresse(adr: str) -> str:
        """Bereinigt fehlerhafte Adressen."""
        if not adr:
            return ""
        # "A-9063 Maria Saal, Trattenweg 6, Telefon" ‚Üí Telefon-Teil abschneiden
        adr = re.sub(r',?\s*Telefon.*$', '', adr, flags=re.IGNORECASE).strip().rstrip(',')
        # "8042 Graz, Neue-Welt-H√∂he 17a" oder "A-9063 Maria Saal, Trattenweg 6"
        # ‚Üí PLZ+Ort vor Stra√üe ‚Üí nur Stra√üe nehmen
        m_ort_vor_strasse = re.match(r'^(?:[A-Za-z]-?)?\d{4,5}\s+\S+.*?,\s*(.+)', adr)
        if m_ort_vor_strasse:
            adr = m_ort_vor_strasse.group(1).strip()
        # "Pritzstra√üe 9 A, Linz" ‚Üí Stadtname am Ende entfernen (keine PLZ ‚Üí kein PLZ/Ort-Feld)
        adr = re.sub(r',\s*[A-Z√Ñ√ñ√ú][a-z√§√∂√º√ü]+$', '', adr).strip()
        return adr

    name_clean = _clean_extracted_name(info.get("eigent√ºmer_name", ""))
    adr_clean  = _clean_extracted_adresse(info.get("eigent√ºmer_adresse", ""))

    if name_clean:
        print(f"    [Gutachten] üë§ Eigent√ºmer: {name_clean}")
        properties["Verpflichtende Partei"] = _rt(name_clean)

    if adr_clean:
        print(f"    [Gutachten] üè† Adresse: {adr_clean}")
        properties["Zustell Adresse"] = _rt(adr_clean)

    if info.get("eigent√ºmer_plz_ort"):
        properties["Zustell PLZ/Ort"] = _rt(info["eigent√ºmer_plz_ort"])

    # ‚îÄ‚îÄ Betreibende Partei (Gl√§ubiger / Bank) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    if info.get("gl√§ubiger"):
        gl_text = " | ".join(info["gl√§ubiger"])
        print(f"    [Gutachten] üè¶ Gl√§ubiger: {' | '.join(info['gl√§ubiger'][:2])}")
        properties["Betreibende Partei"] = _rt(gl_text)

    # ‚îÄ‚îÄ Notizen: Forderungsbetrag + PDF-Link ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # HINWEIS: 'Langgutachten (Datei)' ist ein Notion-File-Upload-Feld und kann
    # keine externen URLs speichern ‚Üí PDF-Link bleibt in Notizen.
    # has_owner basiert auf bereinigtem Name/Adresse
    has_owner = bool(name_clean or adr_clean)

    notiz_parts = []
    if info.get("forderung_betrag"):
        notiz_parts.append("Forderung: " + info["forderung_betrag"])
    notiz_parts.append(f"Gutachten-PDF: {gutachten['url']}")
    properties["Notizen"] = _rt("\n".join(notiz_parts))

    if not has_owner:
        # Gescanntes Dokument ‚Äì trotzdem als analysiert markieren
        properties["Notizen"] = _rt(
            f"Gutachten-PDF: {gutachten['url']}\n"
            "(Kein Text lesbar ‚Äì gescanntes Dokument)"
        )
        print("    [Gutachten] ‚ö†Ô∏è  Kein Eigent√ºmer gefunden (gescanntes Dokument?)")

    try:
        notion.pages.update(page_id=page_id, properties=properties)
        print("    [Gutachten] ‚úÖ Notion aktualisiert")
    except Exception as exc:
        print(f"    [Gutachten] ‚ö†Ô∏è  Notion-Update-Fehler: {exc}")
        return False

    return True


# =============================================================================
# NOTION
# =============================================================================

def notion_load_all_ids(notion: Client, db_id: str) -> dict[str, str]:
    """
    L√§dt ALLE bestehenden Eintr√§ge aus der Notion-DB und gibt ein Dict
    {edikt_id -> page_id} zur√ºck.

    Zus√§tzlich werden Eintr√§ge mit fortgeschrittener Workflow-Phase
    (z.B. 'Angeschrieben', 'Angebot', 'Gekauft') unter dem Sentinel-Wert
    "(geschuetzt)" gespeichert ‚Äì der Scraper √ºberspringt diese komplett,
    auch wenn die Hash-ID matcht. So werden bereits bearbeitete Immobilien
    niemals dupliziert oder √ºberschrieben.

    Paginierung: Notion liefert max. 100 Ergebnisse pro Anfrage.
    """
    # Workflow-Phasen die NICHT √ºberschrieben werden d√ºrfen
    # Phasen die vom Scraper NICHT √ºberschrieben werden d√ºrfen
    # (Eintr√§ge die bereits manuell bearbeitet wurden)
    GESCHUETZT_PHASEN = {
        "üîé In Pr√ºfung",
        "‚ùå Nicht relevant",
        "‚úÖ Relevant ‚Äì Brief vorbereiten",
        "üì© Brief versendet",
        "üìä Gutachten analysiert",
        "‚úÖ Gekauft",
        "üóÑ Archiviert",
    }

    print("[Notion] üì• Lade alle bestehenden IDs aus der Datenbank ‚Ä¶")
    known: dict[str, str] = {}  # edikt_id -> page_id  (oder "(geschuetzt)")
    has_more = True
    cursor = None
    page_count = 0
    geschuetzt_count = 0

    while has_more:
        kwargs: dict = {"filter": {"value": "page", "property": "object"}, "page_size": 100}
        if cursor:
            kwargs["start_cursor"] = cursor
        try:
            resp = notion.search(**kwargs)
        except Exception as exc:
            print(f"  [Notion] ‚ö†Ô∏è  Fehler beim Laden der IDs: {exc}")
            break

        for page in resp.get("results", []):
            # Nur Pages aus unserer DB
            parent = page.get("parent", {})
            if parent.get("database_id", "").replace("-", "") != db_id.replace("-", ""):
                continue

            props = page.get("properties", {})

            # Workflow-Phase pr√ºfen
            phase_sel = props.get("Workflow-Phase", {}).get("select") or {}
            phase = phase_sel.get("name", "")

            # Status-Feld pr√ºfen:
            # üî¥ Rot              ‚Üí IMMER echte page_id speichern (Entfall archiviert immer)
            #                       Rot hat Vorrang vor jeder Phase
            # üü¢ Gr√ºn / üü° Gelb  ‚Üí komplett gesch√ºtzt (kein √úberschreiben, kein Auto-Archiv)
            status_sel = props.get("Status", {}).get("select") or {}
            status = status_sel.get("name", "")
            ist_rot        = (status == "üî¥ Rot")
            # Rot hat Vorrang: auch wenn Phase gesch√ºtzt w√§re, z√§hlt Rot
            ist_geschuetzt = (not ist_rot) and (phase in GESCHUETZT_PHASEN or status in ("üü¢ Gr√ºn", "üü° Gelb"))

            # Hash-ID auslesen
            hash_rt = props.get("Hash-ID / Vergleichs-ID", {}).get("rich_text", [])
            eid = ""
            if hash_rt:
                eid = hash_rt[0].get("plain_text", "").strip().lower()

            if eid:
                if ist_geschuetzt:
                    known[eid] = "(geschuetzt)"
                    geschuetzt_count += 1
                elif ist_rot:
                    # Rot: Scraper legt keinen neuen Eintrag an (Duplikat-Schutz),
                    # aber die echte page_id bleibt gespeichert damit ein
                    # Entfall-Edikt die Seite archivieren kann.
                    known[eid] = page["id"]
                    geschuetzt_count += 1
                else:
                    known[eid] = page["id"]

            # Eintr√§ge OHNE Hash-ID aber MIT fortgeschrittener Phase:
            # Titel als Ersatz-Fingerprint speichern (verhindert Doppelanlage
            # bei manuell eingetragenen Immobilien ohne Hash-ID)
            elif ist_geschuetzt or ist_rot:
                title_rt = props.get("Liegenschaftsadresse", {}).get("title", [])
                title = title_rt[0].get("plain_text", "").strip().lower() if title_rt else ""
                if title:
                    # Gr√ºn/Gelb/Phase ‚Üí Sentinel; Rot ‚Üí echte ID damit Entfall immer greift
                    known[f"__titel__{title}"] = "(geschuetzt)" if ist_geschuetzt else page["id"]
                    geschuetzt_count += 1
                    # (Rot: echte ID gespeichert ‚Üí Duplikat-Schutz trotzdem aktiv,
                    #  da 'elif eid not in known_ids' bei bekannter UUID nicht greift)

            page_count += 1

        has_more = resp.get("has_more", False)
        cursor   = resp.get("next_cursor")

    print(f"[Notion] ‚úÖ {len(known)} Eintr√§ge geladen "
          f"({geschuetzt_count} gesch√ºtzt, {page_count} Seiten gepr√ºft)")
    return known


def notion_load_all_pages(notion: Client, db_id: str) -> list[dict]:
    """
    L√§dt ALLE Pages aus der Notion-DB in einem einzigen Durchlauf.
    Gibt eine Liste aller Page-Objekte (mit Properties) zur√ºck.

    Wird von Status-Sync, Bereinigung, Tote-URLs und Qualit√§ts-Check
    gemeinsam genutzt um mehrfache DB-Scans zu vermeiden.
    """
    print("[Notion] üì• Lade alle Pages f√ºr Cleanup-Schritte ‚Ä¶")
    pages: list[dict] = []
    has_more     = True
    start_cursor = None

    while has_more:
        kwargs: dict = {
            "filter": {"value": "page", "property": "object"},
            "page_size": 100,
        }
        if start_cursor:
            kwargs["start_cursor"] = start_cursor
        try:
            resp = notion.search(**kwargs)
        except Exception as exc:
            print(f"  [Notion] ‚ö†Ô∏è  Fehler beim Laden der Pages: {exc}")
            break

        for page in resp.get("results", []):
            parent = page.get("parent", {})
            if parent.get("database_id", "").replace("-", "") != db_id.replace("-", ""):
                continue
            pages.append(page)

        has_more     = resp.get("has_more", False)
        start_cursor = resp.get("next_cursor")

    print(f"[Notion] ‚úÖ {len(pages)} Pages geladen")
    return pages


def notion_create_eintrag(notion: Client, db_id: str, data: dict) -> dict:
    """
    Legt einen neuen Eintrag in Notion an.
    Ruft die Detailseite ab, filtert nach Kategorie und bef√ºllt alle Felder.
    Gibt den detail-Dict zur√ºck (oder {} wenn Objekt gefiltert wurde).
    R√ºckgabe None bedeutet: Objekt wurde durch Kategorie-Filter ausgeschlossen.
    """
    bundesland   = data.get("bundesland", "Unbekannt")
    link         = data.get("link", "")
    edikt_id     = data.get("edikt_id", "")
    beschreibung = data.get("beschreibung", "")
    typ          = data.get("type", "Versteigerung")

    # ‚îÄ‚îÄ Detailseite abrufen ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    detail: dict = {}
    if link:
        detail = fetch_detail(link)

    # ‚îÄ‚îÄ Kategorie-Filter (auf Detailseite, zuverl√§ssiger als Link-Text) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    kategorie = detail.get("kategorie", "")
    if kategorie and is_excluded_by_kategorie(kategorie):
        print(f"  [Filter] ‚õî Kategorie ausgeschlossen: '{kategorie}' ({edikt_id[:8]}‚Ä¶)")
        return None  # Signalisiert: nicht importieren

    # ‚îÄ‚îÄ Liegenschaftsadresse als Titel ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    adresse_voll = detail.get("adresse_voll", "")
    if not adresse_voll:
        datum_m = re.search(r"\((\d{2}\.\d{2}\.\d{4})\)", beschreibung)
        adresse_voll = f"{bundesland} ‚Äì {datum_m.group(1) if datum_m else beschreibung[:60]}"

    titel    = adresse_voll
    objektart = kategorie or beschreibung[:200]

    # ‚îÄ‚îÄ Kern-Properties (existieren garantiert in jeder Notion-DB) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    properties: dict = {
        "Liegenschaftsadresse": {
            "title": [{"text": {"content": titel[:200]}}]
        },
        "Hash-ID / Vergleichs-ID": {
            "rich_text": [{"text": {"content": edikt_id}}]
        },
        "Link": {"url": link},
        "Art des Edikts": {
            "select": {
                "name": typ if typ in ("Versteigerung", "Entfall des Termins") else "Versteigerung"
            }
        },
        "Bundesland":              {"select": {"name": bundesland}},
        "Neu eingelangt":          {"checkbox": True},
        "Automatisch importiert?": {"checkbox": True},
        "Workflow-Phase":          {"select": {"name": "üÜï Neu eingelangt"}},
        "Objektart": {
            "rich_text": [{"text": {"content": objektart[:200]}}]
        },
    }

    # ‚îÄ‚îÄ Optionale Properties ‚Äì werden einzeln hinzugef√ºgt ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # Schl√§gt ein Feld fehl, wird nur dieses Feld √ºbersprungen, nicht der ganze Eintrag.

    verkehrswert = detail.get("schaetzwert")
    if verkehrswert is not None:
        vk_str = f"{verkehrswert:,.2f} ‚Ç¨".replace(",", "X").replace(".", ",").replace("X", ".")
        properties["Verkehrswert"] = {"rich_text": [{"text": {"content": vk_str}}]}

    termin_iso = detail.get("termin_iso")
    if termin_iso:
        properties["Versteigerungstermin"] = {"date": {"start": termin_iso}}

    # HINWEIS: "Verpflichtende Partei" wird NICHT hier bef√ºllt ‚Äì
    # der Gerichtsname (gericht) ist NICHT der Eigent√ºmer.
    # Dieses Feld wird ausschlie√ülich durch gutachten_enrich_notion_page
    # aus dem Gutachten-PDF extrahiert und eingetragen.

    plz_ort = detail.get("plz_ort", "")
    if plz_ort:
        # Vollst√§ndig: "1120 Wien" ‚Üí "1120 Wien"
        properties[NOTION_PLZ_FIELD] = {
            "rich_text": [{"text": {"content": plz_ort.strip()[:100]}}]
        }

    flaeche = detail.get("flaeche_objekt") or detail.get("flaeche_grundstueck")
    if flaeche is not None:
        flaeche_str = f"{flaeche:,.2f} m¬≤".replace(",", "X").replace(".", ",").replace("X", ".")
        properties["Fl√§che"] = {"rich_text": [{"text": {"content": flaeche_str}}]}

    # ‚îÄ‚îÄ Seite anlegen ‚Äì erst Kern, dann optionale Felder einzeln ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # Strategie: Kern-Properties zuerst. Falls optionale Felder nicht existieren,
    # werden sie weggelassen und der Eintrag trotzdem angelegt.
    created_page = None
    try:
        created_page = notion.pages.create(parent={"database_id": db_id}, properties=properties)
        print(f"  [Notion] ‚úÖ Erstellt: {titel[:80]}")
    except Exception as e:
        err_str = str(e)
        # Herausfinden welches Feld das Problem ist und es entfernen
        optional_fields = [NOTION_PLZ_FIELD, "Fl√§che", "Verkehrswert",
                           "Versteigerungstermin", "Verpflichtende Partei"]
        removed = []
        for field in optional_fields:
            if field in err_str and field in properties:
                del properties[field]
                removed.append(field)

        if removed:
            print(f"  [Notion] ‚ö†Ô∏è  Felder nicht gefunden, √ºbersprungen: {removed}")
            try:
                created_page = notion.pages.create(parent={"database_id": db_id}, properties=properties)
                print(f"  [Notion] ‚úÖ Erstellt (ohne {removed}): {titel[:80]}")
            except Exception as e2:
                raise e2  # Wirklicher Fehler ‚Üí nach oben weitergeben
        else:
            raise  # Kein bekanntes optionales Feld ‚Üí nach oben weitergeben

    # Gibt (detail, page_id) zur√ºck damit der Aufrufer das Gutachten anreichern kann
    new_page_id = created_page["id"] if created_page else None
    return detail, new_page_id


def notion_mark_entfall(notion: Client, page_id: str, item: dict) -> None:
    """
    Markiert ein bestehendes Notion-Objekt als 'Termin entfallen'.

    Verhalten je nach aktuellem Status/Phase:

    üü¢ Gr√ºn / üü° Gelb  ‚Üí Entfall nur vermerken, NICHT archivieren
                          (Immobilie ist relevant / gekauft / in Bearbeitung)

    üî¥ Rot              ‚Üí IMMER archivieren, egal welche Phase
                          (Rot = manuell abgelehnt/abgebrochen, auch in sp√§teren Phasen)

    Bereits archiviert  ‚Üí Nur Art des Edikts aktualisieren (bleibt im Archiv)

    Fortgeschrittene    ‚Üí Nur Entfall vermerken, Phase bleibt erhalten
    Workflow-Phase      (gilt nur wenn Status NICHT Rot ist)

    Unbearbeitet        ‚Üí Normal archivieren
    """
    # Phasen die NICHT auto-archiviert werden (manuell in Bearbeitung)
    # Gilt NUR wenn Status != üî¥ Rot
    SCHUTZ_PHASEN = {
        "üîé In Pr√ºfung",
        "‚úÖ Relevant ‚Äì Brief vorbereiten",
        "üì© Brief versendet",
        "üìä Gutachten analysiert",
    }

    # Aktuellen Zustand der Seite lesen
    try:
        page = notion.pages.retrieve(page_id=page_id)
        props = page.get("properties", {})
        phase    = (props.get("Workflow-Phase", {}).get("select") or {}).get("name", "")
        status   = (props.get("Status", {}).get("select") or {}).get("name", "")
        archiviert = props.get("Archiviert", {}).get("checkbox", False)
    except Exception as exc:
        print(f"  [Notion] ‚ö†Ô∏è  Entfall: Seite konnte nicht gelesen werden: {exc}")
        return

    eid = item.get('edikt_id', '?')

    # Fall 1: Bereits archiviert ‚Üí nur Art des Edikts anpassen, sonst nichts
    if archiviert:
        notion.pages.update(
            page_id=page_id,
            properties={
                "Art des Edikts": {"select": {"name": "Entfall des Termins"}},
            },
        )
        print(f"  [Notion] üóÑ  Entfall im Archiv vermerkt: {eid}")
        return

    # Fall 2: Status Rot ‚Üí IMMER archivieren (egal welche Phase)
    # Rot = manuell abgelehnt/abgebrochen; Phase bleibt erhalten damit
    # man sp√§ter sehen kann in welcher Phase der Abbruch erfolgte.
    if status == "üî¥ Rot":
        notion.pages.update(
            page_id=page_id,
            properties={
                "Art des Edikts": {"select": {"name": "Entfall des Termins"}},
                "Archiviert":     {"checkbox": True},
                # Workflow-Phase NICHT √ºberschreiben ‚Üí bleibt erhalten,
                # damit sichtbar ist in welcher Phase der Abbruch erfolgte
                "Neu eingelangt": {"checkbox": False},
            },
        )
        print(f"  [Notion] üî¥ Entfall archiviert (Status Rot, Phase '{phase}' bleibt erhalten): {eid}")
        return

    # Fall 3: Status Gr√ºn oder Gelb ‚Üí relevant/aktiv in Bearbeitung ‚Üí NUR vermerken
    if status in ("üü¢ Gr√ºn", "üü° Gelb"):
        notion.pages.update(
            page_id=page_id,
            properties={
                "Art des Edikts": {"select": {"name": "Entfall des Termins"}},
                "Neu eingelangt": {"checkbox": False},
            },
        )
        print(f"  [Notion] üîí Entfall vermerkt (Status {status} ‚Äì kein Auto-Archiv): {eid}")
        return

    # Fall 4: Fortgeschrittene Phase ohne Status ‚Üí nur vermerken
    if phase in SCHUTZ_PHASEN:
        notion.pages.update(
            page_id=page_id,
            properties={
                "Art des Edikts": {"select": {"name": "Entfall des Termins"}},
                "Neu eingelangt": {"checkbox": False},
            },
        )
        print(f"  [Notion] üîí Entfall vermerkt (Phase '{phase}' ‚Äì kein Auto-Archiv): {eid}")
        return

    # Fall 5: Unbearbeitet (Neu eingelangt / kein Status) ‚Üí normal archivieren
    notion.pages.update(
        page_id=page_id,
        properties={
            "Art des Edikts": {"select": {"name": "Entfall des Termins"}},
            "Archiviert":     {"checkbox": True},
            "Workflow-Phase": {"select": {"name": "üóÑ Archiviert"}},
            "Neu eingelangt": {"checkbox": False},
        },
    )
    print(f"  [Notion] üî¥ Entfall archiviert: {eid}")


def notion_enrich_urls(notion: Client, db_id: str) -> int:
    """
    Findet Notion-Eintr√§ge OHNE Link-URL und versucht, √ºber die Edikte-Suche
    einen passenden Eintrag zu finden.

    Strategie:
    1. Alle Pages aus der DB via search() laden.
    2. Falls die Seite eine Hash-ID hat ‚Üí Link direkt konstruieren.
    3. Falls nicht ‚Üí √ºber Titel / Bundesland eine Freitextsuche machen.

    Gibt die Anzahl der erfolgreich erg√§nzten URLs zur√ºck.
    """
    print("\n[URL-Anreicherung] üîó Suche nach Eintr√§gen ohne URL ‚Ä¶")

    enriched = 0

    # Alle Seiten via search() laden (notion-client v3 hat kein databases.query)
    pages_without_url: list[dict] = []
    has_more = True
    start_cursor = None

    while has_more:
        kwargs: dict = {
            "filter": {"value": "page", "property": "object"},
            "page_size": 100,
        }
        if start_cursor:
            kwargs["start_cursor"] = start_cursor

        try:
            resp = notion.search(**kwargs)
        except Exception as exc:
            print(f"  [URL-Anreicherung] ‚ùå Notion-Abfrage fehlgeschlagen: {exc}")
            break

        for page in resp.get("results", []):
            # Nur Pages aus unserer DB
            parent = page.get("parent", {})
            if parent.get("database_id", "").replace("-", "") != db_id.replace("-", ""):
                continue
            # Nur Pages ohne Link
            props    = page.get("properties", {})
            link_val = props.get("Link", {}).get("url")
            if not link_val:
                pages_without_url.append(page)

        has_more = resp.get("has_more", False)
        start_cursor = resp.get("next_cursor")

    print(f"  [URL-Anreicherung] üìã {len(pages_without_url)} Eintr√§ge ohne URL gefunden")

    for page in pages_without_url:
        page_id = page["id"]
        props   = page.get("properties", {})

        # Hash-ID vorhanden? ‚Üí Link direkt bauen
        hash_rt = props.get("Hash-ID / Vergleichs-ID", {}).get("rich_text", [])
        if hash_rt:
            edikt_id = hash_rt[0].get("plain_text", "").strip()
            if edikt_id and re.fullmatch(r"[0-9a-f]{32}", edikt_id):
                constructed_link = (
                    f"{BASE_URL}/edikte/ex/exedi3.nsf/alldoc/{edikt_id}!OpenDocument"
                )
                try:
                    notion.pages.update(
                        page_id=page_id,
                        properties={"Link": {"url": constructed_link}},
                    )
                    enriched += 1
                    print(f"  [URL-Anreicherung] ‚úÖ Link gesetzt (Hash-ID): {edikt_id}")
                except Exception as exc:
                    print(f"  [URL-Anreicherung] ‚ùå Update fehlgeschlagen ({edikt_id}): {exc}")
                continue

        # Kein Hash-ID ‚Üí Titel-Suche auf edikte.at
        title_rt = props.get("Liegenschaftsadresse", {}).get("title", [])
        titel = title_rt[0].get("plain_text", "") if title_rt else ""

        bl_prop = props.get("Bundesland", {}).get("select") or {}
        bundesland_name = bl_prop.get("name", "")
        bl_value = BUNDESLAENDER.get(bundesland_name, "")

        if not titel and not bl_value:
            print(f"  [URL-Anreicherung] ‚ö†Ô∏è  Kein Titel/Bundesland f√ºr {page_id[:8]}‚Ä¶")
            continue

        # Suche f√ºr das Bundesland + Keyword aus dem Titel
        keyword = re.sub(r"(Wien|Nieder√∂sterreich|Burgenland|Ober√∂sterreich|Salzburg|"
                         r"Steiermark|K√§rnten|Tirol|Vorarlberg)", "", titel).strip()
        keyword = keyword[:40] if keyword else ""

        matches = _search_edikt_by_keyword(bl_value, keyword)
        if len(matches) == 1:
            candidate = matches[0]
            try:
                notion.pages.update(
                    page_id=page_id,
                    properties={
                        "Link": {"url": candidate["link"]},
                        "Hash-ID / Vergleichs-ID": {
                            "rich_text": [{"text": {"content": candidate["edikt_id"]}}]
                        },
                    },
                )
                enriched += 1
                print(
                    f"  [URL-Anreicherung] ‚úÖ Link gefunden (Freitext): "
                    f"{candidate['edikt_id']}"
                )
            except Exception as exc:
                print(f"  [URL-Anreicherung] ‚ùå Update fehlgeschlagen: {exc}")
        elif len(matches) == 0:
            print(f"  [URL-Anreicherung] üîç Kein Treffer f√ºr '{titel[:50]}'")
        else:
            print(
                f"  [URL-Anreicherung] ‚ùì {len(matches)} Treffer (mehrdeutig) "
                f"f√ºr '{titel[:50]}' ‚Äì √ºbersprungen"
            )

    print(f"[URL-Anreicherung] ‚úÖ {enriched} URLs erg√§nzt")
    return enriched


def _search_edikt_by_keyword(bl_value: str, keyword: str) -> list[dict]:
    """
    Interne Hilfsfunktion: Sucht auf edikte.at f√ºr ein Bundesland mit einem
    Freitext-Keyword und gibt die gefundenen Items zur√ºck.
    """
    if not bl_value:
        return []

    query_parts = [f"([BL]=({bl_value}))"]
    if keyword:
        query_parts.append(keyword)

    params = urllib.parse.urlencode({
        "SearchView": "",
        "subf": "eex",
        "SearchOrder": "4",
        "SearchMax": "50",
        "retfields": f"~BL={bl_value}",
        "ftquery": keyword,
        "query": " ".join(query_parts),
    })
    url = f"{BASE_URL}/edikte/ex/exedi3.nsf/suchedi?{params}"

    try:
        req = urllib.request.Request(
            url,
            headers={"User-Agent": "Mozilla/5.0 (compatible; EdikteMonitor/1.0)"}
        )
        with urllib.request.urlopen(req, timeout=20) as r:
            html = r.read().decode("utf-8", errors="replace")
    except Exception:
        return []

    rel_pattern = re.compile(
        r'<a[^>]+href="(alldoc/([0-9a-f]+)!OpenDocument)"[^>]*>([^<]+)</a>',
        re.IGNORECASE
    )

    results = []
    for href_rel, edikt_id, link_text in rel_pattern.findall(html):
        link_text = link_text.strip()
        if not any(link_text.startswith(t) for t in RELEVANT_TYPES):
            continue
        results.append({
            "edikt_id": edikt_id.lower(),
            "link": f"{BASE_URL}/edikte/ex/exedi3.nsf/{href_rel}",
            "beschreibung": link_text,
        })
    return results


def notion_enrich_gutachten(notion: Client, db_id: str) -> int:
    """
    Findet alle Notion-Eintr√§ge die:
      - eine URL (Link) haben, UND
      - 'Gutachten analysiert?' = False / nicht gesetzt haben, UND
      - NICHT in einer gesch√ºtzten Workflow-Phase sind

    F√ºr jeden solchen Eintrag wird das Gutachten-PDF heruntergeladen
    und die Properties (Eigent√ºmer, Adresse, Gl√§ubiger, Forderung) bef√ºllt.

    Das ist der Weg f√ºr manuell eingetragene Immobilien:
    Sobald die URL gesetzt wird (entweder vom Nutzer oder durch URL-Anreicherung),
    wird das Gutachten automatisch beim n√§chsten Lauf analysiert.

    Gibt die Anzahl der erfolgreich angereicherten Eintr√§ge zur√ºck.
    """
    GESCHUETZT_PHASEN = {
        "üîé In Pr√ºfung",
        "‚ùå Nicht relevant",
        "‚úÖ Relevant ‚Äì Brief vorbereiten",
        "üì© Brief versendet",
        "üìä Gutachten analysiert",
        "‚úÖ Gekauft",
        "üóÑ Archiviert",
    }

    print("\n[Gutachten-Anreicherung] üìÑ Suche nach Eintr√§gen ohne Gutachten-Analyse ‚Ä¶")

    to_enrich: list[dict] = []
    has_more     = True
    start_cursor = None

    while has_more:
        kwargs: dict = {
            "filter": {"value": "page", "property": "object"},
            "page_size": 100,
        }
        if start_cursor:
            kwargs["start_cursor"] = start_cursor

        try:
            resp = notion.search(**kwargs)
        except Exception as exc:
            print(f"  [Gutachten-Anreicherung] ‚ùå Notion-Abfrage fehlgeschlagen: {exc}")
            break

        for page in resp.get("results", []):
            parent = page.get("parent", {})
            if parent.get("database_id", "").replace("-", "") != db_id.replace("-", ""):
                continue

            props = page.get("properties", {})

            # Nur Eintr√§ge in nicht-gesch√ºtzter Phase
            phase = (props.get("Workflow-Phase", {}).get("select") or {}).get("name", "")
            if phase in GESCHUETZT_PHASEN:
                continue

            # Muss eine URL haben
            link_val = props.get("Link", {}).get("url")
            if not link_val:
                continue

            # Noch nicht analysiert
            analysiert = props.get("Gutachten analysiert?", {}).get("checkbox", False)
            if analysiert:
                continue

            to_enrich.append({"page_id": page["id"], "link": link_val})

        has_more     = resp.get("has_more", False)
        start_cursor = resp.get("next_cursor")

    MAX_PER_RUN = 100  # Begrenzung: max. 100 PDFs pro Run (~15‚Äì20 Min. Laufzeit)
    total_found = len(to_enrich)
    if total_found > MAX_PER_RUN:
        print(f"  [Gutachten-Anreicherung] ‚ö†Ô∏è  {total_found} gefunden ‚Äì verarbeite nur die ersten {MAX_PER_RUN} (Rest beim n√§chsten Run)")
        to_enrich = to_enrich[:MAX_PER_RUN]

    print(f"  [Gutachten-Anreicherung] üìã {len(to_enrich)} Eintr√§ge werden jetzt analysiert")

    enriched = 0
    for entry in to_enrich:
        try:
            ok = gutachten_enrich_notion_page(notion, entry["page_id"], entry["link"])
            if ok:
                enriched += 1
        except Exception as exc:
            print(f"  [Gutachten-Anreicherung] ‚ùå Fehler f√ºr {entry['page_id'][:8]}‚Ä¶: {exc}")
        time.sleep(0.3)   # kurze Pause um API-Limits zu schonen

    remaining = total_found - len(to_enrich)
    if remaining > 0:
        print(f"  [Gutachten-Anreicherung] ‚ÑπÔ∏è  Noch {remaining} Eintr√§ge offen ‚Äì werden in n√§chsten Runs verarbeitet")
    print(f"[Gutachten-Anreicherung] ‚úÖ {enriched} Gutachten analysiert")
    return enriched


def notion_reset_falsche_verpflichtende(notion: Client, db_id: str,
                                       all_pages: list[dict] | None = None) -> int:
    """
    Einmalige Bereinigung: Findet Eintr√§ge deren 'Verpflichtende Partei'
    einen Gerichtsnamen enth√§lt (z.B. "BG Schwaz (870)", "BG Innere Stadt Wien (001)").

    Diese Eintr√§ge wurden irrt√ºmlich mit dem Gericht statt dem Eigent√ºmer bef√ºllt.

    Aktion:
      - 'Verpflichtende Partei' ‚Üí leer
      - 'Gutachten analysiert?'  ‚Üí False  (damit der n√§chste Run sie neu verarbeitet)

    Gibt die Anzahl der bereinigten Eintr√§ge zur√ºck.
    """
    GESCHUETZT_PHASEN = {
        "üîé In Pr√ºfung",
        "‚ùå Nicht relevant",
        "‚úÖ Relevant ‚Äì Brief vorbereiten",
        "üì© Brief versendet",
        "üìä Gutachten analysiert",
        "‚úÖ Gekauft",
        "üóÑ Archiviert",
    }

    # Gerichts-Muster: "BG Irgendwas (123)" oder "BG Irgendwas"
    GERICHT_RE = re.compile(
        r'^(BG |Bezirksgericht |LG |Landesgericht |HG |Handelsgericht )',
        re.IGNORECASE
    )

    print("\n[Bereinigung] üîß Suche nach Eintr√§gen mit falschem Gericht in 'Verpflichtende Partei' ‚Ä¶")

    pages = all_pages if all_pages is not None else notion_load_all_pages(notion, db_id)
    to_fix: list[str] = []

    for page in pages:
        props = page.get("properties", {})

        # Gesch√ºtzte Phasen auslassen
        phase = (props.get("Workflow-Phase", {}).get("select") or {}).get("name", "")
        if phase in GESCHUETZT_PHASEN:
            continue

        # 'Verpflichtende Partei' lesen
        vp_rt = props.get("Verpflichtende Partei", {}).get("rich_text", [])
        vp_text = "".join(t.get("text", {}).get("content", "") for t in vp_rt).strip()

        if not vp_text:
            continue

        # Enth√§lt der Wert einen Gerichtsnamen?
        if GERICHT_RE.match(vp_text):
            to_fix.append(page["id"])


    # Zweiter Pass: Eintr√§ge mit analysiert?=True aber OHNE Adresse ‚Üí neu analysieren
    # NUR einmalig: dieser Pass wird NICHT wiederholt wenn das PDF gescannt ist.
    # Erkennungskriterium: Notizen enth√§lt bereits "Kein PDF" oder "gescannt"
    # ‚Üí diese werden NICHT zur√ºckgesetzt (sonst Endlosschleife)
    to_reanalyze: list[str] = []
    for page in pages:  # 'pages' wurde oben bereits geladen (all_pages oder eigener Scan)
        props = page.get("properties", {})
        phase = (props.get("Workflow-Phase", {}).get("select") or {}).get("name", "")
        if phase in GESCHUETZT_PHASEN:
            continue
        # Nur Eintr√§ge die bereits als analysiert markiert sind
        analysiert = props.get("Gutachten analysiert?", {}).get("checkbox", False)
        if not analysiert:
            continue
        # Aber OHNE Zustelladresse
        adr_rt = props.get("Zustell Adresse", {}).get("rich_text", [])
        adr_text = "".join(t.get("text", {}).get("content", "") for t in adr_rt).strip()
        if not adr_text:
            # STOPP: wenn Notizen bereits "Kein PDF" oder √§hnliches enthalten
            # ‚Üí das PDF ist gescannt/nicht lesbar ‚Üí NICHT nochmal versuchen
            notiz_rt = props.get("Notizen", {}).get("rich_text", [])
            notiz_text = "".join(t.get("text", {}).get("content", "") for t in notiz_rt).strip()
            if any(marker in notiz_text for marker in (
                "Kein PDF", "gescannt", "nicht lesbar", "kein Eigent√ºmer"
            )):
                continue  # gescanntes Dokument ‚Üí kein Reset, verhindert Endlosschleife
            # Nur zur√ºcksetzen wenn ein Link vorhanden (sonst kein PDF zum analysieren)
            link_rt = props.get("Link", {}).get("url") or ""
            if link_rt and page["id"] not in to_fix:
                to_reanalyze.append(page["id"])

    if to_reanalyze:
        print(f"  [Bereinigung] üîÑ {len(to_reanalyze)} analysierte Eintr√§ge ohne Adresse ‚Üí werden neu analysiert ‚Ä¶")
        for page_id in to_reanalyze:
            try:
                notion.pages.update(
                    page_id=page_id,
                    properties={"Gutachten analysiert?": {"checkbox": False}}
                )
            except Exception as exc:
                print(f"  [Bereinigung] ‚ö†Ô∏è  Fehler f√ºr {page_id[:8]}‚Ä¶: {exc}")
            time.sleep(0.2)

    if not to_fix and not to_reanalyze:
        print("  [Bereinigung] ‚úÖ Keine falschen Eintr√§ge gefunden ‚Äì alles in Ordnung")
        return 0

    print(f"  [Bereinigung] üîß {len(to_fix)} Eintr√§ge mit Gerichtsname gefunden ‚Äì werden bereinigt ‚Ä¶")

    fixed = 0
    for page_id in to_fix:
        try:
            notion.pages.update(
                page_id=page_id,
                properties={
                    "Verpflichtende Partei": {"rich_text": []},
                    "Gutachten analysiert?": {"checkbox": False},
                }
            )
            fixed += 1
        except Exception as exc:
            print(f"  [Bereinigung] ‚ö†Ô∏è  Fehler f√ºr {page_id[:8]}‚Ä¶: {exc}")
        time.sleep(0.2)

    print(f"[Bereinigung] ‚úÖ {fixed} Gerichtsname-Eintr√§ge + {len(to_reanalyze)} adresslose Eintr√§ge zur√ºckgesetzt")
    return fixed + len(to_reanalyze)


# =============================================================================
# STATUS-SYNC ‚Äì Status (Rot/Gelb/Gr√ºn) ‚Üí Phase + Checkboxen automatisch setzen
# =============================================================================

def notion_status_sync(notion: Client, db_id: str,
                        all_pages: list[dict] | None = None) -> int:
    """
    Synchronisiert zwei manuelle Felder ‚Üí Workflow-Phase + Checkboxen.

    ‚îÄ‚îÄ Quelle 1: Status-Farbe ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      üî¥ Rot  ‚Üí Phase: '‚ùå Nicht relevant', Neu eingelangt: False,
                Relevanz gepr√ºft?: True, Archiviert: True
      üü° Gelb ‚Üí Phase: 'üîé In Pr√ºfung',   Neu eingelangt: False
      üü¢ Gr√ºn ‚Üí Phase: '‚úÖ Gekauft',       Neu eingelangt: False

    ‚îÄ‚îÄ Quelle 2: 'F√ºr uns relevant?' (Select) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      Ja         ‚Üí Phase: '‚úÖ Relevant ‚Äì Brief vorbereiten',
                   Relevanz gepr√ºft?: True, Neu eingelangt: False
      Nein       ‚Üí Phase: '‚ùå Nicht relevant', Status: üî¥ Rot,
                   Relevanz gepr√ºft?: True, Neu eingelangt: False, Archiviert: True
      Beobachten ‚Üí Phase: 'üîé In Pr√ºfung',
                   Relevanz gepr√ºft?: True, Neu eingelangt: False

    all_pages: vorgeladene Pages (von notion_load_all_pages). Falls None,
               wird ein eigener Scan durchgef√ºhrt.
    Gibt die Anzahl aktualisierter Eintr√§ge zur√ºck.
    """

    # Erwartete Phase je Status-Farbe
    STATUS_SOLL_PHASE = {
        "üî¥ Rot":  "‚ùå Nicht relevant",
        "üü° Gelb": "üîé In Pr√ºfung",
        "üü¢ Gr√ºn": "‚úÖ Gekauft",
    }

    # Erwartete Phase je 'F√ºr uns relevant?'-Wert
    RELEVANT_SOLL_PHASE = {
        "Ja":         "‚úÖ Relevant ‚Äì Brief vorbereiten",
        "Nein":       "‚ùå Nicht relevant",
        "Beobachten": "üîé In Pr√ºfung",
    }

    print("\n[Status-Sync] üîÑ Pr√ºfe Status + Relevanz ‚Üí Phase ‚Ä¶")

    pages = all_pages if all_pages is not None else notion_load_all_pages(notion, db_id)
    to_update: list[dict] = []

    for page in pages:
        if True:  # Einr√ºckung beibehalten
            props     = page.get("properties", {})
            status    = (props.get("Status", {}).get("select") or {}).get("name", "")
            relevant  = (props.get("F√ºr uns relevant?", {}).get("select") or {}).get("name", "")
            phase_ist = (props.get("Workflow-Phase", {}).get("select") or {}).get("name", "")

            update_props: dict = {}

            # ‚îÄ‚îÄ Quelle 2: 'F√ºr uns relevant?' hat Vorrang vor Status-Farbe ‚îÄ‚îÄ
            if relevant in RELEVANT_SOLL_PHASE:
                phase_soll = RELEVANT_SOLL_PHASE[relevant]

                # Immer: Relevanz gepr√ºft + Neu eingelangt
                update_props["Relevanz gepr√ºft?"] = {"checkbox": True}
                update_props["Neu eingelangt"]   = {"checkbox": False}

                # Phase nur setzen wenn noch nicht korrekt
                if phase_ist != phase_soll:
                    update_props["Workflow-Phase"] = {"select": {"name": phase_soll}}

                # Bei Nein: zus√§tzlich Status Rot + Archiviert
                if relevant == "Nein":
                    update_props["Status"]    = {"select": {"name": "üî¥ Rot"}}
                    update_props["Archiviert"] = {"checkbox": True}

            # ‚îÄ‚îÄ Quelle 1: Status-Farbe (nur wenn kein Relevanz-Wert gesetzt) ‚îÄ
            elif status in STATUS_SOLL_PHASE:
                phase_soll = STATUS_SOLL_PHASE[status]

                if phase_ist != phase_soll:
                    update_props["Workflow-Phase"] = {"select": {"name": phase_soll}}

                update_props["Neu eingelangt"] = {"checkbox": False}

                if status == "üî¥ Rot":
                    update_props["Relevanz gepr√ºft?"] = {"checkbox": True}
                    update_props["Archiviert"]        = {"checkbox": True}

            # Keine relevanten Felder gesetzt ‚Üí √ºberspringen
            if not update_props:
                continue

            # Bereits alles korrekt ‚Üí √ºberspringen (nur Phase-Check reicht nicht,
            # da Checkboxen evtl. noch falsch sind ‚Äì daher immer in Queue)
            to_update.append({
                "page_id":      page["id"],
                "update_props": update_props,
                "label":        f"relevant={relevant or '‚Äì'} status={status or '‚Äì'} ‚Üí phase={update_props.get('Workflow-Phase', {}).get('select', {}).get('name', phase_ist)}",
            })

    print(f"  [Status-Sync] üìã {len(to_update)} Eintr√§ge werden synchronisiert")

    updated = 0
    for entry in to_update:
        try:
            notion.pages.update(page_id=entry["page_id"], properties=entry["update_props"])
            print(f"  [Status-Sync] ‚úÖ {entry['label']}")
            updated += 1
        except Exception as exc:
            print(f"  [Status-Sync] ‚ö†Ô∏è  Update fehlgeschlagen: {exc}")
        time.sleep(0.2)

    print(f"[Status-Sync] ‚úÖ {updated} Eintr√§ge synchronisiert")
    return updated


# =============================================================================
# SCHRITT 1: QUALIT√ÑTS-CHECK ‚Äì alle analysierten Eintr√§ge auf Vollst√§ndigkeit
# =============================================================================

def notion_qualitaetscheck(notion: Client, db_id: str,
                           all_pages: list[dict] | None = None) -> int:
    """
    Geht alle Eintr√§ge durch die bereits als 'Gutachten analysiert?' = True
    markiert sind, aber eines oder mehrere dieser Felder LEER haben:
      - Verpflichtende Partei (Eigent√ºmer)
      - Zustell Adresse
      - Betreibende Partei (Gl√§ubiger)

    Solche Eintr√§ge werden zur√ºckgesetzt (analysiert? = False) damit
    notion_enrich_gutachten sie beim n√§chsten Schritt neu analysiert.

    Eintr√§ge mit 'gescanntes Dokument' oder 'Kein PDF' im Notizen-Feld
    werden NICHT zur√ºckgesetzt (da kein PDF vorhanden bzw. nicht lesbar).

    Gibt die Anzahl zur√ºckgesetzter Eintr√§ge zur√ºck.
    """
    GESCHUETZT_PHASEN = {
        "üîé In Pr√ºfung",
        "‚ùå Nicht relevant",
        "‚úÖ Relevant ‚Äì Brief vorbereiten",
        "üì© Brief versendet",
        "üìä Gutachten analysiert",
        "‚úÖ Gekauft",
        "üóÑ Archiviert",
    }

    print("\n[Qualit√§ts-Check] üîç Pr√ºfe alle analysierten Eintr√§ge auf Vollst√§ndigkeit ‚Ä¶")

    pages = all_pages if all_pages is not None else notion_load_all_pages(notion, db_id)
    to_reset: list[str] = []
    total_checked = 0

    for page in pages:
        if True:
            props = page.get("properties", {})

            # Nur analysierte Eintr√§ge
            analysiert = props.get("Gutachten analysiert?", {}).get("checkbox", False)
            if not analysiert:
                continue

            # Gesch√ºtzte Phasen √ºberspringen
            phase = (props.get("Workflow-Phase", {}).get("select") or {}).get("name", "")
            if phase in GESCHUETZT_PHASEN:
                continue

            # Archivierte √ºberspringen
            archiviert = props.get("Archiviert", {}).get("checkbox", False)
            if archiviert:
                continue

            # Muss eine URL haben (sonst gibt es nichts zu analysieren)
            link_val = props.get("Link", {}).get("url")
            if not link_val:
                continue

            total_checked += 1

            # Notizen pr√ºfen ‚Äì gescannte/fehlende PDFs nicht nochmal versuchen
            notizen_rt = props.get("Notizen", {}).get("rich_text", [])
            notizen_text = "".join(
                (b.get("text") or {}).get("content", "") for b in notizen_rt
            ).lower()
            if "gescannt" in notizen_text or "kein pdf" in notizen_text or "nicht lesbar" in notizen_text:
                continue

            # Felder pr√ºfen
            eigent√ºmer_rt = props.get("Verpflichtende Partei", {}).get("rich_text", [])
            eigent√ºmer    = "".join(
                (b.get("text") or {}).get("content", "") for b in eigent√ºmer_rt
            ).strip()

            adresse_rt = props.get("Zustell Adresse", {}).get("rich_text", [])
            adresse    = "".join(
                (b.get("text") or {}).get("content", "") for b in adresse_rt
            ).strip()

            gl√§ubiger_rt = props.get("Betreibende Partei", {}).get("rich_text", [])
            gl√§ubiger    = "".join(
                (b.get("text") or {}).get("content", "") for b in gl√§ubiger_rt
            ).strip()

            # Zur√ºcksetzen wenn Eigent√ºmer UND Adresse fehlen (beide leer)
            if not eigent√ºmer and not adresse:
                to_reset.append(page["id"])

    print(f"  [Qualit√§ts-Check] üìä {total_checked} analysierte Eintr√§ge gepr√ºft")
    print(f"  [Qualit√§ts-Check] üîÑ {len(to_reset)} unvollst√§ndige Eintr√§ge ‚Üí werden neu analysiert")

    reset_count = 0
    for page_id in to_reset:
        try:
            notion.pages.update(
                page_id=page_id,
                properties={"Gutachten analysiert?": {"checkbox": False}}
            )
            reset_count += 1
        except Exception as exc:
            print(f"  [Qualit√§ts-Check] ‚ö†Ô∏è  Reset fehlgeschlagen f√ºr {page_id[:8]}‚Ä¶: {exc}")
        time.sleep(0.15)

    print(f"[Qualit√§ts-Check] ‚úÖ {reset_count} Eintr√§ge zur√ºckgesetzt")
    return reset_count


# =============================================================================
# SCHRITT 2: VISION-ANALYSE ‚Äì gescannte PDFs mit GPT-4o-Vision
# =============================================================================

def gutachten_extract_info_vision(pdf_bytes: bytes, pdf_url: str) -> dict:
    """
    Analysiert ein gescanntes PDF (kein extrahierbarer Text) mit GPT-4o-Vision.
    Konvertiert die ersten 3 Seiten des PDFs in Bilder (base64) und sendet
    sie an die OpenAI Vision API.

    Gibt das gleiche Result-Dict zur√ºck wie gutachten_extract_info_llm.
    Gibt leeres Dict zur√ºck bei Fehler.
    """
    api_key = os.environ.get("OPENAI_API_KEY", "")
    if not api_key or not OPENAI_AVAILABLE:
        return {}
    if not FITZ_AVAILABLE:
        return {}

    import base64

    try:
        doc = fitz.open(stream=pdf_bytes, filetype="pdf")
    except Exception as exc:
        print(f"    [Vision] ‚ö†Ô∏è  PDF √∂ffnen fehlgeschlagen: {exc}")
        return {}

    # Erste 8 Seiten als Bilder rendern ‚Äì Eigent√ºmer steht oft erst auf Seite 4‚Äì8
    # 2.5x Zoom = ~190 DPI ‚Üí bessere Lesbarkeit f√ºr gescannte Dokumente
    images_b64: list[str] = []
    for page_num in range(min(8, len(doc))):
        try:
            page = doc[page_num]
            mat  = fitz.Matrix(2.5, 2.5)   # 2.5x Zoom = ~190 DPI
            pix  = page.get_pixmap(matrix=mat, colorspace=fitz.csRGB)
            img_bytes = pix.tobytes("jpeg", jpg_quality=80)
            images_b64.append(base64.b64encode(img_bytes).decode("utf-8"))
        except Exception as exc:
            print(f"    [Vision] ‚ö†Ô∏è  Seite {page_num+1} konnte nicht gerendert werden: {exc}")
            continue

    if not images_b64:
        print("    [Vision] ‚ö†Ô∏è  Keine Seiten gerendert")
        return {}

    prompt = """Du analysierst Bilder aus √∂sterreichischen Gerichts-Gutachten f√ºr Zwangsversteigerungen.
Es gibt zwei Dokumenttypen ‚Äì analysiere BEIDE:

1. Professionelles Gutachten (Wien-Stil): Enth√§lt Abschnitte 'Verpflichtete Partei' (= Eigent√ºmer) und 'Betreibende Partei' (= Gl√§ubiger).
2. Grundbuchauszug (K√§rnten-Stil): Enth√§lt Abschnitte '** B **' oder 'B-Blatt' (= Eigent√ºmer mit Anteilen) und '** C **' oder 'C-Blatt' (= Pfandrechte/Gl√§ubiger). Der Eigent√ºmer steht nach 'Eigentumsrecht' oder 'Anteil' in Sektion B.

Extrahiere genau diese Felder und antworte NUR mit validem JSON, ohne Erkl√§rungen:

{
  "eigent√ºmer_name": "Vollst√§ndiger Name des Immobilieneigent√ºmers. Nur der Name, keine Adresse, kein Geburtsdatum. Mehrere Eigent√ºmer mit ' | ' trennen.",
  "eigent√ºmer_adresse": "Stra√üe und Hausnummer des Eigent√ºmers (Wohnadresse f√ºr Briefversand, NICHT die Liegenschaftsadresse)",
  "eigent√ºmer_plz_ort": "PLZ und Ort des Eigent√ºmers, z.B. '1010 Wien'",
  "gl√§ubiger": ["Liste der betreibenden Banken/Gl√§ubiger. Nur echte Kreditgeber (Banken, Sparkassen, Raiffeisen etc.). KEINE Anw√§lte, Gerichte, WEG/EG/Hausverwaltungen."],
  "forderung_betrag": "Forderungsh√∂he falls angegeben, z.B. 'EUR 150.000'"
}

Wichtige Regeln:
- Sachverst√§ndige, Hilfskr√§fte des SV, Anw√§lte sind KEINE Eigent√ºmer
- WEG, EG, EGT, Eigent√ºmergemeinschaft sind KEINE Gl√§ubiger
- Wenn ein Feld nicht gefunden wird: null"""

    # Nachricht mit allen Seiten-Bildern zusammenbauen
    content: list[dict] = [{"type": "text", "text": "Analysiere dieses Gutachten:"}]
    for img_b64 in images_b64:
        content.append({
            "type": "image_url",
            "image_url": {
                "url": f"data:image/jpeg;base64,{img_b64}",
                "detail": "high"
            }
        })

    try:
        client   = _OpenAI(api_key=api_key)
        response = client.chat.completions.create(
            model="gpt-4o",            # Vision-f√§higes Modell (nicht mini!)
            messages=[
                {"role": "system", "content": prompt},
                {"role": "user",   "content": content},
            ],
            temperature=0,
            max_tokens=500,
            response_format={"type": "json_object"},
        )
        raw  = response.choices[0].message.content.strip()
        data = json.loads(raw)
        print(f"    [Vision] üî≠ GPT-4o Vision analysiert ({len(images_b64)} Seiten)")
    except Exception as exc:
        print(f"    [Vision] ‚ö†Ô∏è  OpenAI Vision-Fehler: {exc}")
        return {}

    def _str(val) -> str:
        return str(val).strip() if val else ""

    def _lst(val) -> list:
        if isinstance(val, list):
            return [str(v).strip() for v in val if v and str(v).strip()]
        if isinstance(val, str) and val.strip():
            return [val.strip()]
        return []

    return {
        "eigent√ºmer_name":    _str(data.get("eigent√ºmer_name")),
        "eigent√ºmer_adresse": _str(data.get("eigent√ºmer_adresse")),
        "eigent√ºmer_plz_ort": _str(data.get("eigent√ºmer_plz_ort")),
        "eigent√ºmer_geb":     "",
        "gl√§ubiger":          _lst(data.get("gl√§ubiger")),
        "forderung_betrag":   _str(data.get("forderung_betrag")),
    }


def notion_enrich_gescannte(notion: Client, db_id: str) -> int:
    """
    Findet alle Eintr√§ge die als 'gescanntes Dokument' markiert sind
    (Notizen enth√§lt 'gescanntes Dokument' oder 'Kein Text lesbar')
    und versucht sie mit GPT-4o Vision neu zu analysieren.

    Gibt die Anzahl erfolgreich analysierter Eintr√§ge zur√ºck.
    """
    if not OPENAI_AVAILABLE or not os.environ.get("OPENAI_API_KEY"):
        print("[Vision-Analyse] ‚ÑπÔ∏è  Kein OpenAI API-Key ‚Äì √ºberspringe Vision-Analyse")
        return 0
    if not FITZ_AVAILABLE:
        print("[Vision-Analyse] ‚ÑπÔ∏è  PyMuPDF nicht verf√ºgbar ‚Äì √ºberspringe Vision-Analyse")
        return 0

    GESCHUETZT_PHASEN = {
        "üîé In Pr√ºfung",
        "‚ùå Nicht relevant",
        "‚úÖ Relevant ‚Äì Brief vorbereiten",
        "üì© Brief versendet",
        "üìä Gutachten analysiert",
        "‚úÖ Gekauft",
        "üóÑ Archiviert",
    }

    print("\n[Vision-Analyse] üî≠ Suche nach gescannten PDFs ‚Ä¶")

    to_vision: list[dict] = []
    has_more     = True
    start_cursor = None

    while has_more:
        kwargs: dict = {
            "filter": {"value": "page", "property": "object"},
            "page_size": 100,
        }
        if start_cursor:
            kwargs["start_cursor"] = start_cursor

        try:
            resp = notion.search(**kwargs)
        except Exception as exc:
            print(f"  [Vision-Analyse] ‚ùå Notion-Abfrage fehlgeschlagen: {exc}")
            break

        for page in resp.get("results", []):
            parent = page.get("parent", {})
            if parent.get("database_id", "").replace("-", "") != db_id.replace("-", ""):
                continue

            props = page.get("properties", {})

            # Nur analysierte Eintr√§ge
            analysiert = props.get("Gutachten analysiert?", {}).get("checkbox", False)
            if not analysiert:
                continue

            # Gesch√ºtzte Phasen + Archivierte √ºberspringen
            phase = (props.get("Workflow-Phase", {}).get("select") or {}).get("name", "")
            if phase in GESCHUETZT_PHASEN:
                continue
            if props.get("Archiviert", {}).get("checkbox", False):
                continue

            # Muss URL haben
            link_val = props.get("Link", {}).get("url")
            if not link_val:
                continue

            # Notizen pr√ºfen: enth√§lt 'gescanntes Dokument' oder 'Kein Text lesbar'?
            notizen_rt = props.get("Notizen", {}).get("rich_text", [])
            notizen_text = "".join(
                (b.get("text") or {}).get("content", "") for b in notizen_rt
            )
            # Marker f√ºr gescannte Dokumente (original oder nach Vision-Versuch)
            ist_gescannt = (
                "gescannt" in notizen_text.lower()
                or "kein text lesbar" in notizen_text.lower()
                or "via gpt-4o vision" in notizen_text.lower()
                or "unleserlich" in notizen_text.lower()
            )
            if not ist_gescannt:
                continue

            # PDF-URL aus Notizen extrahieren
            pdf_url_match = re.search(r'Gutachten-PDF:\s*(https?://\S+)', notizen_text)
            pdf_url = pdf_url_match.group(1).strip() if pdf_url_match else None

            # Eigent√ºmer noch leer?
            eigent√ºmer_rt = props.get("Verpflichtende Partei", {}).get("rich_text", [])
            eigent√ºmer    = "".join(
                (b.get("text") or {}).get("content", "") for b in eigent√ºmer_rt
            ).strip()
            if eigent√ºmer:
                continue  # Eigent√ºmer bereits vorhanden ‚Äì √ºberspringen

            to_vision.append({
                "page_id": page["id"],
                "link":    link_val,
                "pdf_url": pdf_url,
                "notizen": notizen_text,
            })

        has_more     = resp.get("has_more", False)
        start_cursor = resp.get("next_cursor")

    MAX_VISION = 20   # GPT-4o ist teurer ‚Üí max 20 pro Run (~0.40‚Ç¨)
    total_found = len(to_vision)
    if total_found > MAX_VISION:
        print(f"  [Vision-Analyse] ‚ö†Ô∏è  {total_found} gefunden ‚Äì verarbeite nur die ersten {MAX_VISION}")
        to_vision = to_vision[:MAX_VISION]

    print(f"  [Vision-Analyse] üìã {len(to_vision)} gescannte PDFs werden analysiert")

    enriched = 0
    for entry in to_vision:
        try:
            # PDF direkt laden (URL aus Notizen oder neu von Edikt-Seite holen)
            pdf_url = entry["pdf_url"]
            if not pdf_url:
                # PDF-URL neu von der Edikt-Seite laden
                try:
                    attachments = gutachten_fetch_attachment_links(entry["link"])
                    pdfs = attachments.get("pdfs", [])
                    if pdfs:
                        best = gutachten_pick_best_pdf(pdfs)
                        pdf_url = best["url"] if best else None
                except Exception as exc:
                    print(f"    [Vision] ‚ö†Ô∏è  Edikt-Seite nicht ladbar: {exc}")
                    continue

            if not pdf_url:
                print(f"    [Vision] ‚ö†Ô∏è  Keine PDF-URL gefunden f√ºr {entry['page_id'][:8]}‚Ä¶")
                continue

            pdf_bytes = gutachten_download_pdf(pdf_url)
            info = gutachten_extract_info_vision(pdf_bytes, pdf_url)

            if not info.get("eigent√ºmer_name") and not info.get("eigent√ºmer_adresse"):
                # Als endg√ºltig unleserlich markieren ‚Üí nie wieder versuchen
                try:
                    notizen_alt = entry["notizen"].strip()
                    # Alten gescannt-Vermerk durch finalen ersetzen
                    notizen_neu = re.sub(
                        r'\(Kein Text lesbar[^)]*\)|\(Via GPT-4o Vision[^)]*\)',
                        '', notizen_alt
                    ).strip()
                    notizen_neu += "\n(Endg√ºltig unleserlich ‚Äì kein Eigent√ºmer auffindbar)"
                    notion.pages.update(
                        page_id=entry["page_id"],
                        properties={
                            "Notizen": {"rich_text": [{"text": {"content": notizen_neu[:2000]}}]}
                        }
                    )
                except Exception:
                    pass
                print(f"    [Vision] ‚ÑπÔ∏è  Kein Eigent√ºmer gefunden ‚Üí als unleserlich markiert")
                continue

            # Notion-Properties aufbauen
            def _rt(text: str) -> dict:
                return {"rich_text": [{"text": {"content": str(text)[:2000]}}]}

            def _clean_extracted_name(name: str) -> str:
                if not name:
                    return ""
                # GPT-Platzhalter / Nicht-Namen herausfiltern
                INVALID_NAMES = {"nicht angegeben", "unbekannt", "n/a", "none", "null", "-", "‚Äì"}
                if name.strip().lower() in INVALID_NAMES:
                    return ""
                if re.match(r'^[)\\\]}>]', name) or name.rstrip().endswith('-'):
                    return ""
                if not any(c.isalpha() for c in name):
                    return ""
                return name

            def _clean_extracted_adresse(adr: str) -> str:
                if not adr:
                    return ""
                adr = re.sub(r',?\s*Telefon.*$', '', adr, flags=re.IGNORECASE).strip().rstrip(',')
                m_ort_vor_strasse = re.match(r'^(?:[A-Za-z]-?)?\d{4,5}\s+\S+.*?,\s*(.+)', adr)
                if m_ort_vor_strasse:
                    adr = m_ort_vor_strasse.group(1).strip()
                adr = re.sub(r',\s*[A-Z√Ñ√ñ√ú][a-z√§√∂√º√ü]+$', '', adr).strip()
                return adr

            name_clean = _clean_extracted_name(info.get("eigent√ºmer_name", ""))
            adr_clean  = _clean_extracted_adresse(info.get("eigent√ºmer_adresse", ""))

            properties: dict = {"Gutachten analysiert?": {"checkbox": True}}

            if name_clean:
                print(f"    [Vision] üë§ Eigent√ºmer: {name_clean}")
                properties["Verpflichtende Partei"] = _rt(name_clean)

            if adr_clean:
                print(f"    [Vision] üè† Adresse: {adr_clean}")
                properties["Zustell Adresse"] = _rt(adr_clean)

            if info.get("eigent√ºmer_plz_ort"):
                properties["Zustell PLZ/Ort"] = _rt(info["eigent√ºmer_plz_ort"])

            if info.get("gl√§ubiger"):
                gl_text = " | ".join(info["gl√§ubiger"])
                print(f"    [Vision] üè¶ Gl√§ubiger: {gl_text[:80]}")
                properties["Betreibende Partei"] = _rt(gl_text)

            # Notizen aktualisieren (gescannt-Vermerk entfernen)
            notiz_parts = []
            if info.get("forderung_betrag"):
                notiz_parts.append("Forderung: " + info["forderung_betrag"])
            notiz_parts.append(f"Gutachten-PDF: {pdf_url}")
            notiz_parts.append("(Via GPT-4o Vision analysiert ‚Äì gescanntes Dokument)")
            properties["Notizen"] = _rt("\n".join(notiz_parts))

            notion.pages.update(page_id=entry["page_id"], properties=properties)
            print(f"    [Vision] ‚úÖ Notion aktualisiert")
            enriched += 1

        except Exception as exc:
            print(f"  [Vision-Analyse] ‚ùå Fehler f√ºr {entry['page_id'][:8]}‚Ä¶: {exc}")
        time.sleep(0.5)  # etwas mehr Pause wegen gr√∂√üerer API-Anfragen

    print(f"[Vision-Analyse] ‚úÖ {enriched} gescannte PDFs erfolgreich analysiert")
    return enriched


# =============================================================================
# SCHRITT 3: TOTE URLs ‚Äì HTTP 404 ‚Üí automatisch archivieren
# =============================================================================

def notion_archiviere_tote_urls(notion: Client, db_id: str,
                                all_pages: list[dict] | None = None) -> tuple[int, list[str]]:
    """
    Pr√ºft ALLE Eintr√§ge (au√üer bereits archivierte) auf HTTP 404.

    Archivierungs-Logik basierend auf Status und Phase:

    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Status = üü¢ Gr√ºn oder üü° Gelb       ‚îÇ Nur Telegram-Alarm, KEIN Archivieren ‚îÇ
    ‚îÇ (egal welche Phase)                 ‚îÇ (aktive Bearbeitung l√§uft noch)       ‚îÇ
    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
    ‚îÇ Status leer / grau                  ‚îÇ ‚Üí üóÑ Archiviert                       ‚îÇ
    ‚îÇ Phase = üì© Brief versendet          ‚îÇ ‚Üí üóÑ Archiviert + Telegram-Alarm      ‚îÇ
    ‚îÇ Alle anderen                        ‚îÇ ‚Üí üóÑ Archiviert (still)               ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

    Gibt (Anzahl archivierter Eintr√§ge, Liste der Telegram-Alarm-Texte) zur√ºck.
    """
    # Nur wirklich fertig archivierte √ºberspringen
    SKIP_PHASEN = {"üóÑ Archiviert"}

    # Schutz-Status: bei diesen wird NUR alarmiert, nicht archiviert
    SCHUTZ_STATUS = {"üü¢ Gr√ºn", "üü° Gelb"}

    print("\n[Tote-URLs] üîó Pr√ºfe URLs auf 404 ‚Ä¶")

    pages = all_pages if all_pages is not None else notion_load_all_pages(notion, db_id)
    to_check: list[dict] = []

    for page in pages:
        if True:
            props = page.get("properties", {})

            # Bereits archivierte √ºberspringen
            phase = (props.get("Workflow-Phase", {}).get("select") or {}).get("name", "")
            if phase in SKIP_PHASEN:
                continue
            if props.get("Archiviert", {}).get("checkbox", False):
                continue

            # Muss eine URL haben
            link_val = props.get("Link", {}).get("url")
            if not link_val:
                continue

            status_val = (props.get("Status", {}).get("select") or {}).get("name", "")

            # Titel f√ºr Alarm
            titel_rt = props.get("Liegenschaftsadresse", {}).get("title", [])
            titel = "".join(
                (b.get("text") or {}).get("content", "") for b in titel_rt
            ).strip() or page["id"][:8]

            to_check.append({
                "page_id":  page["id"],
                "link":     link_val,
                "phase":    phase,
                "status":   status_val,
                "titel":    titel,
            })

    MAX_CHECK = 50   # max 50 URL-Checks pro Run (schont das Netz)
    if len(to_check) > MAX_CHECK:
        to_check = to_check[:MAX_CHECK]

    print(f"  [Tote-URLs] üìã {len(to_check)} Eintr√§ge werden gepr√ºft")

    archived      = 0
    alarm_lines: list[str] = []   # Telegram-Alarme f√ºr gesch√ºtzte Eintr√§ge

    for entry in to_check:
        is_404 = False
        try:
            req = urllib.request.Request(
                entry["link"],
                headers={"User-Agent": "Mozilla/5.0 (compatible; EdikteMonitor/1.0)"}
            )
            with urllib.request.urlopen(req, timeout=10) as r:
                _ = r.read(1)   # nur Header laden
        except urllib.error.HTTPError as e:
            if e.code == 404:
                is_404 = True
        except Exception:
            pass  # Netzwerkfehler / Timeout ‚Üí kein 404

        if not is_404:
            time.sleep(0.2)
            continue

        print(f"  [Tote-URLs] üóë  HTTP 404: {entry['titel'][:60]} (Phase: {entry['phase']}, Status: {entry['status'] or '‚Äì'})")

        # ‚îÄ‚îÄ Schutz-Status: nur alarmieren, NICHT archivieren ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        if entry["status"] in SCHUTZ_STATUS:
            alarm_lines.append(
                f"‚ö†Ô∏è Edikt verschwunden (Status {entry['status']}): "
                f"<b>{entry['titel'][:80]}</b>"
            )
            # Notiz in Notion setzen ohne Phase zu √§ndern
            try:
                page_data   = notion.pages.retrieve(page_id=entry["page_id"])
                notizen_rt  = page_data["properties"].get("Notizen", {}).get("rich_text", [])
                notizen_alt = "".join(
                    (b.get("text") or {}).get("content", "") for b in notizen_rt
                ).strip()
                notizen_neu = (notizen_alt + "\n" if notizen_alt else "") + \
                              "‚ö†Ô∏è Edikt-Seite nicht mehr verf√ºgbar (HTTP 404) ‚Äì bitte manuell pr√ºfen"
                notion.pages.update(
                    page_id=entry["page_id"],
                    properties={
                        "Notizen": {"rich_text": [{"text": {"content": notizen_neu[:2000]}}]},
                    }
                )
            except Exception as exc2:
                print(f"  [Tote-URLs] ‚ö†Ô∏è  Notiz-Update fehlgeschlagen: {exc2}")
            time.sleep(0.2)
            continue

        # ‚îÄ‚îÄ Alle anderen: archivieren ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        # Bei "Brief versendet" zus√§tzlich Telegram-Alarm
        if entry["phase"] == "üì© Brief versendet":
            alarm_lines.append(
                f"üì¨ Brief bereits versendet ‚Äì Edikt jetzt weg: "
                f"<b>{entry['titel'][:80]}</b> ‚Üí archiviert"
            )

        try:
            page_data   = notion.pages.retrieve(page_id=entry["page_id"])
            notizen_rt  = page_data["properties"].get("Notizen", {}).get("rich_text", [])
            notizen_alt = "".join(
                (b.get("text") or {}).get("content", "") for b in notizen_rt
            ).strip()
            notizen_neu = (notizen_alt + "\n" if notizen_alt else "") + \
                          "Edikt-Seite nicht mehr verf√ºgbar (HTTP 404) ‚Äì automatisch archiviert"

            notion.pages.update(
                page_id=entry["page_id"],
                properties={
                    "Archiviert":    {"checkbox": True},
                    "Workflow-Phase": {"select": {"name": "üóÑ Archiviert"}},
                    "Notizen":       {"rich_text": [{"text": {"content": notizen_neu[:2000]}}]},
                }
            )
            archived += 1
        except Exception as exc2:
            print(f"  [Tote-URLs] ‚ö†Ô∏è  Archivierung fehlgeschlagen: {exc2}")

        time.sleep(0.2)

    print(f"[Tote-URLs] ‚úÖ {archived} tote URLs archiviert")
    return archived, alarm_lines


# =============================================================================
# BRIEF-WORKFLOW ‚Äì Brief erstellen f√ºr relevante Eintr√§ge
# =============================================================================
#
# Ablauf:
#   1. Suche alle Eintr√§ge mit Phase "‚úÖ Relevant ‚Äì Brief vorbereiten"
#      bei denen "Brief erstellt am" noch LEER ist.
#   2. Bestimme zust√§ndige Person anhand des Bundeslandes.
#   3. Bef√ºlle DOCX-Vorlage (brief_vorlage.docx) mit Platzhaltern.
#   4. Konvertiere DOCX ‚Üí PDF (via reportlab/python-docx).
#   5. Lade PDF als GitHub-Artifact hoch ODER schreibe Pfad in Notizen.
#   6. Setze "Brief erstellt am" in Notion (heutiges Datum).
#   7. Sende Telegram-Nachricht mit Zusammenfassung.
#
# Kontaktdaten der Zust√§ndigen:
#   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
#   ‚îÇ Bundesland        ‚îÇ Name         ‚îÇ Tel          ‚îÇ E-Mail        ‚îÇ
#   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
#   ‚îÇ Wien, Steiermark  ‚îÇ Benjamin     ‚îÇ PLACEHOLDER  ‚îÇ PLACEHOLDER   ‚îÇ
#   ‚îÇ N√ñ, Burgenland    ‚îÇ Christopher  ‚îÇ PLACEHOLDER  ‚îÇ PLACEHOLDER   ‚îÇ
#   ‚îÇ K√§rnten, Sbg, O√ñ ‚îÇ Du (Alex)    ‚îÇ PLACEHOLDER  ‚îÇ PLACEHOLDER   ‚îÇ
#   ‚îÇ Tirol, Vorarlberg ‚îÇ (noch offen) ‚îÇ ‚Äì            ‚îÇ ‚Äì             ‚îÇ
#   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
#
# WICHTIG: Kontaktdaten unten in KONTAKT_DATEN eintragen!
# =============================================================================

# ‚îÄ‚îÄ Kontaktdaten der Betreuer (Bundesland ‚Üí Ansprechpartner) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
#
# Benjamin Pippan    ‚Üí Wien, Ober√∂sterreich
# Christopher Dovjak ‚Üí Nieder√∂sterreich, Burgenland
# Friedrich Prause   ‚Üí Steiermark, K√§rnten, Salzburg, Tirol, Vorarlberg
#
KONTAKT_DATEN: dict[str, dict] = {
    "Wien":             {"name": "Benjamin Pippan",    "tel": "+43699 133 90 251", "email": "office@benana.at"},
    "Ober√∂sterreich":   {"name": "Benjamin Pippan",    "tel": "+43699 133 90 251", "email": "office@benana.at"},
    "Nieder√∂sterreich": {"name": "Christopher Dovjak", "tel": "+43 664 4531399",   "email": "christopher.dovjak@dp-im.at"},
    "Burgenland":       {"name": "Christopher Dovjak", "tel": "+43 664 4531399",   "email": "christopher.dovjak@dp-im.at"},
    "Steiermark":       {"name": "Friedrich Prause",   "tel": "+43 664 1843888",   "email": "friedrich.prause@dp-im.at"},
    "K√§rnten":          {"name": "Friedrich Prause",   "tel": "+43 664 1843888",   "email": "friedrich.prause@dp-im.at"},
    "Salzburg":         {"name": "Friedrich Prause",   "tel": "+43 664 1843888",   "email": "friedrich.prause@dp-im.at"},
    "Tirol":            {"name": "Friedrich Prause",   "tel": "+43 664 1843888",   "email": "friedrich.prause@dp-im.at"},
    "Vorarlberg":       {"name": "Friedrich Prause",   "tel": "+43 664 1843888",   "email": "friedrich.prause@dp-im.at"},
}

BRIEF_VORLAGE_PATH = os.path.join(os.path.dirname(os.path.abspath(__file__)), "brief_vorlage.docx")

# Pr√ºfe ob python-docx verf√ºgbar ist
try:
    from docx import Document as _DocxDocument
    from docx.shared import Pt as _DocxPt
    DOCX_AVAILABLE = True
except ImportError:
    DOCX_AVAILABLE = False


def _brief_fill_template(vorlage_path: str, platzhalter: dict[str, str]) -> bytes:
    """
    L√§dt die DOCX-Vorlage, ersetzt alle {{PLATZHALTER}} und gibt den DOCX-
    Inhalt als Bytes zur√ºck.

    Unterst√ºtzt sowohl normale Runs als auch Hyperlink-Paragraphen
    (bei denen der Text in w:hyperlink/w:r/w:t steckt und .runs leer ist).
    """
    from docx import Document
    from io import BytesIO

    doc = Document(vorlage_path)
    W_NS = "http://schemas.openxmlformats.org/wordprocessingml/2006/main"

    def replace_in_paragraph(para):
        """Ersetzt Platzhalter in einem Paragraphen (Runs + Hyperlinks)."""
        # --- Variante 1: normale Runs ---
        if para.runs:
            full_text = "".join(r.text for r in para.runs)
            new_text = full_text
            for key, val in platzhalter.items():
                new_text = new_text.replace(f"{{{{{key}}}}}", val)
            if new_text != full_text:
                para.runs[0].text = new_text
                for r in para.runs[1:]:
                    r.text = ""
            return

        # --- Variante 2: Hyperlink-Struktur (keine Runs) ---
        t_elements = para._element.findall(f".//{{{W_NS}}}t")
        if not t_elements:
            return
        # Gesamttext aus allen w:t zusammensetzen
        full_text = "".join((t.text or "") for t in t_elements)
        new_text = full_text
        for key, val in platzhalter.items():
            new_text = new_text.replace(f"{{{{{key}}}}}", val)
        if new_text != full_text:
            # Ersten w:t mit neuem Text f√ºllen, Rest leeren
            t_elements[0].text = new_text
            for t in t_elements[1:]:
                t.text = ""

    for para in doc.paragraphs:
        replace_in_paragraph(para)
    for table in doc.tables:
        for row in table.rows:
            for cell in row.cells:
                for para in cell.paragraphs:
                    replace_in_paragraph(para)

    buf = BytesIO()
    doc.save(buf)
    return buf.getvalue()


def _brief_anrede(eigentuemer: str) -> str:
    """
    Erzeugt eine geschlechtsspezifische Anrede aus dem Eigent√ºmernamen.
    Heuristik:
      - Enth√§lt "Hr." / "Herr" ‚Üí m√§nnlich
      - Enth√§lt "Fr." / "Frau" ‚Üí weiblich
      - Enth√§lt bekannte weibliche Titel-Pr√§fixe ‚Üí weiblich
      - Sonst ‚Üí neutral "Sehr geehrte Damen und Herren,"
    """
    name = eigentuemer.strip()
    # Direkte Anrede-Teile bestimmen
    lower = name.lower()
    if any(t in lower for t in ("herr", " hr.", "hr ")):
        return f"Sehr geehrter Hr. {name},"
    elif any(t in lower for t in ("frau", " fr.", "fr ")):
        return f"Sehr geehrte Fr. {name},"
    else:
        return f"Sehr geehrte Damen und Herren,"


def _brief_send_email(kontakt_email: str, kontakt_name: str,
                      eigentuemer: str, titel: str,
                      docx_bytes: bytes, dateiname_docx: str) -> bool:
    """
    Sendet den Brief als DOCX-Anhang per E-Mail an den zust√§ndigen Betreuer.

    Verwendet SMTP-Konfiguration aus Umgebungsvariablen:
      SMTP_HOST      (default: smtp.gmail.com)
      SMTP_PORT      (default: 587)
      SMTP_USER      (Absender-Adresse)
      SMTP_PASSWORD  (App-Passwort oder normales Passwort)
      SMTP_FROM      (optional, default = SMTP_USER)

    Gibt True bei Erfolg, False bei Fehler zur√ºck.
    """
    import smtplib
    import ssl
    from email.mime.multipart import MIMEMultipart
    from email.mime.base import MIMEBase
    from email.mime.text import MIMEText
    from email import encoders

    smtp_host = os.environ.get("SMTP_HOST", "smtp.gmail.com")
    smtp_port = int(os.environ.get("SMTP_PORT", "587"))
    smtp_user = os.environ.get("SMTP_USER", "")
    smtp_pw   = os.environ.get("SMTP_PASSWORD", "")
    smtp_from = os.environ.get("SMTP_FROM", smtp_user)

    if not smtp_user or not smtp_pw:
        print(f"  [Brief] ‚ÑπÔ∏è  SMTP nicht konfiguriert (SMTP_USER/SMTP_PASSWORD fehlt) ‚Äì nur lokal gespeichert")
        return False

    try:
        msg = MIMEMultipart()
        msg["From"]    = smtp_from
        msg["To"]      = kontakt_email
        msg["Subject"] = f"Neuer Brief: {titel[:80]}"

        body = "\n".join([
            f"Hallo {kontakt_name},",
            "",
            "anbei der Anschreiben-Entwurf f√ºr:",
            f"  Eigent√ºmer:   {eigentuemer}",
            f"  Liegenschaft: {titel}",
            "",
            "Bitte ausdrucken und versenden.",
            "",
            "Automatisch erstellt vom Edikte-Monitor.",
        ])
        msg.attach(MIMEText(body, "plain", "utf-8"))

        # DOCX anh√§ngen
        part = MIMEBase("application", "vnd.openxmlformats-officedocument.wordprocessingml.document")
        part.set_payload(docx_bytes)
        encoders.encode_base64(part)
        part.add_header("Content-Disposition", f'attachment; filename="{dateiname_docx}"')
        msg.attach(part)

        context = ssl.create_default_context()
        with smtplib.SMTP(smtp_host, smtp_port) as server:
            server.ehlo()
            server.starttls(context=context)
            server.login(smtp_user, smtp_pw)
            server.sendmail(smtp_from, kontakt_email, msg.as_bytes())

        print(f"  [Brief] ‚úâÔ∏è  E-Mail gesendet an {kontakt_email}")
        return True

    except Exception as exc:
        print(f"  [Brief] ‚ö†Ô∏è  E-Mail-Versand fehlgeschlagen: {exc}")
        return False


def notion_brief_erstellen(notion: "Client", db_id: str,
                            all_pages: list[dict] | None = None) -> tuple[int, list[str]]:
    """
    Erstellt Briefe f√ºr alle Eintr√§ge mit Phase '‚úÖ Relevant ‚Äì Brief vorbereiten'
    bei denen 'Brief erstellt am' noch leer ist.

    Ablauf je Eintrag:
      1. Lese Eigent√ºmer, Adresse, PLZ/Ort, Bundesland aus Notion.
      2. Bestimme zust√§ndige Person aus KONTAKT_DATEN.
      3. Erzeuge Anrede (geschlechtsspezifisch).
      4. Bef√ºlle DOCX-Vorlage (brief_vorlage.docx).
      5. Sende DOCX per E-Mail an Betreuer (Option C).
      6. Speichere DOCX lokal als GitHub-Artifact (Backup).
      7. Setze 'Brief erstellt am' in Notion.
      8. F√ºge Notiz "Brief erstellt am DD.MM.YYYY" hinzu.

    Gibt (Anzahl erstellter Briefe, Liste der Telegram-Zeilen) zur√ºck.
    """
    if not DOCX_AVAILABLE:
        print("[Brief] ‚ö†Ô∏è  python-docx nicht installiert ‚Äì √ºberspringe Brief-Erstellung")
        return 0, []

    if not os.path.exists(BRIEF_VORLAGE_PATH):
        print(f"[Brief] ‚ö†Ô∏è  Vorlage nicht gefunden: {BRIEF_VORLAGE_PATH} ‚Äì √ºberspringe")
        return 0, []

    ZIEL_PHASE = "‚úÖ Relevant ‚Äì Brief vorbereiten"

    print("\n[Brief] üìù Suche nach Eintr√§gen f√ºr Brief-Erstellung ‚Ä¶")

    pages = all_pages if all_pages is not None else notion_load_all_pages(notion, db_id)

    to_process: list[dict] = []
    for page in pages:
        props = page.get("properties", {})
        phase = (props.get("Workflow-Phase", {}).get("select") or {}).get("name", "")
        if phase != ZIEL_PHASE:
            continue
        # √úberspringe wenn Brief bereits erstellt (per Datumsfeld ODER Notiz-Marker)
        brief_datum = props.get("Brief erstellt am", {}).get("date")
        if brief_datum and brief_datum.get("start"):
            continue
        # Fallback: pr√ºfe ob Notiz bereits "Brief erstellt am" enth√§lt
        notizen_rt = props.get("Notizen", {}).get("rich_text", [])
        notizen_text = "".join(t.get("plain_text", "") for t in notizen_rt)
        if "Brief erstellt am" in notizen_text:
            continue
        to_process.append(page)

    print(f"[Brief] üìã {len(to_process)} Eintr√§ge f√ºr Brief-Erstellung gefunden")
    if not to_process:
        return 0, []

    erstellt = 0
    telegram_lines: list[str] = []
    from datetime import date

    # Ausgabe-Verzeichnis f√ºr DOCXs (wird als GitHub-Artifact hochgeladen)
    brief_output_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "briefe")
    os.makedirs(brief_output_dir, exist_ok=True)

    for page in to_process:
        page_id = page["id"]
        props   = page.get("properties", {})

        # ‚îÄ‚îÄ Daten aus Notion lesen ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        titel_list  = props.get("Name", {}).get("title", [])
        titel       = "".join(t.get("plain_text", "") for t in titel_list).strip()

        eigentuemer_list = props.get("Verpflichtende Partei", {}).get("rich_text", [])
        eigentuemer      = "".join(t.get("plain_text", "") for t in eigentuemer_list).strip()

        adresse_list = props.get("Zustell Adresse", {}).get("rich_text", [])
        adresse      = "".join(t.get("plain_text", "") for t in adresse_list).strip()

        plz_ort_list = props.get("Zustell PLZ/Ort", {}).get("rich_text", [])
        plz_ort      = "".join(t.get("plain_text", "") for t in plz_ort_list).strip()

        bundesland = (props.get("Bundesland", {}).get("select") or {}).get("name", "")

        notizen_list = props.get("Notizen", {}).get("rich_text", [])
        notizen_alt  = "".join(t.get("plain_text", "") for t in notizen_list).strip()

        # ‚îÄ‚îÄ Pflichtfelder pr√ºfen ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        if not eigentuemer:
            print(f"  [Brief] ‚è≠  √úberspringe {titel[:50]} ‚Äì kein Eigent√ºmer")
            continue
        if not adresse or not plz_ort:
            print(f"  [Brief] ‚è≠  √úberspringe {titel[:50]} ‚Äì keine Zustelladresse")
            continue
        if not bundesland or bundesland not in KONTAKT_DATEN:
            print(f"  [Brief] ‚è≠  √úberspringe {titel[:50]} ‚Äì kein Kontakt f√ºr '{bundesland}'")
            continue

        kontakt   = KONTAKT_DATEN[bundesland]
        heute     = date.today()
        datum_str = heute.strftime("%d.%m.%Y")

        # ‚îÄ‚îÄ PLZ/Ort der Liegenschaft aus Titel extrahieren ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        # Titel-Format: "Musterstra√üe 1, 1010 Wien" oder nur Stra√üe
        # Falls PLZ/Ort erkennbar ist, splitten; sonst Bundesland als Fallback
        liegenschaft_adresse = titel
        liegenschaft_plz_ort = ""
        titel_parts = titel.rsplit(",", 1)
        if len(titel_parts) == 2 and re.match(r"\s*\d{4}", titel_parts[1]):
            liegenschaft_adresse = titel_parts[0].strip()
            liegenschaft_plz_ort = titel_parts[1].strip()
        else:
            # Versuche es mit dem gespeicherten PLZ-Feld
            liegenschaft_plz_ort_list = props.get("PLZ/Ort", {}).get("rich_text", [])
            liegenschaft_plz_ort = "".join(
                t.get("plain_text", "") for t in liegenschaft_plz_ort_list
            ).strip()

        # ‚îÄ‚îÄ Anrede ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        anrede = _brief_anrede(eigentuemer)

        # ‚îÄ‚îÄ Platzhalter bef√ºllen ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        platzhalter = {
            "EIGENTUEMER_NAME":     eigentuemer,
            "ZUSTELL_ADRESSE":      adresse,
            "ZUSTELL_PLZ_ORT":      plz_ort,
            "DATUM":                f"Wien, am {datum_str}",
            "LIEGENSCHAFT_ADRESSE": liegenschaft_adresse,
            "LIEGENSCHAFT_PLZ_ORT": liegenschaft_plz_ort or plz_ort,
            "ANREDE":               anrede,
            "KONTAKT_NAME":         kontakt["name"],
            "KONTAKT_TEL":          kontakt["tel"],
            "KONTAKT_EMAIL":        kontakt["email"],
        }

        try:
            # ‚îÄ‚îÄ DOCX bef√ºllen ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            docx_bytes = _brief_fill_template(BRIEF_VORLAGE_PATH, platzhalter)

            # ‚îÄ‚îÄ Dateiname ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            safe_eigen = re.sub(r"[^\w\s-]", "", eigentuemer)[:40].strip().replace(" ", "_")
            safe_datum = datum_str.replace(".", "-")
            dateiname_docx = f"Brief_{safe_datum}_{safe_eigen}.docx"
            docx_path = os.path.join(brief_output_dir, dateiname_docx)

            with open(docx_path, "wb") as f:
                f.write(docx_bytes)
            print(f"  [Brief] üíæ DOCX gespeichert: {dateiname_docx}")

            # ‚îÄ‚îÄ E-Mail an Betreuer (Option C) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            email_ok = _brief_send_email(
                kontakt_email   = kontakt["email"],
                kontakt_name    = kontakt["name"],
                eigentuemer     = eigentuemer,
                titel           = titel,
                docx_bytes      = docx_bytes,
                dateiname_docx  = dateiname_docx,
            )

            # ‚îÄ‚îÄ Notion: Brief-Datum + Notiz setzen ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            email_info = f" (E-Mail an {kontakt['email']})" if email_ok else " (nur lokal gespeichert)"
            neue_notiz = notizen_alt
            if neue_notiz and not neue_notiz.endswith("\n"):
                neue_notiz += "\n"
            neue_notiz += f"Brief erstellt am {datum_str}{email_info}"
            neue_notiz = neue_notiz[:2000]

            # Zuerst versuchen mit "Brief erstellt am" Datumsfeld
            notion_update_ok = False
            try:
                notion.pages.update(
                    page_id=page_id,
                    properties={
                        "Brief erstellt am": {"date": {"start": heute.isoformat()}},
                        "Notizen": {"rich_text": [{"type": "text", "text": {"content": neue_notiz}}]},
                    }
                )
                notion_update_ok = True
            except Exception as notion_exc:
                err_str = str(notion_exc)
                if "Brief erstellt am" in err_str and "not a property" in err_str:
                    # Feld existiert nicht in Notion ‚Üí nur Notiz schreiben
                    print(f"  [Brief] ‚ö†Ô∏è  Feld 'Brief erstellt am' existiert nicht in Notion ‚Äì "
                          f"schreibe nur Notiz")
                    try:
                        notion.pages.update(
                            page_id=page_id,
                            properties={
                                "Notizen": {"rich_text": [{"type": "text", "text": {"content": neue_notiz}}]},
                            }
                        )
                        notion_update_ok = True
                    except Exception as notiz_exc:
                        print(f"  [Brief] ‚ö†Ô∏è  Auch Notiz-Update fehlgeschlagen: {notiz_exc}")
                else:
                    print(f"  [Brief] ‚ö†Ô∏è  Notion-Update fehlgeschlagen: {notion_exc}")
            print(f"  [Brief] ‚úÖ Erledigt: {eigentuemer[:40]} ({bundesland}) ‚Üí {kontakt['name']}")

            # ‚îÄ‚îÄ Telegram-Zeile ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            icon = "‚úâÔ∏è" if email_ok else "üíæ"
            telegram_lines.append(
                f"{icon} {html_escape(eigentuemer[:35])} | {html_escape(bundesland)} "
                f"‚Üí {html_escape(kontakt['name'])}"
            )
            erstellt += 1
            time.sleep(0.3)

        except Exception as exc:
            print(f"  [Brief] ‚ùå Fehler bei {titel[:50]}: {exc}")

    print(f"[Brief] ‚úÖ {erstellt} Brief(e) erstellt")
    return erstellt, telegram_lines

def fetch_results_for_state(bundesland: str, bl_value: str) -> list[dict]:
    """
    Ruft die Ergebnisseite f√ºr ein Bundesland direkt per HTTP ab.

    Die URL-Struktur wurde durch Analyse des Formulars ermittelt:
    /edikte/ex/exedi3.nsf/suchedi?SearchView&subf=eex&...&query=([BL]=(X))
    """
    print(f"\n[Scraper] üîç Suche f√ºr: {bundesland} (BL={bl_value})")

    query = f"([BL]=({bl_value}))"
    params = urllib.parse.urlencode({
        "SearchView": "",
        "subf": "eex",
        "SearchOrder": "4",
        "SearchMax": "4999",
        "retfields": f"~BL={bl_value}",
        "ftquery": "",
        "query": query,
    })
    url = f"{BASE_URL}/edikte/ex/exedi3.nsf/suchedi?{params}"

    try:
        req = urllib.request.Request(
            url,
            headers={"User-Agent": "Mozilla/5.0 (compatible; EdikteMonitor/1.0)"}
        )
        with urllib.request.urlopen(req, timeout=30) as r:
            html = r.read().decode("utf-8", errors="replace")
    except Exception as exc:
        print(f"  [Scraper] ‚ùå HTTP-Fehler: {exc}")
        return []

    # Links extrahieren ‚Äì Format: alldoc/HEX!OpenDocument (relativ, ohne f√ºhrendes /)
    rel_pattern = re.compile(
        r'<a[^>]+href="(alldoc/([0-9a-f]+)!OpenDocument)"[^>]*>([^<]+)</a>',
        re.IGNORECASE
    )

    results = []
    seen_ids = set()

    for href_rel, edikt_id, link_text in rel_pattern.findall(html):
        link_text = link_text.strip()
        edikt_id  = edikt_id.lower()
        href      = f"{BASE_URL}/edikte/ex/exedi3.nsf/{href_rel}"

        if edikt_id in seen_ids:
            continue
        seen_ids.add(edikt_id)

        # Typ bestimmen
        typ = None
        for t in RELEVANT_TYPES:
            if link_text.startswith(t):
                typ = t
                break
        if not typ:
            continue

        # Ausschlussliste (nur bei Versteigerung relevant)
        if typ == "Versteigerung" and is_excluded(link_text):
            print(f"  [Filter] ‚õî Ausgeschlossen: {link_text[:80]}")
            continue

        results.append({
            "bundesland":   bundesland,
            "type":         typ,
            "beschreibung": link_text,
            "link":         href,
            "edikt_id":     edikt_id,
        })

    print(f"  [Scraper] üìã {len(results)} relevante Treffer f√ºr {bundesland}")
    return results


# =============================================================================
# MAIN
# =============================================================================

async def main() -> None:
    print("=" * 60)
    print(f"Edikte-Monitor gestartet: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)

    notion = Client(auth=env("NOTION_TOKEN"))
    db_id  = clean_notion_db_id(env("NOTION_DATABASE_ID"))

    neue_eintraege:  list[dict] = []
    entfall_updates: list[dict] = []
    fehler:          list[str]  = []

    # ‚îÄ‚îÄ 1. Alle bekannten IDs einmalig laden (schnelle lokale Deduplizierung) ‚îÄ
    try:
        known_ids = notion_load_all_ids(notion, db_id)  # {edikt_id -> page_id}
    except Exception as exc:
        print(f"  [ERROR] Konnte IDs nicht laden: {exc}")
        known_ids = {}

    # ‚îÄ‚îÄ 2. Edikte scrapen + in Notion eintragen ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    for bundesland, bl_value in BUNDESLAENDER.items():
        try:
            results = fetch_results_for_state(bundesland, bl_value)
        except Exception as exc:
            msg = f"Scraper-Fehler {bundesland}: {exc}"
            print(f"  [ERROR] {msg}")
            fehler.append(msg)
            continue

        for item in results:
            try:
                eid = item["edikt_id"].lower()

                if item["type"] == "Versteigerung":
                    if known_ids.get(eid) == "(geschuetzt)":
                        print(f"  [Notion] üîí Gesch√ºtzt (bereits bearbeitet): {eid}")
                    elif eid not in known_ids:
                        result_tuple = notion_create_eintrag(notion, db_id, item)
                        if result_tuple is None:
                            # Kategorie-Filter hat das Objekt ausgeschlossen
                            known_ids[eid] = "(gefiltert)"
                        else:
                            detail, new_page_id = result_tuple
                            item["_detail"] = detail
                            neue_eintraege.append(item)
                            known_ids[eid] = "(neu)"  # sofort als bekannt markieren
                            # ‚îÄ‚îÄ Gutachten sofort anreichern ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                            if new_page_id and item.get("link") and FITZ_AVAILABLE:
                                try:
                                    gutachten_enrich_notion_page(
                                        notion, new_page_id, item["link"]
                                    )
                                except Exception as ge:
                                    print(f"    [Gutachten] ‚ö†Ô∏è  Anreicherung fehlgeschlagen: {ge}")
                    else:
                        print(f"  [Notion] ‚è≠  Bereits vorhanden: {eid}")

                elif item["type"] in ("Entfall des Termins", "Verschiebung"):
                    page_id = known_ids.get(eid)
                    if page_id and page_id not in ("(neu)", "(geschuetzt)", "(gefiltert)"):
                        notion_mark_entfall(notion, page_id, item)
                        entfall_updates.append(item)
                    elif page_id == "(geschuetzt)":
                        print(f"  [Notion] üîí Entfall √ºbersprungen (gesch√ºtzte Phase): {eid}")
                    else:
                        print(f"  [Notion] ‚ÑπÔ∏è  Entfall ohne DB-Eintrag: {eid}")

            except Exception as exc:
                msg = f"Notion-Fehler {item.get('edikt_id', '?')}: {exc}"
                print(f"  [ERROR] {msg}")
                fehler.append(msg)

    # ‚îÄ‚îÄ 3. URL-Anreicherung f√ºr manuell angelegte Eintr√§ge ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    try:
        enriched_count = notion_enrich_urls(notion, db_id)
    except Exception as exc:
        msg = f"URL-Anreicherung fehlgeschlagen: {exc}"
        print(f"  [ERROR] {msg}")
        fehler.append(msg)
        enriched_count = 0

    # ‚îÄ‚îÄ 3. Einmaliges Laden aller Notion-Pages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # Die folgenden 4 Schritte (Status-Sync, Bereinigung, Tote-URLs,
    # Qualit√§ts-Check) w√ºrden sonst jeweils einen eigenen DB-Scan starten.
    # Stattdessen laden wir die DB EINMALIG und geben das Ergebnis weiter.
    try:
        _all_pages = notion_load_all_pages(notion, db_id)
    except Exception as exc:
        print(f"  [WARN] Konnte Pages nicht vorladen ‚Äì Fallback auf Einzel-Scans: {exc}")
        _all_pages = None   # jede Funktion macht dann selbst einen Scan

    # ‚îÄ‚îÄ 3a. Status-Sync: Status-Farbe / F√ºr-uns-relevant? ‚Üí Phase + Checkboxen ‚îÄ
    # Wenn ein Kollege manuell üî¥/üü°/üü¢ setzt oder "F√ºr uns relevant?" bef√ºllt,
    # werden Phase und Checkboxen automatisch angepasst (kein manuelles Ankreuzen n√∂tig).
    try:
        notion_status_sync(notion, db_id, all_pages=_all_pages)
    except Exception as exc:
        print(f"  [WARN] Status-Sync fehlgeschlagen (nicht kritisch): {exc}")

    # ‚îÄ‚îÄ WICHTIG: Pages nach Status-Sync neu laden ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # Status-Sync hat Phasen/Checkboxen in Notion aktualisiert.
    # Damit Brief-Erstellung und Qualit√§ts-Check die neuen Werte sehen,
    # muss die lokale Kopie jetzt neu geladen werden.
    try:
        _all_pages = notion_load_all_pages(notion, db_id)
    except Exception as exc:
        print(f"  [WARN] Neu-Laden nach Status-Sync fehlgeschlagen ‚Äì Fallback auf alte Daten: {exc}")

    # ‚îÄ‚îÄ 3b. Einmalige Bereinigung: falsche Gerichtsnamen in 'Verpflichtende Partei' ‚îÄ‚îÄ
    # Fr√ºhere Script-Versionen haben irrt√ºmlich den Gerichtsnamen (z.B. "BG Schwaz (870)")
    # in das Feld 'Verpflichtende Partei' geschrieben. Diese Eintr√§ge werden hier
    # erkannt, das Feld geleert und 'Gutachten analysiert?' zur√ºckgesetzt,
    # damit der n√§chste Schritt (4) sie neu verarbeitet.
    try:
        notion_reset_falsche_verpflichtende(notion, db_id, all_pages=_all_pages)
    except Exception as exc:
        print(f"  [WARN] Bereinigung fehlgeschlagen (nicht kritisch): {exc}")

    # ‚îÄ‚îÄ 3c. Tote URLs archivieren (HTTP 404) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    tote_urls_archiviert = 0
    tote_urls_alarme: list[str] = []
    try:
        tote_urls_archiviert, tote_urls_alarme = notion_archiviere_tote_urls(notion, db_id, all_pages=_all_pages)
    except Exception as exc:
        print(f"  [WARN] Tote-URLs-Check fehlgeschlagen (nicht kritisch): {exc}")

    # ‚îÄ‚îÄ 3d. Qualit√§ts-Check: analysierte Eintr√§ge auf Vollst√§ndigkeit pr√ºfen ‚îÄ‚îÄ
    # Eintr√§ge die als 'analysiert' markiert sind, aber keinen Eigent√ºmer/Adresse
    # haben, werden zur√ºckgesetzt damit Schritt 4 sie neu analysiert.
    try:
        notion_qualitaetscheck(notion, db_id, all_pages=_all_pages)
    except Exception as exc:
        print(f"  [WARN] Qualit√§ts-Check fehlgeschlagen (nicht kritisch): {exc}")

    # ‚îÄ‚îÄ 3e. Brief-Erstellung: relevant markierte Eintr√§ge ‚Üí Brief erstellen ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # Betrifft: Eintr√§ge mit Phase '‚úÖ Relevant ‚Äì Brief vorbereiten'
    # bei denen 'Brief erstellt am' noch leer ist.
    brief_erstellt = 0
    brief_telegram: list[str] = []
    try:
        brief_erstellt, brief_telegram = notion_brief_erstellen(notion, db_id, all_pages=_all_pages)
    except Exception as exc:
        print(f"  [WARN] Brief-Erstellung fehlgeschlagen (nicht kritisch): {exc}")

    # ‚îÄ‚îÄ 4. Gutachten-Anreicherung: Text-PDFs (LLM) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # Betrifft: Eintr√§ge die eine URL haben aber noch nicht analysiert wurden.
    gutachten_enriched = 0
    if FITZ_AVAILABLE:
        try:
            gutachten_enriched = notion_enrich_gutachten(notion, db_id)
        except Exception as exc:
            msg = f"Gutachten-Anreicherung fehlgeschlagen: {exc}"
            print(f"  [ERROR] {msg}")
            fehler.append(msg)
    else:
        print("[Gutachten] ‚ÑπÔ∏è  PyMuPDF nicht verf√ºgbar ‚Äì √ºberspringe Gutachten-Anreicherung")

    # ‚îÄ‚îÄ 4b. Vision-Analyse: gescannte PDFs (GPT-4o) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    vision_enriched = 0
    try:
        vision_enriched = notion_enrich_gescannte(notion, db_id)
    except Exception as exc:
        print(f"  [WARN] Vision-Analyse fehlgeschlagen (nicht kritisch): {exc}")

    # ‚îÄ‚îÄ 5. Zusammenfassung ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    print("\n" + "=" * 60)
    print(f"‚úÖ Neue Eintr√§ge:         {len(neue_eintraege)}")
    print(f"üî¥ Entfall-Updates:       {len(entfall_updates)}")
    print(f"üîó URLs erg√§nzt:          {enriched_count}")
    print(f"üóë  Tote URLs archiviert:  {tote_urls_archiviert}")
    print(f"üìÑ Gutachten analysiert:  {gutachten_enriched}")
    print(f"üî≠ Vision analysiert:     {vision_enriched}")
    print(f"‚úâÔ∏è  Briefe erstellt:      {brief_erstellt}")
    print(f"‚ö†Ô∏è  Fehler:                {len(fehler)}")
    print("=" * 60)

    if not neue_eintraege and not entfall_updates and not fehler \
            and not gutachten_enriched and not vision_enriched \
            and not tote_urls_archiviert and not tote_urls_alarme \
            and not brief_erstellt:
        print("Keine neuen relevanten √Ñnderungen ‚Äì kein Telegram-Versand.")
        return

    # ‚îÄ‚îÄ 6. Telegram ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    lines = [
        "<b>üèõ Edikte-Monitor</b>",
        f"<i>{datetime.now().strftime('%d.%m.%Y %H:%M')}</i>",
        "",
    ]

    if neue_eintraege:
        lines.append(f"<b>üü¢ Neue Versteigerungen: {len(neue_eintraege)}</b>")
        for item in neue_eintraege[:20]:
            detail    = item.get("_detail", {})
            adresse   = html_escape(detail.get("adresse_voll") or item["beschreibung"][:70])
            kategorie = html_escape(detail.get("kategorie", ""))
            vk        = detail.get("schaetzwert")
            vk_str    = f" | üí∞ {vk:,.0f} ‚Ç¨".replace(",", ".") if vk else ""
            kat_str   = f" [{kategorie}]" if kategorie else ""
            lines.append(f"‚Ä¢ <b>{adresse}</b>{kat_str}{vk_str}")
            lines.append(f"  <a href=\"{item['link']}\">‚Üí Edikt √∂ffnen</a>")
        if len(neue_eintraege) > 20:
            lines.append(f"  ... und {len(neue_eintraege) - 20} weitere")
        lines.append("")

    if entfall_updates:
        lines.append(f"<b>üî¥ Termin entfallen/verschoben: {len(entfall_updates)}</b>")
        for item in entfall_updates[:10]:
            lines.append(f"‚Ä¢ {html_escape(item['bundesland'])} ‚Äì {html_escape(item['beschreibung'][:60])}")
        lines.append("")

    if enriched_count:
        lines.append(f"<b>üîó URLs nachgetragen: {enriched_count}</b>")
        lines.append("")

    if tote_urls_archiviert:
        lines.append(f"<b>üóë Tote Edikte archiviert: {tote_urls_archiviert}</b>")
        lines.append("")

    if tote_urls_alarme:
        lines.append("<b>üö® Achtung ‚Äì Edikt verschwunden (manuelle Pr√ºfung!):</b>")
        for alarm in tote_urls_alarme:
            lines.append(f"‚Ä¢ {alarm}")
        lines.append("")

    if brief_erstellt:
        lines.append(f"<b>‚úâÔ∏è Briefe erstellt: {brief_erstellt}</b>")
        for bl in brief_telegram[:10]:
            lines.append(f"‚Ä¢ {bl}")
        lines.append("")

    if gutachten_enriched:
        lines.append(f"<b>üìÑ Gutachten analysiert (Text): {gutachten_enriched}</b>")
        lines.append("")

    if vision_enriched:
        lines.append(f"<b>üî≠ Gutachten analysiert (Vision): {vision_enriched}</b>")
        lines.append("")

    if fehler:
        lines.append(f"<b>‚ö†Ô∏è Fehler ({len(fehler)}):</b>")
        for f_msg in fehler[:5]:
            lines.append(f"‚Ä¢ {f_msg[:100]}")

    try:
        await send_telegram("\n".join(lines))
    except Exception as exc:
        print(f"[ERROR] Telegram fehlgeschlagen: {exc}")


if __name__ == "__main__":
    asyncio.run(main())
