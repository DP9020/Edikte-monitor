"""
Edikte-Monitor â€“ Ã–sterreich
============================
Scraper fÃ¼r https://edikte.justiz.gv.at (Gerichtliche Versteigerungen)
Alle BundeslÃ¤nder | HTTP-Request (kein Browser nÃ¶tig) | Notion | Telegram
"""

import os
import re
import json
import time
import asyncio
import urllib.request
import urllib.parse
from datetime import datetime
from notion_client import Client

try:
    import fitz          # PyMuPDF â€“ optionale AbhÃ¤ngigkeit
    FITZ_AVAILABLE = True
except ImportError:
    fitz = None
    FITZ_AVAILABLE = False

# =============================================================================
# KONFIGURATION
# =============================================================================

BASE_URL = "https://edikte.justiz.gv.at"

# Bundesland-Werte aus dem Formular (name=BL)
BUNDESLAENDER = {
    "Wien":           "0",
    "NiederÃ¶sterreich": "1",
    "Burgenland":     "2",
    "OberÃ¶sterreich": "3",
    "Salzburg":       "4",
    "Steiermark":     "5",
    "KÃ¤rnten":        "6",
    "Tirol":          "7",
    "Vorarlberg":     "8",
}

# Nur diese Link-Texte werden verarbeitet
RELEVANT_TYPES = ("Versteigerung", "Entfall des Termins", "Verschiebung")

# SchlÃ¼sselwÃ¶rter im Link-Text â†’ Objekt wird NICHT importiert
# (greift auf Ergebnisseite, wo der Text oft nur "Versteigerung (Datum)" ist)
EXCLUDE_KEYWORDS = [
    "landwirtschaft",
    "land- und forst",
    "forstwirtschaft",
    "gewerb",
    "betriebsobjekt",
    "industrie",
    "lager",
    "bÃ¼ro",
    "hotel",
    "pension",
]

# Kategorien aus der Detailseite â†’ Objekt wird NICHT importiert
# Entspricht den Werten im Feld "Kategorie(n)" auf edikte.justiz.gv.at
EXCLUDE_KATEGORIEN = {
    "land- und forstwirtschaftlich genutzte liegenschaft",  # LF
    "gewerbliche liegenschaft",                             # GL
    "betriebsobjekt",
    "superÃ¤difikat",                                        # SE â€“ nur wenn gewerblich
}

# Notion-Feldname fÃ¼r PLZ (exakt so wie in der Datenbank angelegt)
NOTION_PLZ_FIELD = "Liegenschafts PLZ"

# Edikt-ID aus dem Link extrahieren
ID_RE = re.compile(r"alldoc/([0-9a-f]+)!OpenDocument", re.IGNORECASE)

# Verkehrswert / SchÃ¤tzwert
SCHAETZWERT_RE = re.compile(
    r'(?:SchÃ¤tzwert|Verkehrswert|SchÃ¤tzungswert|Wert)[:\s]+([\d\.\s,]+(?:EUR|â‚¬)?)',
    re.IGNORECASE
)


# =============================================================================
# HILFSFUNKTIONEN
# =============================================================================

def env(name: str) -> str:
    """Liest eine Umgebungsvariable â€“ wirft Fehler wenn nicht gesetzt."""
    value = os.getenv(name)
    if not value:
        raise RuntimeError(f"Fehlende Umgebungsvariable: {name}")
    return value


def clean_notion_db_id(raw: str) -> str:
    """Bereinigt die Notion Datenbank-ID (entfernt View-Parameter etc.)."""
    raw = raw.split("?")[0].strip()
    raw = raw.rstrip("/").split("/")[-1]
    clean = re.sub(r"[^0-9a-fA-F]", "", raw)
    if len(clean) == 32:
        return f"{clean[0:8]}-{clean[8:12]}-{clean[12:16]}-{clean[16:20]}-{clean[20:32]}"
    return raw


def is_excluded(text: str) -> bool:
    """PrÃ¼ft ob ein Objekt anhand des Link-Texts ausgeschlossen werden soll."""
    return any(kw in text.lower() for kw in EXCLUDE_KEYWORDS)


def is_excluded_by_kategorie(kategorie: str) -> bool:
    """PrÃ¼ft ob ein Objekt anhand der Detailseiten-Kategorie ausgeschlossen werden soll."""
    return kategorie.lower().strip() in EXCLUDE_KATEGORIEN


def parse_euro(raw: str) -> float | None:
    """
    Wandelt einen Ã¶sterreichischen Betragsstring in float um.
    z.B. '180.000,00 EUR' â†’ 180000.0
    """
    try:
        cleaned = re.sub(r"[â‚¬EUReur\s]", "", raw.strip())
        cleaned = cleaned.replace(".", "").replace(",", ".")
        return float(cleaned)
    except Exception:
        return None


def parse_flaeche(raw: str) -> float | None:
    """Wandelt '96,72 mÂ²' in 96.72 um."""
    try:
        m = re.search(r"([\d.,]+)", raw)
        if m:
            return float(m.group(1).replace(".", "").replace(",", "."))
    except Exception:
        pass
    return None


def fetch_detail(link: str) -> dict:
    """
    LÃ¤dt die Edikt-Detailseite und extrahiert alle strukturierten Felder
    direkt aus dem Bootstrap-Grid (span.col-sm-3 + p.col-sm-9).

    Liefert ein Dict mit den SchlÃ¼sseln:
      liegenschaftsadresse, plz_ort, adresse_voll   â† echte Immobilienadresse
      gericht, aktenzeichen, wegen
      termin, termin_iso
      kategorie, grundbuch, ez
      flaeche_objekt, flaeche_grundstueck
      schaetzwert (float), schaetzwert_str
      geringstes_gebot (float)
    """
    try:
        req = urllib.request.Request(
            link,
            headers={"User-Agent": "Mozilla/5.0 (compatible; EdikteMonitor/1.0)"}
        )
        with urllib.request.urlopen(req, timeout=20) as r:
            html = r.read().decode("utf-8", errors="replace")
    except Exception as exc:
        print(f"    [Detail] âš ï¸  Fehler beim Laden: {exc}")
        return {}

    # â”€â”€ Alle labelâ†’value Paare aus dem Bootstrap-Grid extrahieren â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    grid_re = re.compile(
        r'<span[^>]*col-sm-3[^>]*>\s*([^<]+?)\s*</span>\s*<p[^>]*col-sm-9[^>]*>\s*(.*?)\s*</p>',
        re.DOTALL | re.IGNORECASE
    )

    def clean(html_fragment: str) -> str:
        t = re.sub(r"<[^>]+>", " ", html_fragment)
        t = t.replace("\xa0", " ").replace("&nbsp;", " ")
        from html import unescape
        t = unescape(t)
        return " ".join(t.split()).strip()

    fields: dict[str, str] = {}
    for label, value in grid_re.findall(html):
        key = label.strip().rstrip(":").strip()
        fields[key] = clean(value)

    result: dict = {}

    # â”€â”€ Liegenschaftsadresse (echte Immobilienadresse!) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    adresse    = fields.get("Liegenschaftsadresse", "")
    plz_ort    = fields.get("PLZ/Ort", "")
    if adresse:
        result["liegenschaftsadresse"] = adresse
        result["plz_ort"]              = plz_ort
        result["adresse_voll"]         = f"{adresse}, {plz_ort}".strip(", ")
        print(f"    [Detail] ğŸ“ Adresse: {result['adresse_voll']}")

    # â”€â”€ Gericht / Dienststelle â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if "Dienststelle" in fields:
        result["gericht"] = fields["Dienststelle"]
    elif "Dienststelle:" in fields:
        result["gericht"] = fields["Dienststelle:"]

    # â”€â”€ Aktenzeichen â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    for k in ("Aktenzeichen", "Aktenzeichen:"):
        if k in fields:
            result["aktenzeichen"] = fields[k]
            break

    # â”€â”€ wegen â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if "wegen" in fields:
        result["wegen"] = fields["wegen"]

    # â”€â”€ Versteigerungstermin â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    termin_raw = fields.get("Versteigerungstermin", "")
    m = re.search(r"(\d{1,2}\.\d{1,2}\.\d{4})\s+um\s+([\d:]+\s*Uhr)", termin_raw)
    if m:
        result["termin"] = f"{m.group(1)} {m.group(2)}"
        try:
            dt = datetime.strptime(m.group(1), "%d.%m.%Y")
            result["termin_iso"] = dt.strftime("%Y-%m-%d")
        except Exception:
            pass

    # â”€â”€ Kategorie / Objektart â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if "Kategorie(n)" in fields:
        result["kategorie"] = fields["Kategorie(n)"]

    # â”€â”€ Grundbuch / EZ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if "Grundbuch" in fields:
        result["grundbuch"] = fields["Grundbuch"]
    if "EZ" in fields:
        result["ez"] = fields["EZ"]

    # â”€â”€ FlÃ¤chen â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    fobj = fields.get("ObjektgrÃ¶ÃŸe", "")
    if fobj:
        parsed = parse_flaeche(fobj)
        if parsed:
            result["flaeche_objekt"] = parsed

    fgrst = fields.get("GrundstÃ¼cksgrÃ¶ÃŸe", "")
    if fgrst:
        parsed = parse_flaeche(fgrst)
        if parsed:
            result["flaeche_grundstueck"] = parsed

    # â”€â”€ SchÃ¤tzwert â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    sv_raw = fields.get("SchÃ¤tzwert", "")
    if sv_raw:
        result["schaetzwert_str"] = sv_raw
        parsed = parse_euro(sv_raw)
        if parsed is not None:
            result["schaetzwert"] = parsed
            print(f"    [Detail] ğŸ’° SchÃ¤tzwert: {parsed:,.0f} â‚¬")

    # â”€â”€ Geringstes Gebot â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    gg_raw = fields.get("Geringstes Gebot", "")
    if gg_raw:
        parsed = parse_euro(gg_raw)
        if parsed is not None:
            result["geringstes_gebot"] = parsed

    return result


# =============================================================================
# TELEGRAM
# =============================================================================

def html_escape(text: str) -> str:
    """Escapt Sonderzeichen fÃ¼r Telegram HTML-Modus."""
    return (text
            .replace("&", "&amp;")
            .replace("<", "&lt;")
            .replace(">", "&gt;"))


def _telegram_send_raw(url: str, payload_dict: dict) -> None:
    """Interne Hilfsfunktion: sendet einen JSON-Payload an die Telegram API."""
    payload = json.dumps(payload_dict, ensure_ascii=False).encode("utf-8")
    req = urllib.request.Request(
        url,
        data=payload,
        headers={"Content-Type": "application/json; charset=utf-8"},
    )
    with urllib.request.urlopen(req, timeout=15) as r:
        r.read()


def _truncate_plain(text: str, limit: int = 4096) -> str:
    """KÃ¼rzt Plain-Text sicher auf das Zeichenlimit."""
    if len(text) <= limit:
        return text
    return text[:limit - 6] + "\n[...]"


def _strip_html_tags(text: str) -> str:
    """Entfernt alle HTML-Tags und dekodiert HTML-Entities."""
    plain = re.sub(r"<[^>]+>", "", text)
    plain = plain.replace("&amp;", "&").replace("&lt;", "<").replace("&gt;", ">")
    return plain


async def send_telegram(message: str) -> None:
    """
    Sendet eine Nachricht via Telegram Bot (HTML-Modus).
    - Wenn die Nachricht > 4096 Zeichen: wird in mehrere Teile aufgeteilt,
      wobei jeder Teil an einer Zeilengrenze getrennt wird (kein halber HTML-Tag).
    - Bei HTML-Fehler (400): Fallback auf reinen Text ohne parse_mode.
    """
    token   = env("TELEGRAM_BOT_TOKEN")
    chat_id = env("TELEGRAM_CHAT_ID")
    url     = f"https://api.telegram.org/bot{token}/sendMessage"

    def split_message(text: str, limit: int = 4000) -> list[str]:
        """Teilt eine Nachricht an Zeilengrenzen auf, sodass kein HTML-Tag zerrissen wird."""
        if len(text) <= limit:
            return [text]
        parts = []
        current = []
        current_len = 0
        for line in text.split("\n"):
            line_len = len(line) + 1  # +1 fÃ¼r \n
            if current_len + line_len > limit and current:
                parts.append("\n".join(current))
                current = [line]
                current_len = line_len
            else:
                current.append(line)
                current_len += line_len
        if current:
            parts.append("\n".join(current))
        return parts

    parts = split_message(message)
    total = len(parts)

    for i, part in enumerate(parts, 1):
        label = f" ({i}/{total})" if total > 1 else ""
        try:
            _telegram_send_raw(url, {
                "chat_id":                  chat_id,
                "text":                     part,
                "parse_mode":               "HTML",
                "disable_web_page_preview": True,
            })
            print(f"[Telegram] âœ… Nachricht{label} gesendet ({len(part)} Zeichen)")
        except Exception as e:
            print(f"[Telegram] âš ï¸  HTML-Modus fehlgeschlagen{label} ({e}), versuche Plain Text â€¦")
            # Fallback: HTML-Tags entfernen, kein parse_mode senden
            plain = _truncate_plain(_strip_html_tags(part))
            try:
                _telegram_send_raw(url, {
                    "chat_id":                  chat_id,
                    "text":                     plain,
                    "disable_web_page_preview": True,
                })
                print(f"[Telegram] âœ… Plain-Text{label} gesendet ({len(plain)} Zeichen)")
            except Exception as e2:
                raise RuntimeError(f"Telegram komplett fehlgeschlagen{label}: {e2}") from e2


# =============================================================================
# GUTACHTEN â€“ PDF-DOWNLOAD & PARSING
# =============================================================================

def gutachten_fetch_attachment_links(edikt_url: str) -> dict:
    """
    Ã–ffnet die Edikt-Detailseite und gibt alle Anhang-Links zurÃ¼ck.
    RÃ¼ckgabe: {"pdfs": [...], "images": [...]}
    """
    req = urllib.request.Request(
        edikt_url,
        headers={"User-Agent": "Mozilla/5.0 (compatible; EdikteMonitor/1.0)"}
    )
    with urllib.request.urlopen(req, timeout=30) as r:
        html = r.read().decode("utf-8", errors="replace")

    pattern = re.compile(
        r'href="(/edikte/ex/exedi3\.nsf/0/[^"]+\$file/([^"]+))"',
        re.IGNORECASE
    )
    pdfs   = []
    images = []
    for path, raw_fname in pattern.findall(html):
        fname = urllib.parse.unquote(raw_fname)
        full  = f"{BASE_URL}{path}"
        if fname.lower().endswith(".pdf"):
            pdfs.append({"url": full, "filename": fname})
        elif fname.lower().endswith((".jpg", ".jpeg", ".png")):
            images.append({"url": full, "filename": fname})
    return {"pdfs": pdfs, "images": images}


def gutachten_pick_best_pdf(pdfs: list) -> dict | None:
    """WÃ¤hlt das wahrscheinlichste Gutachten-PDF aus der Liste."""
    preferred = ["gutachten", " g ", "sachverst", "sv-", "/g-", "g "]
    for pdf in pdfs:
        if any(kw in pdf["filename"].lower() for kw in preferred):
            return pdf
    for pdf in pdfs:
        if "anlagen" not in pdf["filename"].lower():
            return pdf
    return pdfs[0] if pdfs else None


def gutachten_download_pdf(url: str) -> bytes:
    """LÃ¤dt ein PDF herunter und gibt die Bytes zurÃ¼ck."""
    req = urllib.request.Request(
        url,
        headers={"User-Agent": "Mozilla/5.0 (compatible; EdikteMonitor/1.0)"}
    )
    with urllib.request.urlopen(req, timeout=60) as r:
        return r.read()


def _gb_extract_section(text: str, start_marker: str, end_marker: str) -> str:
    """Extrahiert Text zwischen zwei Markierungen."""
    start = text.lower().find(start_marker.lower())
    if start == -1:
        return ""
    end = text.lower().find(end_marker.lower(), start + len(start_marker))
    if end == -1:
        return text[start:]
    return text[start:end]


def _gb_parse_owner(section_b: str) -> dict:
    """Parst Namen und Adresse aus Section B des Grundbuchs."""
    result = {
        "eigentÃ¼mer_name":    "",
        "eigentÃ¼mer_adresse": "",
        "eigentÃ¼mer_plz_ort": "",
        "eigentÃ¼mer_geb":     "",
    }
    adr_pattern  = re.compile(
        r'GEB:\s*(\d{4}-\d{2}-\d{2})\s+ADR:\s*(.+?)\s{2,}(\d{4,5})\s*$',
        re.IGNORECASE
    )
    adr_no_geb   = re.compile(r'ADR:\s*(.+?)\s{2,}(\d{4,5})\s*$', re.IGNORECASE)
    adr_simple   = re.compile(r'ADR:\s*(.+)', re.IGNORECASE)

    lines = section_b.splitlines()
    for i, line in enumerate(lines):
        if "ANTEIL:" not in line.upper():
            continue
        for j in range(i + 1, min(i + 8, len(lines))):
            candidate = lines[j]
            stripped  = candidate.strip()
            if not stripped:
                continue
            if re.match(r'^\d', stripped):          continue
            if re.match(r'^[a-z]\s+\d', stripped):  continue
            if "GEB:" in stripped.upper():           continue
            if "ADR:" in stripped.upper():           continue
            if re.match(r'^\*+', stripped):          continue
            result["eigentÃ¼mer_name"] = stripped
            for k in range(j + 1, min(j + 4, len(lines))):
                adr_line = lines[k].strip()
                if not adr_line:
                    continue
                m = adr_pattern.search(adr_line)
                if m:
                    result["eigentÃ¼mer_geb"]     = m.group(1)
                    result["eigentÃ¼mer_adresse"] = m.group(2).strip().rstrip(",")
                    result["eigentÃ¼mer_plz_ort"] = m.group(3)
                    break
                m2 = adr_no_geb.search(adr_line)
                if m2:
                    result["eigentÃ¼mer_adresse"] = m2.group(1).strip().rstrip(",")
                    result["eigentÃ¼mer_plz_ort"] = m2.group(2)
                    break
                m3 = adr_simple.search(adr_line)
                if m3:
                    adr_raw = m3.group(1).strip()
                    plz_m = re.search(r'\s+(\d{4,5})\s*$', adr_raw)
                    if plz_m:
                        result["eigentÃ¼mer_plz_ort"] = plz_m.group(1)
                        result["eigentÃ¼mer_adresse"] = adr_raw[:plz_m.start()].strip().rstrip(",")
                    else:
                        result["eigentÃ¼mer_adresse"] = adr_raw
                    break
            break
        break
    return result


def _gb_parse_creditors(section_c: str) -> tuple:
    """Parst PfandrechtsglÃ¤ubiger und ForderungsbetrÃ¤ge aus Section C."""
    glÃ¤ubiger = []
    betrag    = ""
    lines = [l.strip() for l in section_c.splitlines() if l.strip()]
    fuer_pattern   = re.compile(r'^fÃ¼r\s+(.+)', re.IGNORECASE)
    betrag_pattern = re.compile(r'Hereinbringung von\s+(EUR\s+[\d\.,]+)', re.IGNORECASE)
    pfand_pattern  = re.compile(r'PFANDRECHT\s+HÃ¶chstbetrag\s+(EUR\s+[\d\.,]+)', re.IGNORECASE)
    seen = set()
    for line in lines:
        m = fuer_pattern.match(line)
        if m:
            name = m.group(1).strip().rstrip(".")
            if len(name) > 5 and name not in seen:
                glÃ¤ubiger.append(name)
                seen.add(name)
        if not betrag:
            mb = betrag_pattern.search(line)
            if mb:
                betrag = mb.group(1).strip()
    if not betrag:
        for line in lines:
            mp = pfand_pattern.search(line)
            if mp:
                betrag = mp.group(1).strip()
                break
    return glÃ¤ubiger, betrag


def gutachten_extract_info(pdf_bytes: bytes) -> dict:
    """
    Extrahiert EigentÃ¼mer, Adresse, GlÃ¤ubiger und Forderungsbetrag aus dem PDF.
    UnterstÃ¼tzt Grundbuchauszug-Format (KÃ¤rnten-Stil) und professionelle
    Gutachten mit 'Verpflichtete Partei:'-Angabe (Wien-Stil).
    Gibt leeres Dict zurÃ¼ck wenn fitz nicht verfÃ¼gbar ist.
    """
    if not FITZ_AVAILABLE:
        return {}

    doc      = fitz.open(stream=pdf_bytes, filetype="pdf")
    all_text = [p.get_text() for p in doc if p.get_text().strip()]
    full_text = "\n".join(all_text)

    result = {
        "eigentÃ¼mer_name":    "",
        "eigentÃ¼mer_adresse": "",
        "eigentÃ¼mer_plz_ort": "",
        "eigentÃ¼mer_geb":     "",
        "glÃ¤ubiger":          [],
        "forderung_betrag":   "",
    }

    # â”€â”€ Format 1: Grundbuchauszug Sektionen B / C â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    sec_b = _gb_extract_section(full_text, "** B ***", "** C ***")
    if not sec_b:
        sec_b = _gb_extract_section(full_text, "** B **", "** C **")
    if sec_b:
        result.update(_gb_parse_owner(sec_b))

    sec_c = _gb_extract_section(full_text, "** C ***", "** HINWEIS ***")
    if not sec_c:
        sec_c = _gb_extract_section(full_text, "** C **", "HINWEIS")
    if sec_c:
        gl, bt = _gb_parse_creditors(sec_c)
        result["glÃ¤ubiger"]        = gl
        result["forderung_betrag"] = bt

    # â”€â”€ Format 2: Professionelles Gutachten (Verpflichtete Partei) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if not result["eigentÃ¼mer_name"]:
        vp = re.search(
            r'Verpflichtete(?:\s+Partei)?:\s*(.+?)(?:\n|Betreibende|Auftraggeber)',
            full_text[:3000], re.IGNORECASE | re.DOTALL
        )
        if vp:
            result["eigentÃ¼mer_name"] = vp.group(1).strip().split("\n")[0].strip()

    if result["eigentÃ¼mer_name"] and not result["eigentÃ¼mer_adresse"]:
        name_esc = re.escape(result["eigentÃ¼mer_name"][:30])
        adr_after = re.search(
            name_esc + r'[^\n]*\n\s*([A-ZÃ„Ã–Ãœ][^\n]{5,60})\s*\n',
            full_text[:3000], re.IGNORECASE
        )
        if adr_after:
            adr_raw = adr_after.group(1).strip()
            plz_m = re.search(r'\b(\d{4,5})\b', adr_raw)
            if plz_m:
                result["eigentÃ¼mer_plz_ort"] = plz_m.group(1)
                result["eigentÃ¼mer_adresse"] = adr_raw

    if not result["glÃ¤ubiger"]:
        bp = re.search(
            r'Betreibende(?:\s+Partei)?:\s*(.+?)(?:\n|Verpflichtete)',
            full_text[:3000], re.IGNORECASE | re.DOTALL
        )
        if bp:
            g = bp.group(1).strip().split("\n")[0].strip()
            if g:
                result["glÃ¤ubiger"] = [g]

    return result


def gutachten_enrich_notion_page(
    notion: Client,
    page_id: str,
    edikt_url: str,
) -> bool:
    """
    Hauptfunktion: LÃ¤dt das Gutachten-PDF von der Edikt-Seite,
    extrahiert EigentÃ¼mer/GlÃ¤ubiger und schreibt sie in die Notion-Seite.

    Gibt True zurÃ¼ck wenn erfolgreich, False bei Fehler oder fehlendem PDF.
    Das Flag 'Gutachten analysiert?' wird immer gesetzt (True/False).
    """
    if not FITZ_AVAILABLE:
        print("    [Gutachten] âš ï¸  PyMuPDF nicht verfÃ¼gbar â€“ Ã¼berspringe PDF-Analyse")
        return False

    try:
        attachments = gutachten_fetch_attachment_links(edikt_url)
        pdfs = attachments["pdfs"]
    except Exception as exc:
        print(f"    [Gutachten] âš ï¸  Fehler beim Laden der Edikt-Seite: {exc}")
        notion.pages.update(
            page_id=page_id,
            properties={"Gutachten analysiert?": {"checkbox": False}}
        )
        return False

    if not pdfs:
        print("    [Gutachten] â„¹ï¸  Kein PDF-Anhang gefunden")
        notion.pages.update(
            page_id=page_id,
            properties={"Gutachten analysiert?": {"checkbox": False}}
        )
        return False

    gutachten = gutachten_pick_best_pdf(pdfs)
    print(f"    [Gutachten] ğŸ“„ {gutachten['filename']}")

    try:
        pdf_bytes = gutachten_download_pdf(gutachten["url"])
    except Exception as exc:
        print(f"    [Gutachten] âš ï¸  Download-Fehler: {exc}")
        notion.pages.update(
            page_id=page_id,
            properties={"Gutachten analysiert?": {"checkbox": False}}
        )
        return False

    try:
        info = gutachten_extract_info(pdf_bytes)
    except Exception as exc:
        print(f"    [Gutachten] âš ï¸  Parse-Fehler: {exc}")
        notion.pages.update(
            page_id=page_id,
            properties={"Gutachten analysiert?": {"checkbox": False}}
        )
        return False

    # â”€â”€ Notion-Properties aufbauen â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    has_owner = bool(info.get("eigentÃ¼mer_name") or info.get("eigentÃ¼mer_adresse"))
    properties: dict = {
        "Gutachten analysiert?": {"checkbox": True},
    }

    def _rt(text: str) -> dict:
        return {"rich_text": [{"text": {"content": str(text)[:2000]}}]}

    if info.get("eigentÃ¼mer_name"):
        print(f"    [Gutachten] ğŸ‘¤ EigentÃ¼mer: {info['eigentÃ¼mer_name']}")
        properties["Verpflichtende Partei"] = _rt(info["eigentÃ¼mer_name"])

    if info.get("eigentÃ¼mer_adresse"):
        print(f"    [Gutachten] ğŸ  Adresse: {info['eigentÃ¼mer_adresse']}")
        properties["Zustell Adresse"] = _rt(info["eigentÃ¼mer_adresse"])

    if info.get("eigentÃ¼mer_plz_ort"):
        properties["Zustell PLZ/Ort"] = _rt(info["eigentÃ¼mer_plz_ort"])

    # Notizen: GlÃ¤ubiger + Forderung + PDF-Link
    notiz_parts = []
    if info.get("glÃ¤ubiger"):
        print(f"    [Gutachten] ğŸ¦ GlÃ¤ubiger: {' | '.join(info['glÃ¤ubiger'][:2])}")
        notiz_parts.append("GlÃ¤ubiger: " + " | ".join(info["glÃ¤ubiger"]))
    if info.get("forderung_betrag"):
        notiz_parts.append("Forderung: " + info["forderung_betrag"])
    notiz_parts.append(f"Gutachten-PDF: {gutachten['url']}")
    properties["Notizen"] = _rt("\n".join(notiz_parts))

    if not has_owner:
        # Gescanntes Dokument â€“ trotzdem als analysiert markieren
        properties["Notizen"] = _rt(
            f"Gutachten-PDF: {gutachten['url']}\n"
            "(Kein Grundbuch-Text lesbar â€“ mÃ¶glicherweise gescanntes Dokument)"
        )
        print("    [Gutachten] âš ï¸  Kein EigentÃ¼mer gefunden (gescanntes Dokument?)")

    try:
        notion.pages.update(page_id=page_id, properties=properties)
        print("    [Gutachten] âœ… Notion aktualisiert")
    except Exception as exc:
        print(f"    [Gutachten] âš ï¸  Notion-Update-Fehler: {exc}")
        return False

    return True


# =============================================================================
# NOTION
# =============================================================================

def notion_load_all_ids(notion: Client, db_id: str) -> dict[str, str]:
    """
    LÃ¤dt ALLE bestehenden EintrÃ¤ge aus der Notion-DB und gibt ein Dict
    {edikt_id -> page_id} zurÃ¼ck.

    ZusÃ¤tzlich werden EintrÃ¤ge mit fortgeschrittener Workflow-Phase
    (z.B. 'Angeschrieben', 'Angebot', 'Gekauft') unter dem Sentinel-Wert
    "(geschuetzt)" gespeichert â€“ der Scraper Ã¼berspringt diese komplett,
    auch wenn die Hash-ID matcht. So werden bereits bearbeitete Immobilien
    niemals dupliziert oder Ã¼berschrieben.

    Paginierung: Notion liefert max. 100 Ergebnisse pro Anfrage.
    """
    # Workflow-Phasen die NICHT Ã¼berschrieben werden dÃ¼rfen
    GESCHUETZT_PHASEN = {
        "ğŸ“¨ Angeschrieben",
        "ğŸ¤ Angebot",
        "ğŸ“‹ Due Diligence",
        "âœ… Gekauft",
        "âŒ Abgelehnt",
    }

    print("[Notion] ğŸ“¥ Lade alle bestehenden IDs aus der Datenbank â€¦")
    known: dict[str, str] = {}  # edikt_id -> page_id  (oder "(geschuetzt)")
    has_more = True
    cursor = None
    page_count = 0
    geschuetzt_count = 0

    while has_more:
        kwargs: dict = {"filter": {"value": "page", "property": "object"}, "page_size": 100}
        if cursor:
            kwargs["start_cursor"] = cursor
        try:
            resp = notion.search(**kwargs)
        except Exception as exc:
            print(f"  [Notion] âš ï¸  Fehler beim Laden der IDs: {exc}")
            break

        for page in resp.get("results", []):
            # Nur Pages aus unserer DB
            parent = page.get("parent", {})
            if parent.get("database_id", "").replace("-", "") != db_id.replace("-", ""):
                continue

            props = page.get("properties", {})

            # Workflow-Phase prÃ¼fen
            phase_sel = props.get("Workflow-Phase", {}).get("select") or {}
            phase = phase_sel.get("name", "")
            ist_geschuetzt = phase in GESCHUETZT_PHASEN

            # Hash-ID auslesen
            hash_rt = props.get("Hash-ID / Vergleichs-ID", {}).get("rich_text", [])
            eid = ""
            if hash_rt:
                eid = hash_rt[0].get("plain_text", "").strip().lower()

            if eid:
                if ist_geschuetzt:
                    known[eid] = "(geschuetzt)"
                    geschuetzt_count += 1
                else:
                    known[eid] = page["id"]

            # EintrÃ¤ge OHNE Hash-ID aber MIT fortgeschrittener Phase:
            # Titel als Ersatz-Fingerprint speichern (verhindert Doppelanlage
            # bei manuell eingetragenen Immobilien ohne Hash-ID)
            elif ist_geschuetzt:
                title_rt = props.get("Liegenschaftsadresse", {}).get("title", [])
                title = title_rt[0].get("plain_text", "").strip().lower() if title_rt else ""
                if title:
                    known[f"__titel__{title}"] = "(geschuetzt)"
                    geschuetzt_count += 1

            page_count += 1

        has_more = resp.get("has_more", False)
        cursor   = resp.get("next_cursor")

    print(f"[Notion] âœ… {len(known)} EintrÃ¤ge geladen "
          f"({geschuetzt_count} geschÃ¼tzt, {page_count} Seiten geprÃ¼ft)")
    return known


def notion_create_eintrag(notion: Client, db_id: str, data: dict) -> dict:
    """
    Legt einen neuen Eintrag in Notion an.
    Ruft die Detailseite ab, filtert nach Kategorie und befÃ¼llt alle Felder.
    Gibt den detail-Dict zurÃ¼ck (oder {} wenn Objekt gefiltert wurde).
    RÃ¼ckgabe None bedeutet: Objekt wurde durch Kategorie-Filter ausgeschlossen.
    """
    bundesland   = data.get("bundesland", "Unbekannt")
    link         = data.get("link", "")
    edikt_id     = data.get("edikt_id", "")
    beschreibung = data.get("beschreibung", "")
    typ          = data.get("type", "Versteigerung")

    # â”€â”€ Detailseite abrufen â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    detail: dict = {}
    if link:
        detail = fetch_detail(link)

    # â”€â”€ Kategorie-Filter (auf Detailseite, zuverlÃ¤ssiger als Link-Text) â”€â”€â”€â”€â”€â”€
    kategorie = detail.get("kategorie", "")
    if kategorie and is_excluded_by_kategorie(kategorie):
        print(f"  [Filter] â›” Kategorie ausgeschlossen: '{kategorie}' ({edikt_id[:8]}â€¦)")
        return None  # Signalisiert: nicht importieren

    # â”€â”€ Liegenschaftsadresse als Titel â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    adresse_voll = detail.get("adresse_voll", "")
    if not adresse_voll:
        datum_m = re.search(r"\((\d{2}\.\d{2}\.\d{4})\)", beschreibung)
        adresse_voll = f"{bundesland} â€“ {datum_m.group(1) if datum_m else beschreibung[:60]}"

    titel    = adresse_voll
    objektart = kategorie or beschreibung[:200]

    # â”€â”€ Kern-Properties (existieren garantiert in jeder Notion-DB) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    properties: dict = {
        "Liegenschaftsadresse": {
            "title": [{"text": {"content": titel[:200]}}]
        },
        "Hash-ID / Vergleichs-ID": {
            "rich_text": [{"text": {"content": edikt_id}}]
        },
        "Link": {"url": link},
        "Art des Edikts": {
            "select": {
                "name": typ if typ in ("Versteigerung", "Entfall des Termins") else "Versteigerung"
            }
        },
        "Bundesland":              {"select": {"name": bundesland}},
        "Neu eingelangt":          {"checkbox": True},
        "Automatisch importiert?": {"checkbox": True},
        "Workflow-Phase":          {"select": {"name": "ğŸ†• Neu eingelangt"}},
        "Objektart": {
            "rich_text": [{"text": {"content": objektart[:200]}}]
        },
    }

    # â”€â”€ Optionale Properties â€“ werden einzeln hinzugefÃ¼gt â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # SchlÃ¤gt ein Feld fehl, wird nur dieses Feld Ã¼bersprungen, nicht der ganze Eintrag.

    verkehrswert = detail.get("schaetzwert")
    if verkehrswert is not None:
        vk_str = f"{verkehrswert:,.2f} â‚¬".replace(",", "X").replace(".", ",").replace("X", ".")
        properties["Verkehrswert"] = {"rich_text": [{"text": {"content": vk_str}}]}

    termin_iso = detail.get("termin_iso")
    if termin_iso:
        properties["Versteigerungstermin"] = {"date": {"start": termin_iso}}

    gericht = detail.get("gericht", "")
    if gericht:
        properties["Verpflichtende Partei"] = {
            "rich_text": [{"text": {"content": gericht[:200]}}]
        }

    plz_ort = detail.get("plz_ort", "")
    if plz_ort:
        # VollstÃ¤ndig: "1120 Wien" â†’ "1120 Wien"
        properties[NOTION_PLZ_FIELD] = {
            "rich_text": [{"text": {"content": plz_ort.strip()[:100]}}]
        }

    flaeche = detail.get("flaeche_objekt") or detail.get("flaeche_grundstueck")
    if flaeche is not None:
        flaeche_str = f"{flaeche:,.2f} mÂ²".replace(",", "X").replace(".", ",").replace("X", ".")
        properties["FlÃ¤che"] = {"rich_text": [{"text": {"content": flaeche_str}}]}

    # â”€â”€ Seite anlegen â€“ erst Kern, dann optionale Felder einzeln â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Strategie: Kern-Properties zuerst. Falls optionale Felder nicht existieren,
    # werden sie weggelassen und der Eintrag trotzdem angelegt.
    created_page = None
    try:
        created_page = notion.pages.create(parent={"database_id": db_id}, properties=properties)
        print(f"  [Notion] âœ… Erstellt: {titel[:80]}")
    except Exception as e:
        err_str = str(e)
        # Herausfinden welches Feld das Problem ist und es entfernen
        optional_fields = [NOTION_PLZ_FIELD, "FlÃ¤che", "Verkehrswert",
                           "Versteigerungstermin", "Verpflichtende Partei"]
        removed = []
        for field in optional_fields:
            if field in err_str and field in properties:
                del properties[field]
                removed.append(field)

        if removed:
            print(f"  [Notion] âš ï¸  Felder nicht gefunden, Ã¼bersprungen: {removed}")
            try:
                created_page = notion.pages.create(parent={"database_id": db_id}, properties=properties)
                print(f"  [Notion] âœ… Erstellt (ohne {removed}): {titel[:80]}")
            except Exception as e2:
                raise e2  # Wirklicher Fehler â†’ nach oben weitergeben
        else:
            raise  # Kein bekanntes optionales Feld â†’ nach oben weitergeben

    # Gibt (detail, page_id) zurÃ¼ck damit der Aufrufer das Gutachten anreichern kann
    new_page_id = created_page["id"] if created_page else None
    return detail, new_page_id


def notion_mark_entfall(notion: Client, page_id: str, item: dict) -> None:
    """Markiert ein bestehendes Notion-Objekt als 'Termin entfallen'."""
    notion.pages.update(
        page_id=page_id,
        properties={
            "Art des Edikts": {"select": {"name": "Entfall des Termins"}},
            "Archiviert":     {"checkbox": True},
            "Workflow-Phase": {"select": {"name": "ğŸ—„ Archiviert"}},
            "Neu eingelangt": {"checkbox": False},
        },
    )
    print(f"  [Notion] ğŸ”´ Entfall markiert: {item.get('edikt_id', '?')}")


def notion_enrich_urls(notion: Client, db_id: str) -> int:
    """
    Findet Notion-EintrÃ¤ge OHNE Link-URL und versucht, Ã¼ber die Edikte-Suche
    einen passenden Eintrag zu finden.

    Strategie:
    1. Alle Pages aus der DB via search() laden.
    2. Falls die Seite eine Hash-ID hat â†’ Link direkt konstruieren.
    3. Falls nicht â†’ Ã¼ber Titel / Bundesland eine Freitextsuche machen.

    Gibt die Anzahl der erfolgreich ergÃ¤nzten URLs zurÃ¼ck.
    """
    print("\n[URL-Anreicherung] ğŸ”— Suche nach EintrÃ¤gen ohne URL â€¦")

    enriched = 0

    # Alle Seiten via search() laden (notion-client v3 hat kein databases.query)
    pages_without_url: list[dict] = []
    has_more = True
    start_cursor = None

    while has_more:
        kwargs: dict = {
            "filter": {"value": "page", "property": "object"},
            "page_size": 100,
        }
        if start_cursor:
            kwargs["start_cursor"] = start_cursor

        try:
            resp = notion.search(**kwargs)
        except Exception as exc:
            print(f"  [URL-Anreicherung] âŒ Notion-Abfrage fehlgeschlagen: {exc}")
            break

        for page in resp.get("results", []):
            # Nur Pages aus unserer DB
            parent = page.get("parent", {})
            if parent.get("database_id", "").replace("-", "") != db_id.replace("-", ""):
                continue
            # Nur Pages ohne Link
            props    = page.get("properties", {})
            link_val = props.get("Link", {}).get("url")
            if not link_val:
                pages_without_url.append(page)

        has_more = resp.get("has_more", False)
        start_cursor = resp.get("next_cursor")

    print(f"  [URL-Anreicherung] ğŸ“‹ {len(pages_without_url)} EintrÃ¤ge ohne URL gefunden")

    for page in pages_without_url:
        page_id = page["id"]
        props   = page.get("properties", {})

        # Hash-ID vorhanden? â†’ Link direkt bauen
        hash_rt = props.get("Hash-ID / Vergleichs-ID", {}).get("rich_text", [])
        if hash_rt:
            edikt_id = hash_rt[0].get("plain_text", "").strip()
            if edikt_id and re.fullmatch(r"[0-9a-f]{32}", edikt_id):
                constructed_link = (
                    f"{BASE_URL}/edikte/ex/exedi3.nsf/alldoc/{edikt_id}!OpenDocument"
                )
                try:
                    notion.pages.update(
                        page_id=page_id,
                        properties={"Link": {"url": constructed_link}},
                    )
                    enriched += 1
                    print(f"  [URL-Anreicherung] âœ… Link gesetzt (Hash-ID): {edikt_id}")
                except Exception as exc:
                    print(f"  [URL-Anreicherung] âŒ Update fehlgeschlagen ({edikt_id}): {exc}")
                continue

        # Kein Hash-ID â†’ Titel-Suche auf edikte.at
        title_rt = props.get("Liegenschaftsadresse", {}).get("title", [])
        titel = title_rt[0].get("plain_text", "") if title_rt else ""

        bl_prop = props.get("Bundesland", {}).get("select") or {}
        bundesland_name = bl_prop.get("name", "")
        bl_value = BUNDESLAENDER.get(bundesland_name, "")

        if not titel and not bl_value:
            print(f"  [URL-Anreicherung] âš ï¸  Kein Titel/Bundesland fÃ¼r {page_id[:8]}â€¦")
            continue

        # Suche fÃ¼r das Bundesland + Keyword aus dem Titel
        keyword = re.sub(r"(Wien|NiederÃ¶sterreich|Burgenland|OberÃ¶sterreich|Salzburg|"
                         r"Steiermark|KÃ¤rnten|Tirol|Vorarlberg)", "", titel).strip()
        keyword = keyword[:40] if keyword else ""

        matches = _search_edikt_by_keyword(bl_value, keyword)
        if len(matches) == 1:
            candidate = matches[0]
            try:
                notion.pages.update(
                    page_id=page_id,
                    properties={
                        "Link": {"url": candidate["link"]},
                        "Hash-ID / Vergleichs-ID": {
                            "rich_text": [{"text": {"content": candidate["edikt_id"]}}]
                        },
                    },
                )
                enriched += 1
                print(
                    f"  [URL-Anreicherung] âœ… Link gefunden (Freitext): "
                    f"{candidate['edikt_id']}"
                )
            except Exception as exc:
                print(f"  [URL-Anreicherung] âŒ Update fehlgeschlagen: {exc}")
        elif len(matches) == 0:
            print(f"  [URL-Anreicherung] ğŸ” Kein Treffer fÃ¼r '{titel[:50]}'")
        else:
            print(
                f"  [URL-Anreicherung] â“ {len(matches)} Treffer (mehrdeutig) "
                f"fÃ¼r '{titel[:50]}' â€“ Ã¼bersprungen"
            )

    print(f"[URL-Anreicherung] âœ… {enriched} URLs ergÃ¤nzt")
    return enriched


def _search_edikt_by_keyword(bl_value: str, keyword: str) -> list[dict]:
    """
    Interne Hilfsfunktion: Sucht auf edikte.at fÃ¼r ein Bundesland mit einem
    Freitext-Keyword und gibt die gefundenen Items zurÃ¼ck.
    """
    if not bl_value:
        return []

    query_parts = [f"([BL]=({bl_value}))"]
    if keyword:
        query_parts.append(keyword)

    params = urllib.parse.urlencode({
        "SearchView": "",
        "subf": "eex",
        "SearchOrder": "4",
        "SearchMax": "50",
        "retfields": f"~BL={bl_value}",
        "ftquery": keyword,
        "query": " ".join(query_parts),
    })
    url = f"{BASE_URL}/edikte/ex/exedi3.nsf/suchedi?{params}"

    try:
        req = urllib.request.Request(
            url,
            headers={"User-Agent": "Mozilla/5.0 (compatible; EdikteMonitor/1.0)"}
        )
        with urllib.request.urlopen(req, timeout=20) as r:
            html = r.read().decode("utf-8", errors="replace")
    except Exception:
        return []

    rel_pattern = re.compile(
        r'<a[^>]+href="(alldoc/([0-9a-f]+)!OpenDocument)"[^>]*>([^<]+)</a>',
        re.IGNORECASE
    )

    results = []
    for href_rel, edikt_id, link_text in rel_pattern.findall(html):
        link_text = link_text.strip()
        if not any(link_text.startswith(t) for t in RELEVANT_TYPES):
            continue
        results.append({
            "edikt_id": edikt_id.lower(),
            "link": f"{BASE_URL}/edikte/ex/exedi3.nsf/{href_rel}",
            "beschreibung": link_text,
        })
    return results


def notion_enrich_gutachten(notion: Client, db_id: str) -> int:
    """
    Findet alle Notion-EintrÃ¤ge die:
      - eine URL (Link) haben, UND
      - 'Gutachten analysiert?' = False / nicht gesetzt haben, UND
      - NICHT in einer geschÃ¼tzten Workflow-Phase sind

    FÃ¼r jeden solchen Eintrag wird das Gutachten-PDF heruntergeladen
    und die Properties (EigentÃ¼mer, Adresse, GlÃ¤ubiger, Forderung) befÃ¼llt.

    Das ist der Weg fÃ¼r manuell eingetragene Immobilien:
    Sobald die URL gesetzt wird (entweder vom Nutzer oder durch URL-Anreicherung),
    wird das Gutachten automatisch beim nÃ¤chsten Lauf analysiert.

    Gibt die Anzahl der erfolgreich angereicherten EintrÃ¤ge zurÃ¼ck.
    """
    GESCHUETZT_PHASEN = {
        "ğŸ“¨ Angeschrieben", "ğŸ¤ Angebot",
        "ğŸ“‹ Due Diligence", "âœ… Gekauft", "âŒ Abgelehnt",
    }

    print("\n[Gutachten-Anreicherung] ğŸ“„ Suche nach EintrÃ¤gen ohne Gutachten-Analyse â€¦")

    to_enrich: list[dict] = []
    has_more     = True
    start_cursor = None

    while has_more:
        kwargs: dict = {
            "filter": {"value": "page", "property": "object"},
            "page_size": 100,
        }
        if start_cursor:
            kwargs["start_cursor"] = start_cursor

        try:
            resp = notion.search(**kwargs)
        except Exception as exc:
            print(f"  [Gutachten-Anreicherung] âŒ Notion-Abfrage fehlgeschlagen: {exc}")
            break

        for page in resp.get("results", []):
            parent = page.get("parent", {})
            if parent.get("database_id", "").replace("-", "") != db_id.replace("-", ""):
                continue

            props = page.get("properties", {})

            # Nur EintrÃ¤ge in nicht-geschÃ¼tzter Phase
            phase = (props.get("Workflow-Phase", {}).get("select") or {}).get("name", "")
            if phase in GESCHUETZT_PHASEN:
                continue

            # Muss eine URL haben
            link_val = props.get("Link", {}).get("url")
            if not link_val:
                continue

            # Noch nicht analysiert
            analysiert = props.get("Gutachten analysiert?", {}).get("checkbox", False)
            if analysiert:
                continue

            to_enrich.append({"page_id": page["id"], "link": link_val})

        has_more     = resp.get("has_more", False)
        start_cursor = resp.get("next_cursor")

    MAX_PER_RUN = 15   # Begrenzung: max. 15 PDFs pro Run (~2â€“3 Min. Laufzeit)
    total_found = len(to_enrich)
    if total_found > MAX_PER_RUN:
        print(f"  [Gutachten-Anreicherung] âš ï¸  {total_found} gefunden â€“ verarbeite nur die ersten {MAX_PER_RUN} (Rest beim nÃ¤chsten Run)")
        to_enrich = to_enrich[:MAX_PER_RUN]

    print(f"  [Gutachten-Anreicherung] ğŸ“‹ {len(to_enrich)} EintrÃ¤ge werden jetzt analysiert")

    enriched = 0
    for entry in to_enrich:
        try:
            ok = gutachten_enrich_notion_page(notion, entry["page_id"], entry["link"])
            if ok:
                enriched += 1
        except Exception as exc:
            print(f"  [Gutachten-Anreicherung] âŒ Fehler fÃ¼r {entry['page_id'][:8]}â€¦: {exc}")
        time.sleep(0.3)   # kurze Pause um API-Limits zu schonen

    remaining = total_found - len(to_enrich)
    if remaining > 0:
        print(f"  [Gutachten-Anreicherung] â„¹ï¸  Noch {remaining} EintrÃ¤ge offen â€“ werden in nÃ¤chsten Runs verarbeitet")
    print(f"[Gutachten-Anreicherung] âœ… {enriched} Gutachten analysiert")
    return enriched


# =============================================================================
# SCRAPING â€“ direkte HTTP-Requests (kein Browser nÃ¶tig!)
# =============================================================================

def fetch_results_for_state(bundesland: str, bl_value: str) -> list[dict]:
    """
    Ruft die Ergebnisseite fÃ¼r ein Bundesland direkt per HTTP ab.

    Die URL-Struktur wurde durch Analyse des Formulars ermittelt:
    /edikte/ex/exedi3.nsf/suchedi?SearchView&subf=eex&...&query=([BL]=(X))
    """
    print(f"\n[Scraper] ğŸ” Suche fÃ¼r: {bundesland} (BL={bl_value})")

    query = f"([BL]=({bl_value}))"
    params = urllib.parse.urlencode({
        "SearchView": "",
        "subf": "eex",
        "SearchOrder": "4",
        "SearchMax": "4999",
        "retfields": f"~BL={bl_value}",
        "ftquery": "",
        "query": query,
    })
    url = f"{BASE_URL}/edikte/ex/exedi3.nsf/suchedi?{params}"

    try:
        req = urllib.request.Request(
            url,
            headers={"User-Agent": "Mozilla/5.0 (compatible; EdikteMonitor/1.0)"}
        )
        with urllib.request.urlopen(req, timeout=30) as r:
            html = r.read().decode("utf-8", errors="replace")
    except Exception as exc:
        print(f"  [Scraper] âŒ HTTP-Fehler: {exc}")
        return []

    # Links extrahieren â€“ Format: alldoc/HEX!OpenDocument (relativ, ohne fÃ¼hrendes /)
    rel_pattern = re.compile(
        r'<a[^>]+href="(alldoc/([0-9a-f]+)!OpenDocument)"[^>]*>([^<]+)</a>',
        re.IGNORECASE
    )

    results = []
    seen_ids = set()

    for href_rel, edikt_id, link_text in rel_pattern.findall(html):
        link_text = link_text.strip()
        edikt_id  = edikt_id.lower()
        href      = f"{BASE_URL}/edikte/ex/exedi3.nsf/{href_rel}"

        if edikt_id in seen_ids:
            continue
        seen_ids.add(edikt_id)

        # Typ bestimmen
        typ = None
        for t in RELEVANT_TYPES:
            if link_text.startswith(t):
                typ = t
                break
        if not typ:
            continue

        # Ausschlussliste (nur bei Versteigerung relevant)
        if typ == "Versteigerung" and is_excluded(link_text):
            print(f"  [Filter] â›” Ausgeschlossen: {link_text[:80]}")
            continue

        results.append({
            "bundesland":   bundesland,
            "type":         typ,
            "beschreibung": link_text,
            "link":         href,
            "edikt_id":     edikt_id,
        })

    print(f"  [Scraper] ğŸ“‹ {len(results)} relevante Treffer fÃ¼r {bundesland}")
    return results


# =============================================================================
# MAIN
# =============================================================================

async def main() -> None:
    print("=" * 60)
    print(f"Edikte-Monitor gestartet: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)

    notion = Client(auth=env("NOTION_TOKEN"))
    db_id  = clean_notion_db_id(env("NOTION_DATABASE_ID"))

    neue_eintraege:  list[dict] = []
    entfall_updates: list[dict] = []
    fehler:          list[str]  = []

    # â”€â”€ 1. Alle bekannten IDs einmalig laden (schnelle lokale Deduplizierung) â”€
    try:
        known_ids = notion_load_all_ids(notion, db_id)  # {edikt_id -> page_id}
    except Exception as exc:
        print(f"  [ERROR] Konnte IDs nicht laden: {exc}")
        known_ids = {}

    # â”€â”€ 2. Edikte scrapen + in Notion eintragen â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    for bundesland, bl_value in BUNDESLAENDER.items():
        try:
            results = fetch_results_for_state(bundesland, bl_value)
        except Exception as exc:
            msg = f"Scraper-Fehler {bundesland}: {exc}"
            print(f"  [ERROR] {msg}")
            fehler.append(msg)
            continue

        for item in results:
            try:
                eid = item["edikt_id"].lower()

                if item["type"] == "Versteigerung":
                    if known_ids.get(eid) == "(geschuetzt)":
                        print(f"  [Notion] ğŸ”’ GeschÃ¼tzt (bereits bearbeitet): {eid}")
                    elif eid not in known_ids:
                        result_tuple = notion_create_eintrag(notion, db_id, item)
                        if result_tuple is None:
                            # Kategorie-Filter hat das Objekt ausgeschlossen
                            known_ids[eid] = "(gefiltert)"
                        else:
                            detail, new_page_id = result_tuple
                            item["_detail"] = detail
                            neue_eintraege.append(item)
                            known_ids[eid] = "(neu)"  # sofort als bekannt markieren
                            # â”€â”€ Gutachten sofort anreichern â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                            if new_page_id and item.get("link") and FITZ_AVAILABLE:
                                try:
                                    gutachten_enrich_notion_page(
                                        notion, new_page_id, item["link"]
                                    )
                                except Exception as ge:
                                    print(f"    [Gutachten] âš ï¸  Anreicherung fehlgeschlagen: {ge}")
                    else:
                        print(f"  [Notion] â­  Bereits vorhanden: {eid}")

                elif item["type"] in ("Entfall des Termins", "Verschiebung"):
                    page_id = known_ids.get(eid)
                    if page_id and page_id != "(neu)":
                        notion_mark_entfall(notion, page_id, item)
                        entfall_updates.append(item)
                    else:
                        print(f"  [Notion] â„¹ï¸  Entfall ohne DB-Eintrag: {eid}")

            except Exception as exc:
                msg = f"Notion-Fehler {item.get('edikt_id', '?')}: {exc}"
                print(f"  [ERROR] {msg}")
                fehler.append(msg)

    # â”€â”€ 3. URL-Anreicherung fÃ¼r manuell angelegte EintrÃ¤ge â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    try:
        enriched_count = notion_enrich_urls(notion, db_id)
    except Exception as exc:
        msg = f"URL-Anreicherung fehlgeschlagen: {exc}"
        print(f"  [ERROR] {msg}")
        fehler.append(msg)
        enriched_count = 0

    # â”€â”€ 4. Gutachten-Anreicherung fÃ¼r manuell angelegte EintrÃ¤ge â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Betrifft: EintrÃ¤ge die bereits eine URL haben aber noch nicht analysiert wurden.
    # Das sind Immobilien die ihr selbst eingetragen habt (mit oder ohne Hash-ID).
    gutachten_enriched = 0
    if FITZ_AVAILABLE:
        try:
            gutachten_enriched = notion_enrich_gutachten(notion, db_id)
        except Exception as exc:
            msg = f"Gutachten-Anreicherung fehlgeschlagen: {exc}"
            print(f"  [ERROR] {msg}")
            fehler.append(msg)
    else:
        print("[Gutachten] â„¹ï¸  PyMuPDF nicht verfÃ¼gbar â€“ Ã¼berspringe Gutachten-Anreicherung")

    # â”€â”€ 5. Zusammenfassung â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("\n" + "=" * 60)
    print(f"âœ… Neue EintrÃ¤ge:       {len(neue_eintraege)}")
    print(f"ğŸ”´ Entfall-Updates:     {len(entfall_updates)}")
    print(f"ğŸ”— URLs ergÃ¤nzt:        {enriched_count}")
    print(f"ğŸ“„ Gutachten analysiert:{gutachten_enriched}")
    print(f"âš ï¸  Fehler:              {len(fehler)}")
    print("=" * 60)

    if not neue_eintraege and not entfall_updates and not fehler:
        print("Keine neuen relevanten Ã„nderungen â€“ kein Telegram-Versand.")
        return

    # â”€â”€ 4. Telegram â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    lines = [
        "<b>ğŸ› Edikte-Monitor</b>",
        f"<i>{datetime.now().strftime('%d.%m.%Y %H:%M')}</i>",
        "",
    ]

    if neue_eintraege:
        lines.append(f"<b>ğŸŸ¢ Neue Versteigerungen: {len(neue_eintraege)}</b>")
        for item in neue_eintraege[:20]:
            detail    = item.get("_detail", {})
            adresse   = html_escape(detail.get("adresse_voll") or item["beschreibung"][:70])
            kategorie = html_escape(detail.get("kategorie", ""))
            vk        = detail.get("schaetzwert")
            vk_str    = f" | ğŸ’° {vk:,.0f} â‚¬".replace(",", ".") if vk else ""
            kat_str   = f" [{kategorie}]" if kategorie else ""
            lines.append(f"â€¢ <b>{adresse}</b>{kat_str}{vk_str}")
            lines.append(f"  <a href=\"{item['link']}\">â†’ Edikt Ã¶ffnen</a>")
        if len(neue_eintraege) > 20:
            lines.append(f"  ... und {len(neue_eintraege) - 20} weitere")
        lines.append("")

    if entfall_updates:
        lines.append(f"<b>ğŸ”´ Termin entfallen/verschoben: {len(entfall_updates)}</b>")
        for item in entfall_updates[:10]:
            lines.append(f"â€¢ {html_escape(item['bundesland'])} â€“ {html_escape(item['beschreibung'][:60])}")
        lines.append("")

    if enriched_count:
        lines.append(f"<b>ğŸ”— URLs nachgetragen: {enriched_count}</b>")
        lines.append("")

    if gutachten_enriched:
        lines.append(f"<b>ğŸ“„ Gutachten analysiert: {gutachten_enriched}</b>")
        lines.append("")

    if fehler:
        lines.append(f"<b>âš ï¸ Fehler ({len(fehler)}):</b>")
        for f_msg in fehler[:5]:
            lines.append(f"â€¢ {f_msg[:100]}")

    try:
        await send_telegram("\n".join(lines))
    except Exception as exc:
        print(f"[ERROR] Telegram fehlgeschlagen: {exc}")


if __name__ == "__main__":
    asyncio.run(main())
